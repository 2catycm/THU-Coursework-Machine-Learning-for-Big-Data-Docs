<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="叶璨铭 (2024214500) ycm24@mails.tsinghua.edu.cn">

<title>深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用 – THU-Coursework-Machine-Learning-for-Big-Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../thu_logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<meta property="og:title" content="深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用 – THU-Coursework-Machine-Learning-for-Big-Data">
<meta property="og:description" content="大数据机器学习课程第一次实验项目">
<meta property="og:site_name" content="THU-Coursework-Machine-Learning-for-Big-Data">
<meta name="twitter:title" content="深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用 – THU-Coursework-Machine-Learning-for-Big-Data">
<meta name="twitter:description" content="大数据机器学习课程第一次实验项目">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">THU-Coursework-Machine-Learning-for-Big-Data</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="搜索"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="展开或折叠导航栏" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../theory_assignments/index.html" aria-current="page"> 
<span class="menu-text">理论作业 Theory Assignments</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../coding_projects/index.html"> 
<span class="menu-text">代码项目 Coding Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.xuetangx.com/course/THU08091001026/1515437"> 
<span class="menu-text">关于课程 Course Information</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/Open-Book-Studio"> 
<span class="menu-text">关于我们 About Us</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-discuss-with-us" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">和我们一起讨论 Discuss with Us</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-discuss-with-us">    
        <li>
    <a class="dropdown-item" href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">你的作业有地方写错了 Report an Issue on Assignments</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="http://qm.qq.com/cgi-bin/qm/qr?wv=1027&amp;k=v0Vpqbr4pScRi4IkFK3dsDUCzvu-BtX&amp;authKey=vyojwISealVovwzm6TQR7bkawm4oj6Wgbe4YBheQjRU5XOllK9pQ57eQjaG30dlq&amp;noverify=0&amp;group_code=935310031"><i class="bi bi-chat-right-text" role="img">
</i> 
 <span class="dropdown-text">X9高校人工智能技术讨论 X9 AI Tech Discussion</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/2catycm"><i class="bi bi-question-circle" role="img">
</i> 
 <span class="dropdown-text">联系我们 Contact Us</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Open-Book-Studio"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/THU-CVML"> <i class="bi bi-github" role="img" aria-label="THU-CVML 课题组">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../coding_projects/index.html">coding_projects</a></li><li class="breadcrumb-item"><a href="../../coding_projects/P1_KNN/kd_tree.html">P1_KNN</a></li><li class="breadcrumb-item"><a href="../../coding_projects/P1_KNN/kd_tree.html">深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">THU-Coursework-Machine-Learning-for-Big-Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../help (library information).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Library Information</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../coding_projects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">coding_projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">P1_ANOVA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P1_ANOVA/anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">深入探索方差分析 (Analysis of Variance, ANOVA)</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">P1_KNN</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P1_KNN/kd_tree.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">P2_SVM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/00svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/use_lib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/handy_crafted_linear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——02手动实现SGD优化的软间隔线性SVM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/kernel_hpo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——03不同Kernel的SVM超参数优化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/handy_crafted_kernel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——04手动实现使用SMO的Kernel SVM</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">big_data_analytics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">P2_Matrix-Decomposition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../theory_assignments/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">theory_assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">A1</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A1/p_assignment1_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">从数据集中进行分布参数估计: 以伯努利分布为例</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">A2</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A2/p_assignment2_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">大数据机器学习课程第二次作业</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">A3</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A3/p_assignment3_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">朴素贝叶斯与决策树的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">A4</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A4/p_assignment4_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">最大熵模型以及对数几率分类模型的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">A5</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A5/p_assignment5_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">支持向量机的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">A6</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A6/p_assignment6_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AdaBoost算法的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">该页面内容</h2>
   
  <ul>
  <li><a href="#实验目的" id="toc-实验目的" class="nav-link active" data-scroll-target="#实验目的"><span class="header-section-number">1</span> 实验目的</a></li>
  <li><a href="#实验数据" id="toc-实验数据" class="nav-link" data-scroll-target="#实验数据"><span class="header-section-number">2</span> 实验数据</a></li>
  <li><a href="#实验内容" id="toc-实验内容" class="nav-link" data-scroll-target="#实验内容"><span class="header-section-number">3</span> 实验内容</a>
  <ul>
  <li><a href="#knn和kd树的关系是什么什么叫基于kd树的knn算法" id="toc-knn和kd树的关系是什么什么叫基于kd树的knn算法" class="nav-link" data-scroll-target="#knn和kd树的关系是什么什么叫基于kd树的knn算法"><span class="header-section-number">3.1</span> KNN和KD树的关系是什么？什么叫基于KD树的KNN算法？</a></li>
  <li><a href="#基于sklearn的knn算法实现手写数字识别" id="toc-基于sklearn的knn算法实现手写数字识别" class="nav-link" data-scroll-target="#基于sklearn的knn算法实现手写数字识别"><span class="header-section-number">3.2</span> 基于sklearn的KNN算法实现手写数字识别</a></li>
  <li><a href="#自己实现kd树" id="toc-自己实现kd树" class="nav-link" data-scroll-target="#自己实现kd树"><span class="header-section-number">3.3</span> 自己实现KD树</a></li>
  <li><a href="#euclidean_distance" id="toc-euclidean_distance" class="nav-link" data-scroll-target="#euclidean_distance"><span class="header-section-number">3.4</span> euclidean_distance</a></li>
  <li><a href="#build_kd_tree" id="toc-build_kd_tree" class="nav-link" data-scroll-target="#build_kd_tree"><span class="header-section-number">3.5</span> build_kd_tree</a></li>
  <li><a href="#node" id="toc-node" class="nav-link" data-scroll-target="#node"><span class="header-section-number">3.6</span> Node</a></li>
  <li><a href="#knn_classifier" id="toc-knn_classifier" class="nav-link" data-scroll-target="#knn_classifier"><span class="header-section-number">3.7</span> knn_classifier</a></li>
  <li><a href="#search_kd_tree" id="toc-search_kd_tree" class="nav-link" data-scroll-target="#search_kd_tree"><span class="header-section-number">3.8</span> search_kd_tree</a></li>
  <li><a href="#超参数调优" id="toc-超参数调优" class="nav-link" data-scroll-target="#超参数调优"><span class="header-section-number">3.9</span> 超参数调优</a>
  <ul class="collapse">
  <li><a href="#什么是参数什么是超参数什么是元参数" id="toc-什么是参数什么是超参数什么是元参数" class="nav-link" data-scroll-target="#什么是参数什么是超参数什么是元参数"><span class="header-section-number">3.9.1</span> 什么是参数？什么是超参数？什么是元参数？</a></li>
  <li><a href="#什么是搜索" id="toc-什么是搜索" class="nav-link" data-scroll-target="#什么是搜索"><span class="header-section-number">3.9.2</span> 什么是搜索？</a></li>
  <li><a href="#knn和kd树有哪些元参数" id="toc-knn和kd树有哪些元参数" class="nav-link" data-scroll-target="#knn和kd树有哪些元参数"><span class="header-section-number">3.9.3</span> KNN和KD树有哪些元参数？</a></li>
  <li><a href="#具体要怎么调参呢" id="toc-具体要怎么调参呢" class="nav-link" data-scroll-target="#具体要怎么调参呢"><span class="header-section-number">3.9.4</span> 具体要怎么调参呢？</a></li>
  <li><a href="#代码实现调优" id="toc-代码实现调优" class="nav-link" data-scroll-target="#代码实现调优"><span class="header-section-number">3.9.5</span> 代码实现调优</a></li>
  </ul></li>
  <li><a href="#evaluate_knn" id="toc-evaluate_knn" class="nav-link" data-scroll-target="#evaluate_knn"><span class="header-section-number">3.10</span> evaluate_knn</a></li>
  <li><a href="#objective" id="toc-objective" class="nav-link" data-scroll-target="#objective"><span class="header-section-number">3.11</span> objective</a>
  <ul class="collapse">
  <li><a href="#调优结果分析" id="toc-调优结果分析" class="nav-link" data-scroll-target="#调优结果分析"><span class="header-section-number">3.11.1</span> 调优结果分析</a></li>
  </ul></li>
  <li><a href="#regplot" id="toc-regplot" class="nav-link" data-scroll-target="#regplot"><span class="header-section-number">3.12</span> regplot</a></li>
  <li><a href="#附加任务-尝试使不同的策略来构建-kd-树使得在分类阶段可以有更快的分类效率" id="toc-附加任务-尝试使不同的策略来构建-kd-树使得在分类阶段可以有更快的分类效率" class="nav-link" data-scroll-target="#附加任务-尝试使不同的策略来构建-kd-树使得在分类阶段可以有更快的分类效率"><span class="header-section-number">3.13</span> 附加任务: 尝试使⽤不同的策略来构建 KD 树，使得在分类阶段可以有更快的分类效率</a></li>
  <li><a href="#fast_build_kd_tree" id="toc-fast_build_kd_tree" class="nav-link" data-scroll-target="#fast_build_kd_tree"><span class="header-section-number">3.14</span> fast_build_kd_tree</a></li>
  <li><a href="#fast_search_kd_tree" id="toc-fast_search_kd_tree" class="nav-link" data-scroll-target="#fast_search_kd_tree"><span class="header-section-number">3.15</span> fast_search_kd_tree</a></li>
  <li><a href="#fastkdtree" id="toc-fastkdtree" class="nav-link" data-scroll-target="#fastkdtree"><span class="header-section-number">3.16</span> FastKDTree</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues/new" class="toc-action"><i class="bi bi-github"></i>反馈问题</a></li></ul></div><div class="quarto-alternate-formats"><h2>其他格式</h2><ul><li><a href="kd_tree.html.docx"><i class="bi bi-file-word"></i>MS Word</a></li><li><a href="kd_tree.html.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../coding_projects/index.html">coding_projects</a></li><li class="breadcrumb-item"><a href="../../coding_projects/P1_KNN/kd_tree.html">P1_KNN</a></li><li class="breadcrumb-item"><a href="../../coding_projects/P1_KNN/kd_tree.html">深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用</h1>
<p class="subtitle lead">大数据机器学习课程第一次实验项目</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">作者</div>
    <div class="quarto-title-meta-contents">
             <p>叶璨铭 (2024214500) ycm24@mails.tsinghua.edu.cn </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">发布于</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2024年10月21日星期一</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p><img src="../../thu_sigs_logo.png" alt="清华深研院-横" style="zoom:50%;"></p>
<p>代码复现说明</p>
<pre class="shell"><code>pip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git
pip install ray optuna seaborn matplotlib sklearn</code></pre>
<p>我们的代码导出为了python模块形式</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> thu_big_data_ml_tree <span class="im">import</span> FastKDTree</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="实验目的" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="实验目的"><span class="header-section-number">1</span> 实验目的</h2>
<blockquote class="blockquote">
<p>老师给我们的要求是 1. 完成 KD 树算法，并利⽤实现的算法完成数字识别任务 2. 对所建模型进行分析评判。</p>
</blockquote>
<p>我们不仅完成以上内容，还进行了 1. 参考谷歌调参手册，使用科学的实验设计来对KNN分类算法的元参数进行搜索，从而实现更高的分类精度。 2. 参考前沿论文，尝试修改KD树的训练策略，从而对KD树的推理速度进行改进。</p>
</section>
<section id="实验数据" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="实验数据"><span class="header-section-number">2</span> 实验数据</h2>
<blockquote class="blockquote">
<p>MNIST 数据库是由 Yann et. al.&nbsp;提供的⼿写数字数据库⽂件, 官网地址为 http://yann.lecun.com/exdb/mnist/。 主要包含了 60000 张的训练图像和 10000 张的测试图像</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 获取MNIST数据集,并抽样一部分数据以便后续的计算</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.random.choice(<span class="dv">70000</span>,<span class="dv">5000</span>,replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">"mnist_784"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> mnist.data.to_numpy(), mnist.target.to_numpy().astype(<span class="st">'int'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[idx]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[idx]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 划分数据集为训练集和测试集</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</blockquote>
<p>以上代码有几个小问题，我们需要改进一下 1. 由于网络环境问题，fetch_openml(“mnist_784”) 是无法跑通的，会卡死。 事实上，给sklearn贡献过代码的同学可能知道，sklearn还有一个load_digits数据集，这个数据集是sklearn CI（持续集成）测试用例的一部分。这个回归测试通过测试贡献者的新做的改进是否导致性能不如以前的版本，来决定是否接受更改。 因此，我们使用load_digits数据集代替mnist_784数据集来完成这个项目。</p>
<p>https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_digits.html</p>
<ol start="2" type="1">
<li>划分数据集时，train_test_split应当使用stratify参数，以确保每一类样本的比例相同。</li>
<li>import过多，应该只导入需要的模块。</li>
</ol>
<div id="cell-7" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dataset_dict <span class="op">=</span> load_digits()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>dataset_dict.keys()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X:np.array <span class="op">=</span> dataset_dict[<span class="st">'data'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y:np.array <span class="op">=</span> dataset_dict[<span class="st">'target'</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X.shape, X.dtype, y.shape, y.dtype</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>((1797, 64), dtype('float64'), (1797,), dtype('int64'))</code></pre>
</div>
</div>
<p>划分数据集为训练集和测试集</p>
<div id="cell-10" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                                    stratify<span class="op">=</span>y)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(X_train), <span class="bu">len</span>(X_test)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(1437, 360)</code></pre>
</div>
</div>
</section>
<section id="实验内容" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="实验内容"><span class="header-section-number">3</span> 实验内容</h2>
<section id="knn和kd树的关系是什么什么叫基于kd树的knn算法" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="knn和kd树的关系是什么什么叫基于kd树的knn算法"><span class="header-section-number">3.1</span> KNN和KD树的关系是什么？什么叫基于KD树的KNN算法？</h3>
<p>在我们开始实验内容之前，有必要澄清这一理论上的概念。</p>
<p>KNN（K-Nearest Neighbor）算法是一种基本的机器学习算法，既可以用于分类也可以用于回归。 对于新的一个测试样本（未知类别或标签值）来说，它和训练集中每一个样本都有距离，从而存在离测试样本最近的K个样本（当然训练集要大于K啦），然后根据这些样本的已知标签来决定测试样本的标签。</p>
<blockquote class="blockquote">
<p>我今天学习的《自然辩证法课》上正好讲到一个哲学概念叫做“类比推理”与“演绎推理”。古希腊的哲学家们则发展了形式逻辑，比如亚里士多德的三段论，我们在《数理逻辑导论》课上还了解了罗素、哥德尔等人对整套逻辑的进一步发展。而中国古代的先贤很喜欢类比推理，比如孟子要提倡“舍生而取义者也”，偏偏不和你论证为什么要舍生取义（后文也有一点论证），而是先跟你说他观察到了“二者不可得兼，舍鱼而取熊掌者也。”，然后他认为这两个事情很像，然后告诉你所以要舍生取义；又比如孟子想要说“天将降大任于是人也，必先苦其心志”，他先给了你一个训练集，说好多“降大任”的“人”都是被“苦其心志的”。这个推理看起来很扯，实际上也是也是有一定的统计意义的。</p>
</blockquote>
<p>而KD树（k-dimensional tree）是一种用于组织k维空间数据的树形数据结构，它是一种特殊的二叉树。KD树将k维空间进行分割，每个节点代表一个k维超矩形区域。KD树的主要作用是在高维空间中快速地进行最近邻查找，它能够显著减少在KNN算法中计算所有训练样本与测试样本之间距离的需求，从而提高效率。</p>
<p>KNN不一定要使用KD树来进行近邻搜索，事实上还有其他更加高效的数据结构，比如Ball Tree。如果我们说默认的KNN是用暴力方法计算所有距离的逐一比较的话，我们可以说KD树不是KNN算法的一部分，而是KNN算法的一个优化工具，用于在高维空间中快速查找最近邻。</p>
</section>
<section id="基于sklearn的knn算法实现手写数字识别" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="基于sklearn的knn算法实现手写数字识别"><span class="header-section-number">3.2</span> 基于sklearn的KNN算法实现手写数字识别</h3>
<div id="cell-13" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建KNeighborsClassifier模型，使用kd树作为搜索算法</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">3</span>, algorithm<span class="op">=</span><span class="st">'kd_tree'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 在训练集上训练模型</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 在测试集上进行预测</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 评估模型性能</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"KNN Accuracy: </span><span class="sc">{</span>accuracy <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>KNN Accuracy: 98.61%</code></pre>
</div>
</div>
</section>
<section id="自己实现kd树" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="自己实现kd树"><span class="header-section-number">3.3</span> 自己实现KD树</h3>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L27" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="euclidean_distance" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="euclidean_distance"><span class="header-section-number">3.4</span> euclidean_distance</h3>
<blockquote class="blockquote">
<pre><code> euclidean_distance (x1, x2)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L17" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="build_kd_tree" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="build_kd_tree"><span class="header-section-number">3.5</span> build_kd_tree</h3>
<blockquote class="blockquote">
<pre><code> build_kd_tree (X, depth=0)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L9" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="node" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="node"><span class="header-section-number">3.6</span> Node</h3>
<blockquote class="blockquote">
<pre><code> Node (data, left=None, right=None)</code></pre>
</blockquote>
<p><em>Initialize self. See help(type(self)) for accurate signature.</em></p>
<div id="cell-18" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 这里我们需要注意使用PriorityQueue的一个坑点，same priority 下 会崩溃； PriorityQueue文档没写，heapq写了</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://docs.python.org/3/library/heapq.html</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TestNode:</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, point):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.point <span class="op">=</span> point</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>test1 <span class="op">=</span> [</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">13.30413469565007</span>, <span class="fl">1.2</span>),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">9.327379053088816</span>, <span class="fl">0.0</span>),</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">13.30413469565007</span>, <span class="fl">1.4</span>),</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>test2 <span class="op">=</span> [</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">13.30413469565007</span>, TestNode(<span class="fl">1.2</span>)),</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">9.327379053088816</span>, TestNode(<span class="fl">0.0</span>)),</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="fl">13.30413469565007</span>, TestNode(<span class="fl">1.4</span>)),</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>test3 <span class="op">=</span> [</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span>, TestNode(<span class="fl">1.2</span>)),</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span>, TestNode(<span class="fl">0.0</span>)),</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">2</span>, TestNode(<span class="fl">1.4</span>)),</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>test_pq <span class="op">=</span> PriorityQueue()</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> test1:</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    test_pq.put(t)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_pq.get())</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>test_pq <span class="op">=</span> PriorityQueue()</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> test3:</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    test_pq.put(t)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_pq.get())</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 注意这种情况下报错</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="co"># for t in test2:</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co">#     test_pq.put(t)</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="co"># print(test_pq.get())</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(-13.30413469565007, 1.2)
(0, &lt;__main__.TestNode object&gt;)</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L100" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="knn_classifier" class="level3" data-number="3.7">
<h3 data-number="3.7" class="anchored" data-anchor-id="knn_classifier"><span class="header-section-number">3.7</span> knn_classifier</h3>
<blockquote class="blockquote">
<pre><code> knn_classifier (X_train, y_train, X_test, k=3)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L35" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="search_kd_tree" class="level3" data-number="3.8">
<h3 data-number="3.8" class="anchored" data-anchor-id="search_kd_tree"><span class="header-section-number">3.8</span> search_kd_tree</h3>
<blockquote class="blockquote">
<pre><code> search_kd_tree (tree, target, k=3)</code></pre>
</blockquote>
<div id="cell-21" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 构建KD树</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>kd_tree <span class="op">=</span> build_kd_tree(X_train)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-22" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用KNN算法进行分类</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>k_neighbors <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn_classifier(X_train, y_train, X_test, k_neighbors)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 评估分类性能</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"KNN Accuracy: </span><span class="sc">{</span>accuracy <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>KNN Accuracy: 98.61%</code></pre>
</div>
</div>
</section>
<section id="超参数调优" class="level3" data-number="3.9">
<h3 data-number="3.9" class="anchored" data-anchor-id="超参数调优"><span class="header-section-number">3.9</span> 超参数调优</h3>
<p>实验题目要求我们对 knn 进⾏超参数的搜索。那么什么是超参数搜索呢？为此我们需要理解两个概念——超参数和搜索。</p>
<section id="什么是参数什么是超参数什么是元参数" class="level4" data-number="3.9.1">
<h4 data-number="3.9.1" class="anchored" data-anchor-id="什么是参数什么是超参数什么是元参数"><span class="header-section-number">3.9.1</span> 什么是参数？什么是超参数？什么是元参数？</h4>
<p>在大数据分析中，我们往往不知道数据的总体，只能获得数据的一个采样。然而我们对数据的总体是什么分布非常感兴趣，这些未知的分布，我们假设可能是由一些参数来决定的，我们需要根据采样出来的数据对总体的参数进行参数估计（Parameter Estimation）。比如说总体是高斯分布，那么高斯分布的均值和方差就是参数。</p>
<p>刚才我们说了参数是什么，那么什么是超参数呢？参数估计我们通常会用极大似然估计方法，但是相比于贝叶斯参数估计来说有一定的局限性。在贝叶斯机器学习中，我们认为参数本身也是有一个概率分布的，而不是确定的值，而描述参数分布的参数，我们称之为超参数。当然，我们可以认为超参数也有其分布，那么就有对应的超超参数，这种多层嵌套的结构称为贝叶斯网络。</p>
<p>对应到机器学习和深度学习中，参数是指参数化模型的权重。但是我们没有在使用贝叶斯估计，并没有说这些模型权重具有一定的分布，那么超参数是怎么一回事呢？事实上，根据谷歌团队提出的《深度学习调优指南》<span class="citation" data-cites="tuningplaybookgithub">(<a href="#ref-tuningplaybookgithub" role="doc-biblioref">Godbole 等 2023</a>)</span>，深度学习社区错误地把学习率、批处理大小、正则化系数等参数叫做超参数，这是错误的。他们确实决定了模型的假设空间的不同，决定了最终的性能，而且在模型训练过程中不发生变化，而是决定了训练过程，但是他们本身并不是先验分布的参数，严格来说不应该叫做超参数，应该叫做元参数。</p>
</section>
<section id="什么是搜索" class="level4" data-number="3.9.2">
<h4 data-number="3.9.2" class="anchored" data-anchor-id="什么是搜索"><span class="header-section-number">3.9.2</span> 什么是搜索？</h4>
<p>搜索是人工智能中的重要的方法<span class="citation" data-cites="Russell_Norvig_2016">(<a href="#ref-Russell_Norvig_2016" role="doc-biblioref">Russell 和 Norvig 2016</a>)</span>。搜索包括约束可满足问题和最优化问题，以及带有约束的优化问题。 这里我们说的超参数优化，一般来说是带有约束的优化问题。 其中约束是指，有些超参数组合如果错误地选择，会导致机器学习系统崩溃，或者算法无法收敛。</p>
<p>然而这些约束我们很可能是不知道的，需要调参算法本身尝试。 有时候我们发现的约束可能暗示着代码存在错误，或者深度学习模型本身的优化过程不够稳定，如果是后者，可以通过Gradient Clip, 降低学习率等方法来缓解。</p>
</section>
<section id="knn和kd树有哪些元参数" class="level4" data-number="3.9.3">
<h4 data-number="3.9.3" class="anchored" data-anchor-id="knn和kd树有哪些元参数"><span class="header-section-number">3.9.3</span> KNN和KD树有哪些元参数？</h4>
<p>上文我们辨析了KNN和KD树的关系，即是否选用KD树作为KNN的近邻搜索算法，本身是KNN的一个元参数，KNN也可以选择Ball Tree、Brute Force等其他近邻搜索算法。</p>
<p>KD树本身也有一些元参数，比如分割方式、节点的选择方式等，这些元参数会影响KD树的构建和搜索的系统性能（时间复杂度、空间复杂度），但是不会影响到机器学习的性能（分类准确率、ROC-AUC等指标）。因为不影响机器学习的性能，在本节我们不讨论KD树的元参数如何调优。我们会在下一节，附加题中，讨论不同的KD树构建方式对搜索速度的影响。</p>
<p>那么KNN作为一个机器学习算法，有哪些元参数需要调优呢？参考sklearn的KNeighborsClassifier类的参数说明，我们可以看到以下参数</p>
<div id="cell-26" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># help(KNeighborsClassifier)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用 ipython的 ? 可以更好地看到 函数和类的docstring信息。</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>KNeighborsClassifier?</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Init signature:
KNeighborsClassifier(
    n_neighbors=5,
    *,
    weights='uniform',
    algorithm='auto',
    leaf_size=30,
    p=2,
    metric='minkowski',
    metric_params=None,
    n_jobs=None,
)
Docstring:     
Classifier implementing the k-nearest neighbors vote.

Read more in the :ref:`User Guide &lt;classification&gt;`.

Parameters
----------
n_neighbors : int, default=5
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : {'uniform', 'distance'}, callable or None, default='uniform'
    Weight function used in prediction.  Possible values:

    - 'uniform' : uniform weights.  All points in each neighborhood
      are weighted equally.
    - 'distance' : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Refer to the example entitled
    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`
    showing the impact of the `weights` parameter on the decision
    boundary.

algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'
    Algorithm used to compute the nearest neighbors:

    - 'ball_tree' will use :class:`BallTree`
    - 'kd_tree' will use :class:`KDTree`
    - 'brute' will use a brute-force search.
    - 'auto' will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is equivalent
    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.
    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected
    to be positive.

metric : str or callable, default='minkowski'
    Metric to use for distance computation. Default is "minkowski", which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is "precomputed", X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only "nonzero" elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy's metrics, but is less
    efficient than passing the metric name as a string.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.
    Doesn't affect :meth:`fit` method.

Attributes
----------
classes_ : array of shape (n_classes,)
    Class labels known to the classifier

effective_metric_ : str or callble
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to
    'minkowski' and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    'minkowski'.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

outputs_2d_ : bool
    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

See Also
--------
RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.
KNeighborsRegressor: Regression based on k-nearest neighbors.
RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.
NearestNeighbors: Unsupervised learner for implementing neighbor searches.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances
   but different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)
&gt;&gt;&gt; neigh.fit(X, y)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(neigh.predict([[1.1]]))
[0]
&gt;&gt;&gt; print(neigh.predict_proba([[0.9]]))
[[0.666... 0.333...]]
File:           ~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/neighbors/_classification.py
Type:           ABCMeta
Subclasses:     </code></pre>
</div>
</div>
<p>其中这几个参数是和分类准确率有关的 - <code>n_neighbors</code>, 也就是k - <code>weights</code>，检索出来的k个点用来决策，这些点一样重要吗？ - 我们李航书学的基础版本是uniform，而distance方法不一样在于 - 每一个点的投票权是距离的-1次方。（哈哈为什么不是像万有引力那样是-2次方） - <code>p</code>和<code>metric</code>和<code>metric_params</code>, 要怎么计算距离？</p>
<p>而 <code>algorithm</code> <code>leaf_size</code> <code>n_jobs</code> 三个参数暂时和我们无关。</p>
<div id="cell-28" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> distance_metrics</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>distance_metrics().keys()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>dict_keys(['cityblock', 'cosine', 'euclidean', 'haversine', 'l2', 'l1', 'manhattan', 'precomputed', 'nan_euclidean'])</code></pre>
</div>
</div>
</section>
<section id="具体要怎么调参呢" class="level4" data-number="3.9.4">
<h4 data-number="3.9.4" class="anchored" data-anchor-id="具体要怎么调参呢"><span class="header-section-number">3.9.4</span> 具体要怎么调参呢？</h4>
<p>如果我们就把调参问题当做搜索问题，那么它就是一个无梯度黑盒最优化问题。对于这类问题，最平凡（trivial）的搜索方法是全盘遍历（grid search），然而当搜索空间太大的时候，这就不是很高效了。一些基础的改进是贪心算法和随机化搜索方法，比如爬山法、随机采样法、模拟退火法等<span class="citation" data-cites="Russell_Norvig_2016">(<a href="#ref-Russell_Norvig_2016" role="doc-biblioref">Russell 和 Norvig 2016</a>)</span>。而要想得到最先进（SOTA）的性能，演化计算和贝叶斯优化是两个最好的方法，也是目前人工智能仍然活跃的科研方向<span class="citation" data-cites="Russell_Norvig_2016">(<a href="#ref-Russell_Norvig_2016" role="doc-biblioref">Russell 和 Norvig 2016</a>)</span>。</p>
<p>然而调参问题并不完全是搜索问题。Google的《深度学习调优指南》<span class="citation" data-cites="tuningplaybookgithub">(<a href="#ref-tuningplaybookgithub" role="doc-biblioref">Godbole 等 2023</a>)</span>指出，调参是一个“探索与利用”（exploration and exploitation）的过程。我的理解是，在我们做深度学习研究的时候，我们其实更想知道，我们的方法对于那些超参数敏感，在其他方法也调到最优超参的情况下我的方法是否仍然显著优于其他方法，而不只是说我的方法在单单一个超参数上优于其他方法（选择“我的方法”还是“其他近期SOTA方法”就是一个离散型目标元参数）。因此，我们需要在调参的过程中理解不同的参数对于结果的影响。这其实也是作为科学家和研究者我们做科学实验的过程。调参的实质不是乱试，而是“控制变量”，参数就是自变量和无关变量，评价指标就是因变量。不过，与我们高中生物课学习的“控制变量法”稍有不同，无关变量不一定是控制相等，在计算资源充足时，无关变量应该控制到最优，所以这里有优化问题。</p>
<p>对于具体的调参算法和代码而言，我们当然可以用sklearn默认提供的GridSearchCV、RandomizedSearchCV等方法，我猜做这个作业的大部分同学用的是这两个。但是刚才我们也说了，GridSearch代价太高，而RandomizedSearchCV以及贝叶斯优化、演化计算忙于“利用”，而没有进行单一变量原则，无法通过科学实验“探索”出我们想获得的insight。根据Google的建议，在探索阶段最适合的算法其实是准随机搜索算法（quasi random search）。</p>
<p>因此，我们遵循google指南，使用Optuna+Ray Tune中的Quasi Random Search实现来进行调参。</p>
<p>此外，我还实现了一个“学生实验算法”，这个算法从优化上来说是一种交替优化（alternating optimization）或者叫做多阶段优化（multi-stage optimization）的方法，即先固定一个超参数，然后在这个超参数下进行优化，再固定另一个超参数，再进行优化，以此类推，直到所有超参数都优化完毕。这个算法的好处是遵循了单一变量原则和无关变量控制相等原则，可以探索出很多结论。我把这个算法写成了一个pypi库，可见<a href="https://github.com/2catycm/CosmicSelection.git">github连接</a>。</p>
<p>在这里我们也做一个科学实验，实验假设是在其他参数最优时，使用”distance”的KNN比普通的”uniform”KNN的效果好。 这样我们有一个研究的目标，相当于我们扮演那个提出”distance”方法的科学家，要和其他人的方法做比较才能发论文。</p>
</section>
<section id="代码实现调优" class="level4" data-number="3.9.5">
<h4 data-number="3.9.5" class="anchored" data-anchor-id="代码实现调优"><span class="header-section-number">3.9.5</span> 代码实现调优</h4>
<p>首先我们需要定义KNN元参数的分布空间</p>
<p>然后我们定义评价函数</p>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L128" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
</section>
<section id="evaluate_knn" class="level3" data-number="3.10">
<h3 data-number="3.10" class="anchored" data-anchor-id="evaluate_knn"><span class="header-section-number">3.10</span> evaluate_knn</h3>
<blockquote class="blockquote">
<pre><code> evaluate_knn (weights:str, n_neighbors:int, distance_metric:str,
               random_seed:int=42)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L161" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="objective" class="level3" data-number="3.11">
<h3 data-number="3.11" class="anchored" data-anchor-id="objective"><span class="header-section-number">3.11</span> objective</h3>
<blockquote class="blockquote">
<pre><code> objective (meta_parameters)</code></pre>
</blockquote>
<p>接下来我们要定义使用的搜索算法。</p>
<div id="cell-35" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search <span class="im">import</span> ConcurrencyLimiter</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.search.optuna <span class="im">import</span> OptunaSearch</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> optuna.samplers <span class="im">import</span> QMCSampler</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># quasi random search</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> QMCSampler()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>algo <span class="op">=</span> OptunaSearch(sampler<span class="op">=</span>sampler)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>algo <span class="op">=</span> ConcurrencyLimiter(algo, max_concurrent<span class="op">=</span><span class="dv">4</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.
  sampler = QMCSampler()</code></pre>
</div>
</div>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>tuner <span class="op">=</span> tune.Tuner(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    objective,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    tune_config<span class="op">=</span>tune.TuneConfig(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span><span class="st">"mean_score"</span>,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">"max"</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        num_samples<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># num_samples=3,</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        search_alg<span class="op">=</span>algo,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    param_space<span class="op">=</span>search_space,</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>results:tune.ResultGrid  <span class="op">=</span> tuner.fit()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="cell-37" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>experiment_dir <span class="op">=</span> <span class="st">"/home/ycm/ray_results/objective_2024-10-22_23-27-35"</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>restored_tuner <span class="op">=</span> tune.Tuner.restore(experiment_dir, objective)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> restored_tuner.get_results()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-38" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>results.errors</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[]</code></pre>
</div>
</div>
<section id="调优结果分析" class="level4" data-number="3.11.1">
<h4 data-number="3.11.1" class="anchored" data-anchor-id="调优结果分析"><span class="header-section-number">3.11.1</span> 调优结果分析</h4>
<div id="cell-40" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.train <span class="im">import</span> Result</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>best_result:Result <span class="op">=</span> results.get_best_result()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>{k:v <span class="cf">for</span> k,v <span class="kw">in</span> best_result.metrics.items() <span class="cf">if</span> <span class="st">"score"</span> <span class="kw">in</span> k}, best_result.config</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>({'mean_score': 0.9860796554394116,
  'std_score': 0.003124647521844644,
  'score_0': 0.9861111111111112,
  'score_1': 0.9895833333333334,
  'score_2': 0.9825783972125436,
  'score_3': 0.9825783972125436,
  'score_4': 0.9895470383275261},
 {'weights': 'distance', 'n_neighbors': 1, 'distance_metric': 'euclidean'})</code></pre>
</div>
</div>
<div id="cell-41" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> results.get_dataframe(</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    filter_metric<span class="op">=</span><span class="st">"mean_score"</span>, filter_mode<span class="op">=</span><span class="st">"max"</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_score</th>
<th data-quarto-table-cell-role="th">std_score</th>
<th data-quarto-table-cell-role="th">score_0</th>
<th data-quarto-table-cell-role="th">score_1</th>
<th data-quarto-table-cell-role="th">score_2</th>
<th data-quarto-table-cell-role="th">score_3</th>
<th data-quarto-table-cell-role="th">score_4</th>
<th data-quarto-table-cell-role="th">timestamp</th>
<th data-quarto-table-cell-role="th">checkpoint_dir_name</th>
<th data-quarto-table-cell-role="th">done</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">time_total_s</th>
<th data-quarto-table-cell-role="th">pid</th>
<th data-quarto-table-cell-role="th">hostname</th>
<th data-quarto-table-cell-role="th">node_ip</th>
<th data-quarto-table-cell-role="th">time_since_restore</th>
<th data-quarto-table-cell-role="th">iterations_since_restore</th>
<th data-quarto-table-cell-role="th">config/weights</th>
<th data-quarto-table-cell-role="th">config/n_neighbors</th>
<th data-quarto-table-cell-role="th">config/distance_metric</th>
<th data-quarto-table-cell-role="th">logdir</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.978421</td>
<td>0.008356</td>
<td>0.972222</td>
<td>0.993056</td>
<td>0.972125</td>
<td>0.972125</td>
<td>0.982578</td>
<td>1729610862</td>
<td>None</td>
<td>False</td>
<td>...</td>
<td>0.142350</td>
<td>302368</td>
<td>amax</td>
<td>10.103.10.61</td>
<td>0.142350</td>
<td>1</td>
<td>uniform</td>
<td>8</td>
<td>l2</td>
<td>9db3a177</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.972854</td>
<td>0.006012</td>
<td>0.972222</td>
<td>0.982639</td>
<td>0.965157</td>
<td>0.968641</td>
<td>0.975610</td>
<td>1729610871</td>
<td>None</td>
<td>False</td>
<td>...</td>
<td>0.249111</td>
<td>303174</td>
<td>amax</td>
<td>10.103.10.61</td>
<td>0.249111</td>
<td>1</td>
<td>uniform</td>
<td>15</td>
<td>nan_euclidean</td>
<td>ad504238</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.978424</td>
<td>0.007435</td>
<td>0.972222</td>
<td>0.989583</td>
<td>0.968641</td>
<td>0.982578</td>
<td>0.979094</td>
<td>1729610864</td>
<td>None</td>
<td>False</td>
<td>...</td>
<td>0.072539</td>
<td>302745</td>
<td>amax</td>
<td>10.103.10.61</td>
<td>0.072539</td>
<td>1</td>
<td>distance</td>
<td>17</td>
<td>cosine</td>
<td>c0464454</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.986080</td>
<td>0.003125</td>
<td>0.986111</td>
<td>0.989583</td>
<td>0.982578</td>
<td>0.982578</td>
<td>0.989547</td>
<td>1729610866</td>
<td>None</td>
<td>False</td>
<td>...</td>
<td>0.051633</td>
<td>302934</td>
<td>amax</td>
<td>10.103.10.61</td>
<td>0.051633</td>
<td>1</td>
<td>distance</td>
<td>1</td>
<td>euclidean</td>
<td>5cc5dc31</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.974937</td>
<td>0.009465</td>
<td>0.975694</td>
<td>0.989583</td>
<td>0.961672</td>
<td>0.968641</td>
<td>0.979094</td>
<td>1729610869</td>
<td>None</td>
<td>False</td>
<td>...</td>
<td>0.401711</td>
<td>303051</td>
<td>amax</td>
<td>10.103.10.61</td>
<td>0.401711</td>
<td>1</td>
<td>uniform</td>
<td>10</td>
<td>nan_euclidean</td>
<td>8bd53b66</td>
</tr>
</tbody>
</table>

<p>5 rows × 24 columns</p>
</div>
</div>
</div>
<div id="cell-42" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>intersted_cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> df.columns <span class="cf">if</span> c.startswith(<span class="st">"config"</span>) <span class="kw">or</span> <span class="st">"score"</span> <span class="kw">in</span> c]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>dfi <span class="op">=</span> df[intersted_cols]</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>dfi.head()</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_score</th>
<th data-quarto-table-cell-role="th">std_score</th>
<th data-quarto-table-cell-role="th">score_0</th>
<th data-quarto-table-cell-role="th">score_1</th>
<th data-quarto-table-cell-role="th">score_2</th>
<th data-quarto-table-cell-role="th">score_3</th>
<th data-quarto-table-cell-role="th">score_4</th>
<th data-quarto-table-cell-role="th">config/weights</th>
<th data-quarto-table-cell-role="th">config/n_neighbors</th>
<th data-quarto-table-cell-role="th">config/distance_metric</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.978421</td>
<td>0.008356</td>
<td>0.972222</td>
<td>0.993056</td>
<td>0.972125</td>
<td>0.972125</td>
<td>0.982578</td>
<td>uniform</td>
<td>8</td>
<td>l2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.972854</td>
<td>0.006012</td>
<td>0.972222</td>
<td>0.982639</td>
<td>0.965157</td>
<td>0.968641</td>
<td>0.975610</td>
<td>uniform</td>
<td>15</td>
<td>nan_euclidean</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.978424</td>
<td>0.007435</td>
<td>0.972222</td>
<td>0.989583</td>
<td>0.968641</td>
<td>0.982578</td>
<td>0.979094</td>
<td>distance</td>
<td>17</td>
<td>cosine</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.986080</td>
<td>0.003125</td>
<td>0.986111</td>
<td>0.989583</td>
<td>0.982578</td>
<td>0.982578</td>
<td>0.989547</td>
<td>distance</td>
<td>1</td>
<td>euclidean</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.974937</td>
<td>0.009465</td>
<td>0.975694</td>
<td>0.989583</td>
<td>0.961672</td>
<td>0.968641</td>
<td>0.979094</td>
<td>uniform</td>
<td>10</td>
<td>nan_euclidean</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>首先我们从整体上来看两个方法（distance和uniform）的性能差异。</p>
<div id="cell-44" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-45" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>sns.boxplot(data<span class="op">=</span>dfi, x<span class="op">=</span><span class="st">'config/weights'</span>, y<span class="op">=</span><span class="st">'mean_score'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>dfi.plot(x<span class="op">=</span><span class="st">'config/weights'</span>, y<span class="op">=</span><span class="st">'mean_score'</span>, ax<span class="op">=</span>ax, kind<span class="op">=</span><span class="st">'scatter'</span>, c<span class="op">=</span><span class="st">'red'</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kd_tree_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img" alt="每一个红点是一次实验结果，平均准确率是每一次实验中五折交叉验证的平均值。"></p>
<figcaption>uniform与distance方法平均准确率箱线图对比</figcaption>
</figure>
</div>
</div>
</div>
<p>以上的结果并没有控制变量，是直接进行了一个统计。相关性不代表因果性，所以上面的结果仅仅代表了在我们调参采样过程中，自变量“weights”与因变量“mean_score”的一定的相关性。 如果我们不知道每一次实验具体的其他的无关变量，上面的图我们也可以做一个合理的假设检验（验证我们的实验假设的零假设是否要拒绝！）。</p>
<p>根据论文<span class="citation" data-cites="Demšar_2006">(<a href="#ref-Demšar_2006" role="doc-biblioref">Demšar 2006</a>)</span>，在机器学习中应该使用mann-whitney U检验和Wilcoxon signed-rank检验，因为这两个检验对样本的分布没有假定，而其他的一些检验比如t检验不太适用与样本分布不符合假设分布的情况。其中对于 “不知道每一次实验的其他无关变量是什么”的情况，也就是说自变量取“distance”和“uniform”得到的两列样本是独立（independent）的时候，应当使用mann-whitney U检验。</p>
<div id="cell-47" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> mannwhitneyu</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>grouped <span class="op">=</span> dfi.groupby(<span class="st">'config/weights'</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>group_mean_scores <span class="op">=</span> {name:group[<span class="st">'mean_score'</span>] <span class="cf">for</span> name, group <span class="kw">in</span> grouped}</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>scores_for_distance <span class="op">=</span> group_mean_scores[<span class="st">'distance'</span>]</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>scores_for_uniform <span class="op">=</span> group_mean_scores[<span class="st">'uniform'</span>]</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>u, p <span class="op">=</span> mannwhitneyu(scores_for_distance, scores_for_uniform, </span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                    alternative<span class="op">=</span><span class="st">'greater'</span> <span class="co"># 实验备则假设，distance 方法更好</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Reject null hypothesis! `distance` is significantly better than `uniform`"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reject null hypothesis! `distance` is significantly better than `uniform`</code></pre>
</div>
</div>
<p>刚才我们只是整体分析。 接下来我们要寻找控制其他变量最优时，两个方法各自最优的参数是什么？以及这两个方法对哪些超参数比较敏感？</p>
<p>我们先回答第一个问题，我们从刚才的表格筛选一下。</p>
<div id="cell-50" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>max_rows <span class="op">=</span> dfi.loc[df.groupby(<span class="st">'config/weights'</span>)[<span class="st">'mean_score'</span>].idxmax()]</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>max_rows</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_score</th>
<th data-quarto-table-cell-role="th">std_score</th>
<th data-quarto-table-cell-role="th">score_0</th>
<th data-quarto-table-cell-role="th">score_1</th>
<th data-quarto-table-cell-role="th">score_2</th>
<th data-quarto-table-cell-role="th">score_3</th>
<th data-quarto-table-cell-role="th">score_4</th>
<th data-quarto-table-cell-role="th">config/weights</th>
<th data-quarto-table-cell-role="th">config/n_neighbors</th>
<th data-quarto-table-cell-role="th">config/distance_metric</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.98608</td>
<td>0.003125</td>
<td>0.986111</td>
<td>0.989583</td>
<td>0.982578</td>
<td>0.982578</td>
<td>0.989547</td>
<td>distance</td>
<td>1</td>
<td>euclidean</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">36</td>
<td>0.98608</td>
<td>0.003125</td>
<td>0.986111</td>
<td>0.989583</td>
<td>0.982578</td>
<td>0.982578</td>
<td>0.989547</td>
<td>uniform</td>
<td>1</td>
<td>l2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>这里我们可以对5次实验的结果进行统计分析，由于这五次实验是相关的，即这五次实验每一次用的同一个fold去训练，所以这里我们不应当用mann-whitney U检验，这一次我们要用Wilcoxon signed-rank检验。</p>
<div id="cell-52" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> wilcoxon</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-53" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>scores_for_distance <span class="op">=</span> [v <span class="cf">for</span> k, v <span class="kw">in</span> max_rows.iloc[<span class="dv">0</span>].to_dict().items() <span class="cf">if</span> k.startswith(<span class="st">'score_'</span>)]</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>scores_for_uniform <span class="op">=</span> [v <span class="cf">for</span> k, v <span class="kw">in</span> max_rows.iloc[<span class="dv">1</span>].to_dict().items() <span class="cf">if</span> k.startswith(<span class="st">'score_'</span>)]</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>u, p <span class="op">=</span> wilcoxon(scores_for_distance, scores_for_uniform, </span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>                zero_method<span class="op">=</span><span class="st">'zsplit'</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>                    alternative<span class="op">=</span><span class="st">'greater'</span> <span class="co"># 实验备则假设，distance 方法更好</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p<span class="op">&gt;</span> <span class="fl">0.05</span>:</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Null hypothesis cannot be rejected, so I have to accept it. "</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Null hypothesis cannot be rejected, so I have to accept it. </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.
  res = hypotest_fun_out(*samples, **kwds)
/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Sample size too small for normal approximation.
  res = hypotest_fun_out(*samples, **kwds)</code></pre>
</div>
</div>
<p>原来，当我们控制无关变量最优时，两个方法的性能能达到一致。具体来说，这里种找到的最优超参数正好是让knn的k为1，所以这个情况下distance方法和n_neighbors方法没有区别。按照谷歌调参手册的科研方法，对于这个数据集来说就无法说明这两个方法的优劣了。</p>
<p>然而，我个人认为，一个方法之所以被学术界认为有价值，在于这个方法能被其他人follow和cite。什么样的方法能对其他人的工作有帮助，什么样的方法就有价值。形式化一点来说，对 “其他人的工作”这个随机分布而言，我们的方法“应用上去之后，比不应用我们的方法或者使用其他方法更好”这个随机变量的期望值就是我们做科研应该追求的价值。</p>
<p>需要注意的是，“其他人的工作”由于他们计算资源以及研究者认知的局限，是比较不可能为你的方法调整整个实验流程其他的元参数或者说无关变量的。换句话说，如果你的方法需要其他人为你的方法来调参才能表现良好，那么你的方法的价值其实也是比较有限的。</p>
<p>在这里我们就遇到这个情况，在大部分随机的无关变量上，我们看到假设检验拒绝了零假设，说明distance方法期望地来说是对其他研究人员有帮助的，然而当调参到最优时，他们又都能达到最好。</p>
<p>现在我们回答第二个问题，这两个方法分别对其他元参数的敏感性如何? 首先分析对n_neighbors的敏感性。这个是通过quasi random search采样的。</p>
<div id="cell-56" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L171" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
</section>
<section id="regplot" class="level3" data-number="3.12">
<h3 data-number="3.12" class="anchored" data-anchor-id="regplot"><span class="header-section-number">3.12</span> regplot</h3>
<blockquote class="blockquote">
<pre><code> regplot (*args, line_kws=None, marker=None, scatter_kws=None, **kwargs)</code></pre>
</blockquote>
<div id="cell-fig-n_neighbors" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> plt.figure()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> f.add_subplot(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>line_dict <span class="op">=</span> {}</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, group <span class="kw">in</span> grouped:</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.scatter(group['config/n_neighbors'], group['mean_score'], label=name)</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># p = sns.regplot(x='config/n_neighbors', y='mean_score', data=dfi, fit_reg=True, ax=ax)</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    k, b <span class="op">=</span> regplot(x<span class="op">=</span><span class="st">'config/n_neighbors'</span>, y<span class="op">=</span><span class="st">'mean_score'</span>, data<span class="op">=</span>group, label<span class="op">=</span>name, fit_reg<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    line_dict[name] <span class="op">=</span> (k, b)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co"># sns.lmplot(x='config/n_neighbors', y='mean_score', data=dfi, hue="config/weights", fit_reg=True)</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用整数x坐标轴</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">21</span>))</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.xlabel('n_neighbors')</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.ylabel('mean_score')</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.title("Relationship between n_neighbors and mean_score")</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="co"># p.get_lines()[0].get_xdata(), p.get_lines()[0].get_ydata()</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, (k, b) <span class="kw">in</span> line_dict.items():</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"For </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">, the regression line is y = </span><span class="sc">{</span>k<span class="sc">:.2e}</span><span class="ss">x + </span><span class="sc">{</span>b<span class="sc">:.2e}</span><span class="ss">"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-n_neighbors" class="quarto-float quarto-figure quarto-figure-center anchored" alt="在图中我们画出了拟合的直线以及之前的95%置信区间。">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-n_neighbors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="kd_tree_files/figure-html/fig-n_neighbors-output-1.png" class="img-fluid figure-img" alt="在图中我们画出了拟合的直线以及之前的95%置信区间。">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-n_neighbors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
图&nbsp;1: Relationship between n_neighbors and mean_score
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For distance, the regression line is y = -9.18e-04x + 9.87e-01
For uniform, the regression line is y = -9.86e-04x + 9.84e-01</code></pre>
</div>
</div>
<p>从图 <a href="#fig-n_neighbors" class="quarto-xref">图&nbsp;1</a> 中可以看出，在数字识别问题上，无论是distance方法还是uniform方法，都是neighbors数量越多，精度反而越低。</p>
<p>从斜率上来看可能会以为这个问题很小，只是稍微减少了精度，但是从视觉上好像确实下降地很明显。我们为了从统计上说明清楚到底下降地显不显著，可以进一步通过皮尔森相关系数以及斯皮尔曼相关系数对应的假设检验来验证这个问题。</p>
<div id="cell-60" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr, spearmanr</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-61" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_correlation_with(x, y, data, test_func, alpha<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    correlation, p_value <span class="op">=</span> test_func(data[x], data[y])</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>test_func<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">  correlation coefficient: between </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>correlation<span class="sc">}</span><span class="ss">, p-value: </span><span class="sc">{</span>p_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> p_value <span class="op">&lt;</span> alpha:</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"The correlation is significant!"</span>)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"The correlation is not significant."</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>test_correlation_with(<span class="st">'config/n_neighbors'</span>, <span class="st">'mean_score'</span>, dfi, pearsonr)</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>test_correlation_with(<span class="st">'config/n_neighbors'</span>, <span class="st">'mean_score'</span>, dfi, spearmanr)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>pearsonr  correlation coefficient: between config/n_neighbors and mean_score: -0.8148057329177487, p-value: 6.1435506488484e-25
The correlation is significant!
spearmanr  correlation coefficient: between config/n_neighbors and mean_score: -0.8085147488740115, p-value: 2.6833127946483235e-24
The correlation is significant!</code></pre>
</div>
</div>
</section>
<section id="附加任务-尝试使不同的策略来构建-kd-树使得在分类阶段可以有更快的分类效率" class="level3" data-number="3.13">
<h3 data-number="3.13" class="anchored" data-anchor-id="附加任务-尝试使不同的策略来构建-kd-树使得在分类阶段可以有更快的分类效率"><span class="header-section-number">3.13</span> 附加任务: 尝试使⽤不同的策略来构建 KD 树，使得在分类阶段可以有更快的分类效率</h3>
<p>注意我们这里探索要修改的目标是构建 KD 树的过程，也就是要改变KD树的结构，而不是修改KNN分类算法，主要也不是修改KD树的搜索算法。 这里我们的目标是让搜索的效率更高。</p>
<p>文献@KD-means中总结了KD树构造时的一些常见策略，其中最重要的就是splitting method。分割一个父节点的时候，我们需要决定1. 在哪个数据维度（𝑠𝑑）上进行划分 2. 这个维度上哪个值作为划分点。对于第一点，作者选择范围最广的维度（𝑚𝑎𝑥 − 𝑚𝑖𝑛）来进行划分。</p>
<p>对于第二点，作者选择了滑动中点分割规则，因为它比其他经典规则提供了更优化的数据组织。这种规则不会产生空节点或数据空间非常稀疏的节点。与选择中位数作为切割值的经典规则不同，滑动中点分割规则选择点的中间值（（最大值𝑚𝑎𝑥 + 最小值𝑚𝑖𝑛）/ 2），这样做成本更低。</p>
<p>作者还提到KD树的构建过程中可以限制KD树的深度。但是我不太懂如果限制了深度，不是叶子节点的地方在搜索时应该如何处理，退化为暴力吗？</p>
<p>在我们实现新的算法之前，我们首先测试一下没改进之前的算法的速度。</p>
<div id="cell-65" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.07 s ± 100 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>现在我们来实现更快的KD树。</p>
<div id="cell-67" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 复用上面的一些定义</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>Node, euclidean_distance</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(__main__.Node, &lt;function __main__.euclidean_distance(x1, x2)&gt;)</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L205" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="fast_build_kd_tree" class="level3" data-number="3.14">
<h3 data-number="3.14" class="anchored" data-anchor-id="fast_build_kd_tree"><span class="header-section-number">3.14</span> fast_build_kd_tree</h3>
<blockquote class="blockquote">
<pre><code> fast_build_kd_tree (X, axis_order_list:list, strategy='median', depth=0)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L242" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="fast_search_kd_tree" class="level3" data-number="3.15">
<h3 data-number="3.15" class="anchored" data-anchor-id="fast_search_kd_tree"><span class="header-section-number">3.15</span> fast_search_kd_tree</h3>
<blockquote class="blockquote">
<pre><code> fast_search_kd_tree (tree, target, axis_order_list:list, k=3)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L311" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="fastkdtree" class="level3" data-number="3.16">
<h3 data-number="3.16" class="anchored" data-anchor-id="fastkdtree"><span class="header-section-number">3.16</span> FastKDTree</h3>
<blockquote class="blockquote">
<pre><code> FastKDTree (X, split_value_strategy='median',
             axis_order_strategy='range')</code></pre>
</blockquote>
<p><em>Initialize self. See help(type(self)) for accurate signature.</em></p>
<p>我们发现如果是用middle策略，由于数字识别数据集的分布特性，中点能划分的点太少，无法成功建树。</p>
<div id="cell-72" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tree = FastKDTree(X, split_value_strategy="median")</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> FastKDTree(X_train, split_value_strategy<span class="op">=</span><span class="st">"median"</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 0 32 39 31 24 56 16  8 40 47 48 23  1 57 15 55 33 38  7  9 30 25 10  4
 14 13 12 11  6  5  3  2 28 29 26 27 19 20 21 22 17 18 42 41 36 37 35 34
 46 45 44 43 51 52 50 49 54 53 58 59 60 61 62 63]</code></pre>
</div>
</div>
<div id="cell-73" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X_train)):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    k_nearest <span class="op">=</span> tree.search_kd_tree(X_train[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    where <span class="op">=</span> np.where((X_train <span class="op">==</span> k_nearest[<span class="dv">0</span>]).<span class="bu">all</span>(axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    where <span class="op">=</span> where[<span class="dv">0</span>]</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(where) <span class="op">==</span> <span class="dv">1</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-74" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k_nearest = tree.search_kd_tree(X_test[0], 2)</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co"># k_nearest = tree.search_kd_tree(X_train[0], 2)</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co"># k_nearest, X_train[0]</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co"># k_nearest = tree.search_kd_tree(X_test[0], 2)</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co"># k_nearest</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> tree.knn_classifier(X_train, y_train, X_test, k_neighbors)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, y_pred) <span class="co"># 确保数值正确</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0.9861111111111112</code></pre>
</div>
</div>
<div id="cell-75" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.15 s ± 107 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>我们发现速度变慢了！ 如果使用方差最大策略呢？会不会更好？</p>
<div id="cell-77" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> FastKDTree(X_train, split_value_strategy<span class="op">=</span><span class="st">"median"</span>, axis_order_strategy<span class="op">=</span><span class="st">'variance'</span>)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> tree.knn_classifier(X_train, y_train, X_test, k_neighbors)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, y_pred) <span class="co"># 确保数值正确</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 0 32 39 56 24 16 31  8 40 48 47 23 15  1 57 55  7 63 49 41 25  9 22  6
 33 17 38 14 30 11 62  3 46  4 59  2 12 54 60 58 51 52 10 45 50  5 18 19
 37 29 61 36 27 53 13 28 26 20 21 35 34 44 43 42]</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>0.9861111111111112</code></pre>
</div>
</div>
<div id="cell-78" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.5 s ± 217 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>甚至更慢！为了避免是因为我们实现新的方法有一定的overhead，我们对原本的划分策略也做一次测速。</p>
<div id="cell-80" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> FastKDTree(X_train, split_value_strategy<span class="op">=</span><span class="st">"median"</span>, axis_order_strategy<span class="op">=</span><span class="st">'simple'</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]
5.37 s ± 310 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<div id="cell-81" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> tree.knn_classifier(X_train, y_train, X_test, k_neighbors)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, y_pred) <span class="co"># 确保数值正确</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0.9861111111111112</code></pre>
</div>
</div>
<p>根据以上结果，我们初步得出结论，range划分方法比simple方法快，而simple方法比variance方法快。</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">参考文献</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Demšar_2006" class="csl-entry" role="listitem">
Demšar, Janez. 2006. <span>《Statistical Comparisons of Classifiers over Multiple Data Sets》</span>. <em>The Journal of Machine Learning Research</em> 7 (十二月): 1–30.
</div>
<div id="ref-tuningplaybookgithub" class="csl-entry" role="listitem">
Godbole, Varun, George E. Dahl, Justin Gilmer, Christopher J. Shallue, 和 Zachary Nado. 2023. <span>《Deep Learning Tuning Playbook》</span>. <a href="http://github.com/google-research/tuning_playbook">http://github.com/google-research/tuning_playbook</a>.
</div>
<div id="ref-Russell_Norvig_2016" class="csl-entry" role="listitem">
Russell, Stuart J., 和 Peter Norvig. 2016. <em>Artificial intelligence: a modern approach</em>. Third edition, Global edition. Prentice Hall series in artificial intelligence. Boston Columbus Indianapolis New York San Francisco Upper Saddle River Amsterdam Cape Town Dubai London Madrid Milan Munich Paris Montreal Toronto Delhi Mexico City Sao Paulo Sydney Hong Kong Seoul Singapore Taipei Tokyo: Pearson.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/Open-Book-Studio\.github\.io\/THU-Coursework-Machine-Learning-for-Big-Data");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues/new" class="toc-action"><i class="bi bi-github"></i>反馈问题</a></li></ul></div></div></div></footer></body></html>