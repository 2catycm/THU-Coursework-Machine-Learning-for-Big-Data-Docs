[
  {
    "objectID": "theory_assignments/A6/p_assignment6_yecanming.html#sec-1",
    "href": "theory_assignments/A6/p_assignment6_yecanming.html#sec-1",
    "title": "AdaBoost算法的深入理解",
    "section": "1 第一题——一个例子理解 AdaBoost",
    "text": "1 第一题——一个例子理解 AdaBoost\n题目如下\n\n某公司招聘职员考查身体、业务能力、发展潜力这3项。身体分为合格1、不合格0两级，业务能力和发展潜力分为上1、中2、下3三级。分类为合格1、不合格-1两类。\n已知10个人的数据，如表格1所示。假设弱分类器为决策树桩。试用AdaBoost算法学习一个强分类器。\n\n表1：应聘人员情况数据表\n\n\n\n列\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n身体\n0\n0\n1\n1\n1\n0\n1\n1\n1\n0\n\n\n业务能力\n1\n3\n2\n1\n2\n1\n1\n1\n3\n2\n\n\n发展潜力\n3\n1\n2\n3\n3\n2\n2\n1\n1\n1\n\n\n分类\n-1\n-1\n-1\n-1\n-1\n-1\n1\n1\n-1\n-1\n\n\n\n表1：应聘人员情况数据表\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n身体\n0\n0\n1\n1\n1\n0\n1\n1\n1\n0\n\n\n业务能力\n1\n3\n2\n1\n2\n1\n1\n1\n3\n2\n\n\n发展潜力\n3\n1\n2\n3\n3\n2\n2\n1\n1\n1\n\n\n分类\n-1\n-1\n-1\n-1\n-1\n-1\n1\n1\n-1\n-1\n\n\n\n\n1.1 审题\n我们首先复习一下李航书上的内容。\n\n什么是 Boosting？\n\n李航书上boost是提升的意思,指的是把一个弱学习算法提升为强学习算法。因为PAC框架下被证明,如果前者存在,后者必定存在,反之亦然。\n我们如果已经找到弱学习算法，那当然是说明强学习算法存在，但是找到强学习算法的算法未必存在，但是我们可以尝试构造。\n强就是准确率高，具体多高书上没定义，弱就是比随机猜测（最大熵模型？）好。\n注意学习算法不是学习器，弱学习算法是说，多项式时间内训练出一个弱学习器的算法。boost操作的对象是“弱学习算法”，那个多项式时间复杂度的算法，不一定是通过操作弱学习器，当然如果你的boost只需要操作弱学习器，构造出强学习器，这个步骤本身构成了强学习算法，那这个当然也是boost。\n？难道其他ensemble learning算法不是把弱学习提升为强学习吗\n李航书上说“大多数的boosting方法”是改变训练数据的概率分布来解决提升的问题。这个或许就是和其他集成学习的区别。\n\n什么是 AdaBoost 算法？\n\n多轮学习多个弱学习分类器，每一轮的数据概率分布有所不同，依赖于上一轮的结果。\n上一轮若分类器错误分类的样本权值变大，正确的权值变小，权值加起来始终为1, 变化规则是 \\(w_{m+1, i} = w_{mi} \\frac{1}{Z_m} exp(-\\alpha_m y_i G_m(x_i))\\)，其中\\(y_i \\in \\{1, -1\\}\\)\n集成分类器 $G(x) = sign(_{m=1}^{M}_m G_m(x)) $, 注意 \\(\\alpha_m\\) 加在一起并不是1。这个很奇怪？\n其中 \\(\\alpha_m = \\frac{1}{2} log\\frac{1-e_m}{e_m}\\), 而\\(e_m\\)是按照 \\(w_m\\)加权后\\(G_m\\)的错误率，\\(\\alpha_m\\) 像是 分类器加权正确率的logodds的一半。不知道为什么这样设计？\n\nAdaBoost 的第二解释如何理解？\n\n李航书上给出了8.3节，认为 AdaBoost 也是加法模型在指数函数下使用前向分步算法进行二分类的学习方法。\n\n\n什么是决策树桩？\n\n李航统计学习方法166页给出了这个概念。\n决策树桩（Decision Stump）是就是只有一个分裂节点和两个叶节点的决策树，也就是只有单个特征（假如是连续型随机变量），根据阈值分割为两个集合，然后集合内哪个类别多就是哪个。\n在二分类的情况下，使用决策树桩作为基本分类器的 AdaBoost 又叫做boosting tree提升树算法。多分类和回归的话提升树就有一些新的方法。\n\n什么是概率近似正确框架？\n\n复习之后，我们来看看题目询问的问题。\n首先对 表格 可视化\n\nimport pandas as pd\nimport numpy as np\n\n\n# 创建原始数据的np array\ndata = np.array([\n    [0, 1, 3, -1],\n    [0, 3, 1, -1],\n    [1, 2, 2, -1],\n    [1, 1, 3, -1],\n    [1, 2, 3, -1],\n    [0, 1, 2, -1],\n    [1, 1, 2, 1],\n    [1, 1, 1, 1],\n    [1, 3, 1, -1],\n    [0, 2, 1, -1]\n])\n\n# 将np array转换为DataFrame\ndf = pd.DataFrame(data, columns=['身体', '业务能力', '发展潜力', '分类'])\n\ndf\n\n\n\n\n\n\n\n\n身体\n业务能力\n发展潜力\n分类\n\n\n\n\n0\n0\n1\n3\n-1\n\n\n1\n0\n3\n1\n-1\n\n\n2\n1\n2\n2\n-1\n\n\n3\n1\n1\n3\n-1\n\n\n4\n1\n2\n3\n-1\n\n\n5\n0\n1\n2\n-1\n\n\n6\n1\n1\n2\n1\n\n\n7\n1\n1\n1\n1\n\n\n8\n1\n3\n1\n-1\n\n\n9\n0\n2\n1\n-1\n\n\n\n\n\n\n\n\n\n\n1.2 plot_binary_classification_3d\n\n plot_binary_classification_3d (X, y, labels=[1, -1], label_names=['正例',\n                                '负例'], label_colors=['blue', 'red'],\n                                label_markers=['o', 'x'], x_names=['x(1)',\n                                'x(2)', 'x(3)'], point_size=100,\n                                text_offset=(0.1, 0.1, 0.1),\n                                point_names=None, title='数据点可视化', size=(9,\n                                6))\n\n\nX_columns = ['身体', '业务能力', '发展潜力']\ny_column = '分类'\nX = df[X_columns].values\ny = df[y_column].values\nfig, ax = plot_binary_classification_3d(X, y,x_names=X_columns)\nplt.show()\n\n\n\n\n\n\n\n\n接下来尝试使用 AdaBoost算法\n\n\n1.3 解题\n\n1.3.1 解法一：手算推导法（考试写解答题）\n初始化权值分布 \\(D_1 = (w_{1, 1}, w_{1, 2}, \\cdots, w_{1, 10}) = (\\frac{1}{10}, \\frac{1}{10}, \\cdots, \\frac{1}{10})\\)\n\n首先我们在 \\(D_1\\) 上学习决策树桩。决策树桩有很多种学习准则，比较常用的 AdaBoost-SAMME 方法选择的是 CART 决策树的分类树,参考，也就是用 gini 系数来做特征选择，同时选择最优二值切分点。\n\n首先计算“身体”这个属性的基尼指数。\n\\[Gini(D_1, 身体=0 or not) = \\frac{4}{10}(1- (1^2 + 0^2)) + \\frac{6}{10}( 1- (\\frac{4}{6}^2 + \\frac{2}{6}^2)) = \\frac{4}{15}\\]\n， 最优切分点是“是否 身体=0”，因为没有别的选择。\n注意这里 李航书上的表示是具有误导性的，李航书上写的 \\(Gini(D_1, 身体=0)\\) 表示的是 身体=0这个子集上的基尼指数，而我们这里是在说 身体==0 这个特征，严谨的表述是 \\(Gini(D_1, 身体==0)\\) \n同理可得 \\[Gini(D_1, 业务能力==1), Gini(D_1, 业务能力==2),Gini(D_1, 业务能力==3)\\]\n\\[Gini(D_1, 发展潜力==1), Gini(D_1, 发展潜力==2), Gini(D_1, 发展潜力==3)\\]\n由于 Gini(D_1, 业务能力==1) 最小，\n\\[\nG_1 =\n\\begin{cases}\n1, & \\text{如果 } 业务能力==1; \\\\\n-1, & \\text{如果 } 业务能力!=1 .\n\\end{cases}\n\\]\n注意这里是不平衡二分类，所以我们对CART做了调整，要不然两个树桩都是-1.\n\n\n\n\n1.4 calculate_gini_index\n\n calculate_gini_index (df, feature, value)\n\n\n\n\n1.5 calculate_gini_index_for_subset\n\n calculate_gini_index_for_subset (df_subset)\n\n*计算给定 DataFrame 子集的 Gini 指数。\n参数: df_subset (pd.DataFrame): 包含类别标签的 DataFrame 子集。\n返回: float: Gini 指数。*\n\ngini_body_0 = calculate_gini_index(df, '身体', 0)\ngini_yewu_1 = calculate_gini_index(df, '业务能力', 1)\ngini_yewu_2 = calculate_gini_index(df, '业务能力', 2)\ngini_yewu_3 = calculate_gini_index(df, '业务能力', 3)\ngini_fazhan_1 = calculate_gini_index(df, '发展潜力', 1)\ngini_fazhan_2 = calculate_gini_index(df, '发展潜力', 2)\ngini_fazhan_3 = calculate_gini_index(df, '发展潜力', 3)\n\ngini_body_0, gini_yewu_1, gini_yewu_2, gini_yewu_3, gini_fazhan_1, gini_fazhan_2, gini_fazhan_3\n\n(0.26666666666666666,\n 0.24,\n 0.2857142857142857,\n 0.30000000000000004,\n 0.31666666666666665,\n 0.3047619047619048,\n 0.2857142857142857)\n\n\n\n训练数据集上的分类误差率是 \\(e_1 = P(G_1(x_i) \\ne y_i) = 0.3\\) , 因为样本 1,4,6 都分错了\n\\(G_1(x)\\) 的 系数 _1 = (｛ 1-0.3 ｝｛ 0.3 ｝)\n\n更新 \\(D_2\\), 分类错误的1, 4, 6 权重提升为 0.16667, 其他样本分类正确，降低为 0.07143\n\ne = 0.3\nalpha = 0.5 * np.log((1 - e) / e)\nalpha\n\n0.42364893019360184\n\n\n同理我们可以在 \\(D_2\\) 上学习决策树桩。 三轮之后，我们可以得到分类正确率 100% 的集成模型。\n\n1.5.1 解法二：使用Python和机器学习库（科研使用）\n参考 https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\nimport numpy as np\n\n\nclf = AdaBoostClassifier(n_estimators=3)\nclf.fit(X, y)\ny_predict = clf.predict(X)\nscore = clf.score(X, y)\nscore\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n  warnings.warn(\n\n\n1.0\n\n\n\nclf.estimators_\n\n[DecisionTreeClassifier(max_depth=1, random_state=1986558224),\n DecisionTreeClassifier(max_depth=1, random_state=209715172),\n DecisionTreeClassifier(max_depth=1, random_state=1797073605)]\n\n\n\nclf.estimator_errors_\n\narray([2.00000000e-01, 1.66666673e-01, 2.25517146e-08])\n\n\n\nclf.estimator_weights_\n\narray([1., 1., 1.])\n\n\n注意第一轮的弱分类器因为数据不平衡，所以选择所有样本的都是1，所以分类误差率是0.2, 而不是我们的0.3",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A6",
      "AdaBoost算法的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A6/p_assignment6_yecanming.html#sec-2",
    "href": "theory_assignments/A6/p_assignment6_yecanming.html#sec-2",
    "title": "AdaBoost算法的深入理解",
    "section": "2 第二题——理解软间隔支持向量机以及其对偶形式",
    "text": "2 第二题——理解软间隔支持向量机以及其对偶形式\n题目如下 &gt; 比较支持向量机、AdaBoost、逻辑斯谛回归模型的学习策略与算法。\n\n2.1 解题\n\n\n\n\n\n\n\n\n\n\n特性\n支持向量机 (SVM)\nAdaBoost\nAdaBoost第二种理解\n逻辑斯谛回归模型\n\n\n\n\n模型\nw和b表示的分割超平面\n弱学习器组合成的强学习器\n(弱学习器作为基函数提取的特征的)加法模型\nw和b表示的分割超平面\n\n\n学习策略（训练损失）\n间隔最大化\n关注错误样本\n最小化指数损失\n最大化似然函数\n\n\n参数学习算法\n原始问题梯度下降、对偶问题凸二次规划、SMO算法等\n多轮迭代改变样本概率分布，学习多个弱分类器，根据错误率组合弱分类器为强分类器\n前向分步算法\n梯度下降、拟牛顿法等\n\n\n优缺点\n泛化能力强，对参数敏感\n减小偏差，对异常值敏感\n同左列\n效率高，非线性表现不佳\n\n\n\n我们可以画出一个思维导图\ngraph LR\n    A[Machine Learning Algorithms] --&gt; B[Support Vector Machine SVM]\n    A --&gt; C[AdaBoost]\n    A --&gt; E[Logistic Regression Model]\n    \n    B --&gt;|Model| B1[Separating Hyperplane w and b]\n    B --&gt;|Learning Strategy Training Loss| B2[Margin Maximization]\n    B --&gt;|Parameter Learning Algorithm| B3[Gradient Descent for Primal Problem, Convex Quadratic Programming for Dual Problem, SMO Algorithm, etc.]\n    B --&gt;|Advantages and Disadvantages| B4[Strong Generalization, Sensitive to Parameters]\n    \n    C --&gt;|Model| C1[Combination of Weak Learners into a Strong Learner]\n    C --&gt;|Learning Strategy Training Loss| C2[Focus on Misclassified Samples]\n    C --&gt;|Parameter Learning Algorithm| C3[Multiple Iterations to Change Sample Probability Distribution, Learning Multiple Weak Classifiers, Combining Weak Classifiers into a Strong Classifier Based on Error Rate]\n    C --&gt;|Advantages and Disadvantages| C4[Reduces Bias, Sensitive to Outliers]\n    \n    E --&gt;|Model| E1[Separating Hyperplane w and b]\n    E --&gt;|Learning Strategy Training Loss| E2[Minimization of Exponential Loss]\n    E --&gt;|Parameter Learning Algorithm| E3[Gradient Descent, Quasi-Newton Methods, etc.]\n    E --&gt;|Advantages and Disadvantages| E4[High Efficiency, Poor Performance on Non-linear Problems]\n\n\n\n\n2.2 题目扩展问题",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A6",
      "AdaBoost算法的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A4/p_assignment4_yecanming.html#sec-1",
    "href": "theory_assignments/A4/p_assignment4_yecanming.html#sec-1",
    "title": "最大熵模型以及对数几率分类模型的深入理解",
    "section": "1 第二题——最大熵模型的深入理解",
    "text": "1 第二题——最大熵模型的深入理解\n题目如下\n\n写出最大熵模型学习的DFP算法\n\n\n\n\n\n\n\n注记\n\n\n\nTL; DR 前面审题内容较长，学习了一些这道题的一些背景知识方便理解。 对于题目的证明，可以直接跳到解题部分@sec-proof。\n\n\n\n1.1 审题\n\n1.1.1 什么是熵？\n\n1.1.1.1 首先复习一下课件以及李航课本\n《决策树》那节课上，我们学习了ID3算法，首次提到了熵的概念，我们来看第一页课件讲了什么：第一页我们就遇到了不少问题，我们稍后解答。我们首先明白了事件有信息量。 多个事件的平均信息量似乎是他们信息量的加和，那课件上说“平均”似乎不妥。  经过我的查询，其实是第一个定义错了，课件上的I(a)就已经是平均信息量了，事件的“信息量”其实是指香农信息量，就是 \\(-log_2P(a)\\)，没有多乘一个\\(P(a)\\)。 值得注意的是，从课件这一页的公式来看，\\(I(a_1, a_2) \\neq I(a_1 \\cup a_2)\\)，也就是说如果两个事件合并为一个事件的平均信息量和两个事件的平均信息量之和是不一样的。有点让人困惑\n在我们学习概率论与数理统计的时候，重要的就是从讨论事件变为讨论随机变量，所以随机变量的信息量也要定义。纠正了刚才第一页课件的错误之后，我们按照第一页的概念来说，随机变量的信息量就是随机变量所有取值事件各自平均信息量的加和，或者是说各个取值事件的信息量在随机变量分布下的期望。  第二页中让我们疑惑的是，熵和信息量这两个概念为什么可以混用？如果可以混用为什么上一页叫做信息量，这一页叫做熵？简单理解一下，目前我们认为信息量 (Information Content)是对一个随机变量取值去定义，熵 (Entropy) 是对随机变量去定义，熵就是信息量在这个随机变量下的期望。注意，一个随机变量取值可能实际上对应了很多个事件，我们刚才说\\(I(a_1, a_2) \\neq I(a_1 \\cup a_2)\\)，随机变量这个变量被人定义后，就定义了一种对信息的理解方式，不同的理解方式下我们认为的信息量是不同的。\n这一页是在讲熵(Entropy)和不确定性(Uncertainty)之间的关系。随机变量的不确定性通常是指其结果的不可预测性，即在进行观测之前，我们无法确定随机变量将取哪个具体的值。怎么量化这个不确定的程度呢？熵只是一种方式罢了，方差以及分布的图像也可以让我们看到随机变量的不确定性。这一页并没有解释这一点，而是开始举了个例子告诉我们什么情况下熵比较大，什么情况比较小，取值范围是什么样的。  注意这里说的是离散随机变量，有分布列，取值有n种，简单推导知道了熵在p=1/n的情况下最大。那么方差是不是一样呢？暂时没找到说法。不过我感觉熵似乎更靠谱的地方在于它不会被随机变量具体取值的大小所影响。\n注意这里还有个要点，就是如果p=0， \\(plog_2p\\) 等于0，这是因为我们学过洛必达法则，\\(\\lim_{p \\to 0} \\frac{\\log p}{\\frac{1}{p}} = \\lim_{p \\to 0} \\frac{\\frac{1}{p}}{-\\frac{1}{p^2}} = \\lim_{p \\to 0} (-p) = 0\\)\n这里我们复习一下什么是条件期望。我们知道什么叫做条件概率分布，条件期望就是条件概率采样下y取值的期望。  上面课件中最下面的公式意思是说如果相求h(y)的期望，并不需要求出h(y)的分布或者h(y)|x的分布。这是因为函数期望的基本定理（注意不是说期望的函数等于函数的期望，而是说函数的期望可以用原本的采样去计算）。\n 这里我们的问题是，这个定义看起来嵌套了一层，我们能不能直接通过条件期望去定义条件熵呢？ 答案是不能。这里的符号我们需要特别注意，\\(H(Y|X) \\neq H(Y|X=x)\\)，前者的X不知道，是个平均情况。\n下一个概念是互信息。 李航书上提到，Y对X的互信息\\(I(Y; X) = H(Y) - H(Y|X)\\)是指得知X的取值让Y的不确定性减少，需要得知Y取值所需要的信息量减少了多少。 之所以叫做互相信息，是因为 $I(Y;X) = I (X; Y) $\n\n\n1.1.1.2 PRML书上有什么补充吗？\n\n\n1.1.1.3 进一步的资料查找\n\n\n\n1.1.2 什么是最大熵？\n最大熵就是给定某些限制条件下，允许我们修改一个随机变量的分布，使得其熵最大。问我们怎么修改。\n这个问题其实需要分类讨论。核心结论是 - 离散随机变量均匀分布熵最大。 - 连续随机变量给定方差一定时，高斯分布的熵最大。\n这里有几个问题 - 连续随机变量为什么均匀分布熵没有高斯分布大？ - 如果我们限定连续随机变量的取值范围为[a, b], 截断高斯分布(Truncated Gaussian Distribution)和均匀分布去比，哪个熵更大？\n\n1.1.2.1 具体怎么推导的？\n对于离散型随机变量X，取值有N个，每个取值的概率是\\(p_i\\)，那么什么情况下X的熵最大呢？\n\\(\\max_{p_1,p_2,\\cdots,p_N} H(X) = -\\sum_{i=1}^N p_i \\log_2 p_i \\\\ s.t. \\sum_{i=1}^N p_i = 1\\)\n求导 \\(\\frac{dH_p(X)}{p_i} = - (1 \\times \\log_2 p_i + p_i \\times \\frac{1}{p_i}) = -( log_2 p_i + 1 ) = 0\\) 似乎得到p_i=0，然而这个不满足约束条件。我们不能直接求导解决，要考虑约束。\n应当使用拉格朗日乘子法，引入拉格朗日函数$ L(p_1, p_2, …, p_N, ) = -(_{i=1}^{N} p_i 2 p_i) + ({i=1}^{N} p_i - 1) $ 其中，$ $ 是拉格朗日乘子。\n对每个变量 $ p_i $ 和 $ $ 求偏导数，并将它们设置为0以找到极值点。我们得到以下方程组： $ = -_2 p_i - 1 + = 0 $\n$ = _{i=1}^{N} p_i - 1 = 0 $\n这里的重点是注意到第一个方程组，告诉我们每一个 \\(p_i\\) 都是 \\(2^{-1+\\lambda}\\)，都是同样的\\(\\lambda\\)，所以是同一个数。第二个方程其实就还是约束条件，那么就简单了，\\(p_i = 1/N\\)。\n\n\n\n1.1.3 什么是最大熵原理？\n最大熵原理是一个学习准则，认为学习概率模型应当选择熵最大的模型。 在什么东西里面选呢？还要先满足约束条件，也就是能在训练集上拟合，然后熵是在帮忙衡量模型的结构风险。\n 李航书上没有讨论具体求解约束的顺序。\n这里我们再理解下书上的这个图  一个三角形表示了能取三个值的离散分布列。在顶点上表示这个顶点的那个值概率为1，其他两个取值为0，在边上表示对面的顶点取值是0。具体坐标是怎么对应到概率的呢？这个暂时没有搜索到答案。 为什么约束条件是直线不是曲线呢？图中的约束条件两条直线有唯一的交点，为什么李航仍然说这个模型还有无穷多个呢？\n\n\n1.1.4 什么是最大熵模型？\n书上讲的很抽象，这里我的理解是，模型是指机器学习模型，也就是\\(P_w(Y|X)\\), 机器学习训练集会给我们约束，限制\\(P_w(Y|X)\\)，然后我们使用最大熵原理去选择。\n具体怎么约束是关键。李航书上介绍的方法是利用 \\(P(X, Y) = P(X) \\times P(Y|X)\\)的性质，其中P(X, Y)和P(X)直接从数据集进行估计得到经验分布。 利用函数的期望的性质，进一步说要用期望相等来作为约束条件。 \n但是李航的书上讲到这里戛然而止，并没有说对于分类模型f要怎么定义。袁老师的课件上说对于NLP和CV是不同的，我仍然无法理解到底要干什么。\n李航书上另一个疑点是X的分布他认为是连续型，但是这样估计出来的P(X, Y)和P(X)对吗？\n\n\n\nimage-4.png\n\n\n我们可以看到最后李航推到出来的东西  推理的时候，模型对于已知的x，试一下每一个不同的y，看看n个f(x, y)特征在w的组合下得到的值是多少，然后最后exp一下这个值，对所有试过的y做归一化。 这里我们终于看懂最大熵模型在搞什么了，前面推导时”f(x, y)“只能是两个值让我们不找到在干什么。 现在懂了，最大熵模型，如果\\(f(x, y)=x\\)，不去管y，就是softmax。\n\n\n\n1.2 解题\n\n1.2.1 牛顿法和拟牛顿法\n首先需要商榷一下课件上术语的表述。 - Number 1, 牛顿法=牛顿迭代法=Newton-Raphson Method， 这三个东西肯定一样的。但是梯度下降法有所区别。 - Number 2, 牛顿法分为两个，一个是用来解方程的（求根使得式子=0），一个是用来优化（求最小值）。这个很容易混淆，因为我们机器学习的时候，往往loss最小值就是0，搞得求根好像就是在优化一样。 - Number 3, 牛顿法解方程，迭代公式是 \\(x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\\)，其中 \\(f(x_k)\\) 是函数值，\\(f'(x_k)\\) 是函数的导数，这个是用切线去搞，不是叫做梯度下降法，梯度在下面，梯度下降法是用来优化的不是求根的。而牛顿法做优化，迭代公式才是 \\(x_{k+1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\\)， 这个反而和梯度下降法有关系，是对梯度下降法用二阶导数做了修正。 - 李航书上直接介绍了牛顿优化法的多维情况，也就是黑塞矩阵啦。  - 牛顿法解方程是利用一阶泰勒展开，局部用切线近似曲线，用切线的根代替曲线的根。牛顿法做优化则是利用二阶泰勒展开，局部用二次函数近似曲线，用二次函数的极值代替曲线的极值。\n拟（quasi, /ˈkweɪzaɪ; ˈkweɪsaɪ; ˈkwɑːzi/, as it were）牛顿法想要替代掉 黑塞矩阵的逆矩阵 \\(H^{-1}\\)。 首先一阶导数的变化量可以用二阶导数乘上x的变化量来近似（二阶泰勒展开就是相等）  这个就是拟牛顿条件，就是说能充当\\(H_k^{-1}\\)的\\(G_k\\), 需要 $G_k (g_{k+1}-g_k) = (x_{k+1}-x_k) $\n拟牛顿法需要通过迭代来计算\\(G_{k+1} = G_k + \\Delta_k\\)，其中\\(\\Delta_k\\)是拟牛顿条件的增量。\n\n中间有一段感觉李航突然介绍了另一个东西，和拟牛顿法没关系，介绍了正定性说明牛顿法一定可以成功好奇怪。\n\n\n\n1.2.2 DFP算法\nDFP(Davidon-Fletcher-Powell)算法(DFP algorithm) 在李航528页附录B有描述，是求解无约束最优化问题的一种拟牛顿法。\n假设 \\(\\Delta_k = P_k + Q_k\\)，使用拟牛顿条件可以得到 \n注意这里符号\\(y_k\\)实际上是\\(g_{k+1}-g_k\\)，不是原本那个y。\n而初始的\\(G_k\\) 要正定。\nBGFS和DFP类似，只不过不是近似\\(G_k \\approx H_k^{-1}\\)，而是近似\\(B_k \\approx H_k\\)。\n\n\n1.2.3 最大熵模型拉格朗日乘子法化简\n一开始我们最大熵的模型优化问题是\n\\[\n\\max_{P\\in C} H(P) = -\\sum_{x, y} \\tilde{P}(x) P(y|x) \\log P(y|x)\\\\\ns.t. E_{P}(f_i) = E_{\\tilde{P}}(f_i), i=1,2,...,n\\\\\n\\sum_{y} P(y|x) = 1, x\\in X\n\\]\n引入拉格朗日乘子w_{0:n}后，问题变成\n\\[\n\\min_{P\\in C} \\max_{w} L(P, w) \\equiv -H(P) + w_0 (1-\\sum_{y} P(y|x)) + \\sum_{i=1}^n w_i (E_{P}(f_i) - E_{\\tilde{P}}(f_i))\n\\]\n注意这个式子的列法，我们产生疑问，求最大值和最小值有没有区别，是加上lambda还是减去lambda乘上约束条件？\n首先注意拉格朗日乘子是大于等于0的，我们之所以可以按照上面的方法变换，在于外面想要最小化，而里面让约束条件不满足时有机会优化到正无穷（让违反约束的对应的拉格朗日乘子很大就行），所以里面是最小化。如果外面是要搞最大化，那里面就应该是最小化，或者变成减去拉格朗日乘子，让约束条件满足时有机会优化到负无穷。\n对偶问题是反过来，在所有的拉格朗日乘子中搜索，其中任何一个x都有对应的最小的值，可能有时候偶尔违反下约束，得让那个东西小，最后搜索到x那么吝啬的小东西还要让它大。根据定理，这样对抗下来，其实拉格朗日乘子也不太敢把自己弄得很大，x会变得很小心翼翼，所以其实这个找到的最优值甚至比原始问题还要小。 \n在满足KKT条件的时候，原始问题和对偶问题的最优解是等价的。最大熵模型就是满足了。\n进一步求解偏导数=0之后，我们首先把P_w(y|x)的形式优化了出来。\n\\[\nP_w(y|x) = softmax(\\sum_{i=1}^n w_i f_i(x,y))\n\\]\n所以我们最后的问题简化为拉格朗日乘子，这里实际上是模型参数，的最大化 \\[\n\\max_{w} L(P, w) \\equiv -H(P) + w_0 (1-\\sum_{y} P_w(y|x)) + \\sum_{i=1}^n w_i (E_{P}(f_i) - E_{\\tilde{P}}(f_i))\n\\]\n也就是 \\[\\min_{w\\in R^n}\\begin{aligned}\nf(w)\n&=\\sum_x \\hat P(x)\\log \\sum_y \\exp \\left( \\sum_{i=1}^{n} w_i f_i(x,y)\\right)-\\sum_{x,y} \\hat P(x,y)\\sum_{i=1}^{n} w_i f_i(x,y)\n\\end{aligned},\\] 梯度为 \\[g(w)=\\left(\\frac{\\partial f(w)}{\\partial w_1}, \\frac{\\partial f(w)}{\\partial w_2},...,\\frac{\\partial f(w)}{\\partial w_n}\\right)^T\\] 其中, \\[\\frac{\\partial f(w)}{\\partial w_i}=\\sum_{x,y} \\hat P(x)P_w(y|x)f_i(x,y)-E_{\\hat P}(f_i),\\quad i=1,2,...,n\\]\n\n\n1.2.4 DFP算法求解\n输入为：特征函数 $ f_1,f_2,…,f_n$ ，经验分布 \\(\\hat{P}(x,y)\\) ，目标函数 $ f(w)$ ，梯度 \\(g(w)=\\nabla f(w)\\) ，精度要求 $$ 。\n输出为：最优参数值 $ w^$ ，最优模型 $ P_{w^}(y|x)$ 。\n算法步骤：\n（1）选定初始点 $ w^{(0)}$ ，取 $ G_0$ 为正定对称矩阵，置 $ k=0$ ；\n（2）计算 $ g_k=g{(w^{(k)})}$ ，若 $|g_k|&lt;$ ，则认为精度到了，停止计算，得 $ w^*=w^{(k)}$，退出算法；\n（3）由 $ p_k=-G_kg_k$ 求出 $ p_k$， 这个 $ p_k$ 就是要更新的东西，近似的是 \\(-H_kg_k\\)\n（4）一维搜索：求 $ _k$ 使得 $ f(w^{(k)}+_kp_k)=f(w^{(k)}+p_k)$ ；这一步是为了更好的利用 $ p_k$\n（5）置 $ w{(k+1)}=w{(k)}+_kp_k$ ；进行权重的实际更新\n（6）计算 $ g_{k+1}=g(w^{(k+1)})$ ，若 $|g_{k+1}|&lt;$ ，则停止计算，得 $ w^*=w^{(k+1)}\\(；否则，按下式求出 新的\\) G_{k+1};$ \\(\\begin{aligned}\n&G_{k+1}=G_k+\\frac{\\delta_k\\delta_k^T}{\\delta_k^Ty_k}-\\frac{G_ky_ky_k^TG_k}{y_k^TG_ky_k}\n\\end{aligned}\\) 其中， \\(\\begin{aligned}&y_k=g_{k+1}-g_k,&\\delta_k=w^{(k+1)}-w^{(k)}\\end{aligned}\\)\n（7）置 $ k=k+1$ ，转步骤（3）。\n\n\n1.2.5 Pytorch代码实现\n最大熵实际上是怎么做多分类任务的呢？ 我们尝试把上面的那些公式再用Pytorch实现一下。\n由于我们还没有理解多分类任务的特征函数到底要怎么定义，所以我们这一部分的代码暂时先不写，等到理解了再补充。\n\n\n代码\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nclass XYFeatureExtractor(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(XYFeatureExtractor, self).__init__()\n    def forward(self, x):\n        # 这个是生成式模型，所以模型会自己脑补y，把所有情况的y都考虑一下\n        return 1\n        \n# 定义最大熵模型（softmax分类器）\nclass MaxEntropyModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(MaxEntropyModel, self).__init__()\n        self.fc = nn.Linear(input_dim*output_dim, output_dim)\n\n    def forward(self, features):\n        # 这里的x就是 batch个  f_{1:n}(x, y) 向量\n        return torch.softmax(self.fc(features), dim=1)\n    \nclass MaxEntropyLoss(nn.Module):\n    def __init__(self, model:MaxEntropyModel, extractor : XYFeatureExtractor):\n        super(MaxEntropyLoss, self).__init__()\n        # 最大熵模型的损失函数和weight也有关系, 所以得传进来\n        self.model = model \n\n    def forward(self, input, target):\n        # print(input.shape)\n        log_sum_exp = torch.logsumexp(self.model.fc(input), dim=1)\n        # print(log_sum_exp.shape)\n        sum_x_log_sum_exp = torch.sum(log_sum_exp) # empirical x\n        sum_logits = torch.sum(self.model.fc(input), dim=1) \n        \n        return -sum_x_log_sum_exp\n\n\n\n\n代码\n# model = MaxEntropyModel(100, 10) \n# criterion = MaxEntropyLoss(model)\n# criterion(torch.randn(10, 100), torch.randint(0, 10, (10,)))\n\n\ntorch.Size([10, 100])\ntorch.Size([10])\n\n\ntensor(-23.8446, grad_fn=&lt;NegBackward0&gt;)\n\n\n我们很快观察到代码似乎都没用到target变量，到底怎么学习呢？\n有待于进一步探究，我们会在后面的理论作业中尽可能搞懂这个问题，现在确实太抽象了，公式我是懂的，但是f(x, y)书上是真的没有写。需要调查一下资料，要不然我不知道Pytorch怎么实现最大熵模型。\n我们倒是可以实现以下DFP算法先，这个看起来很好理解。\n\n\n代码\n# class DFP_optimizer(torch.optim.Optimizer):\nclass DFP_optimizer():\n    def __init__(self, params):\n        self.params = list(params)\n        self.G = [torch.eye(p.size()[0]) for p in self.params]\n        self.epsilon = 1e-5\n\n    def step(self):\n        for i, param in enumerate(self.params):\n            g = param.grad\n            G = self.G[i]\n            pk = -torch.mv(G, g)\n            # 一维搜索（这里简化为固定步长）\n            lambda_k = 0.01\n            param.data.add_(lambda_k, pk)\n            gk_new = param.grad\n            yk = gk_new - g\n            dk = lambda_k * pk\n            rho_k = 1.0 / torch.dot(yk, dk)\n            # 更新G\n            G = G - rho_k * torch.ger(torch.mv(G, yk), torch.mv(G, yk)) + rho_k * torch.ger(dk, dk)\n            self.G[i] = G\n\n\n\n\n代码\n# Testing the DFP optimizer on a simple quadratic function\ndef quadratic_function(x):\n    return (x - 3)**2\n\n# Gradient of the quadratic function\ndef quadratic_gradient(x):\n    return 2 * (x - 3)\n\n# Initialize parameter\nx = torch.tensor([0.0], requires_grad=True)\noptimizer = DFP_optimizer([x])\n\n# Optimization loop\nfor _ in range(20):\n    # optimizer.zero_grad()\n    x.grad = None\n    loss = quadratic_function(x)\n    loss.backward()\n    optimizer.step()\n    print(f'Current x: {x.item()}, Loss: {loss.item()}')\n\nprint(f'Optimized x: {x.item()}')\n\n\nCurrent x: 0.05999999865889549, Loss: 9.0\nCurrent x: nan, Loss: 8.643600463867188\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nCurrent x: nan, Loss: nan\nOptimized x: nan\n\n\n/tmp/ipykernel_2183857/2759460865.py:15: UserWarning: This overload of add_ is deprecated:\n    add_(Number alpha, Tensor other)\nConsider using one of the following signatures instead:\n    add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1578.)\n  param.data.add_(lambda_k, pk)\n\n\n看来我们的实现还有问题，要进一步优化一下，不过不是这次理论作业的重点，暂时先这样吧，去做科研了。\n\n\n\n1.3 题目扩展问题",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A4",
      "最大熵模型以及对数几率分类模型的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A5/p_assignment5_yecanming.html#sec-1",
    "href": "theory_assignments/A5/p_assignment5_yecanming.html#sec-1",
    "title": "支持向量机的深入理解",
    "section": "1 第一题——一个例子理解支持向量机",
    "text": "1 第一题——一个例子理解支持向量机\n题目如下\n\n已知正例点 \\(x_1=(1,2)^T\\), \\(x_2=(2,3)^T\\), \\(x_3=(3,3)^T\\), 负例点\\(x_4=(2,1)^T\\), \\(x_5=(3,2)^T\\), 试求最大间隔分离超平面和分类决策函数，并在图上画出分离超平面、间隔边界及支持向量。\n\n\n1.1 审题\n我们首先复习一下李航书上的内容。\n\n什么是分离超平面？什么是超平面？\n\n首先我认为为了学好这一章以及感知机的内容，有必要详细了解超平面到底是什么。\n\\(R^n\\)中的超平面(hyperplane)是指其中一个 \\(n-1\\)维 (需要多少个向量来张成)的子空间（不一定通过原点，所以不一定是向量空间）。超平面将原本的空间一分为二，分为两个半平面。\n超平面的解析式有很多种，高中和高数就学过平面有一般式、点法式、截距式、参数式等，我们机器学习中关注是一般式，而一般式和点法式是可以互相转换的，具有一定的关联。\n高数中学的三维空间中的平面一般式是 \\(Ax+By+Cz+D=0\\)，A,B,C不同时为零。扩展一下那就是\\(w\\cdot x + b = 0\\)，其中 \\(w\\) 是超平面的法向量，要求\\(w\\)不是零向量，也就是至少其中一个分量不为零。\n\n李航书上随口一说\\(b\\) 是超平面的“截距”，但是这个说法我找不到依据（不要想当然以为直线里面的 y=kx+b 的b叫截距这里就也是截距）。实际上一般式里面的D没有任何几何意义！\n所谓截距（intercept），是平面和坐标轴的交点的位置，也就是其他维度的值取0的时候，剩下这个坐标轴这个维度上，取哪个值才能正好也落在平面上。\n\n所以平面的截距式是 \\(\\frac{x_0}{i_0} + \\frac{x_1}{i_1} + \\frac{x_2}{i_2} = 1\\);\n这里的 \\(i\\) 才是真正的 “截距”。\n\n三维空间的二维平面这里有四个参数，但是实际上平面的维度是2，这是为什么呢？首先这是个方程决定的点集，而不是通过函数决定的点集，方程左右同时乘k仍然成立，所以少一个自由度。那还有一个参数呢？平面维度是2的意思是，你确定点在这个平面上的时候，两个坐标可以描述上面的点，这个2和需要多少个参数来描述这个平面自身在三维空间的位置是两回事。那为什么n维空间的超平面需要n-1个参数来描述呢？这里其实还有些数学细节可以深入探讨，TODO。\n\n点法式是\\(\\vec{w} \\cdot (\\vec{x}-\\vec{x_0})=0\\), \\(w\\)和一般式的一样都是法向量(可长可短，方向是那个方向)。\n\n注意李航书的符号规范上不用\\(\\vec{向量箭头}\\)。\n这个很好理解，平面上一个点\\(x_0\\) 与 真的在直线上的点 \\(x\\) 的差的向量，必然还是在平面上的，所以 这个差向量 和 法向量垂直。\n稍微变一下就是 \\(w\\cdot x + (- w\\cdot x_0) = 0\\),\n\\(D = - w\\cdot x_0\\) ，如果 \\(||w||_2 = 1\\), 在这个情况下， \\(D\\)是有意义的，表示 某个平面上的点投影到法向量方向上的长度，那实际上就是从坐标原点0向量到达平面的垂直距离（最短距离），也就是说李航就算要说\\(b\\)是什么，也应该说它是“到原点距离”，而不是“截距”，何况这是有条件的。\n\n\n什么是最大间隔？函数间隔与几何间隔是什么？\n什么是间隔边界？\n\n复习之后，我们清晰看到题目询问的问题。\n首先对正例点 \\(x_1=(1,2)^T\\), \\(x_2=(2,3)^T\\), \\(x_3=(3,3)^T\\), 负例点\\(x_4=(2,1)^T\\), \\(x_5=(3,2)^T\\) 可视化\n\nimport numpy as np\nX = np.array([\n    [1, 2], \n    [2, 3],\n    [3, 3],\n    [2, 1], \n    [3, 2]\n])\ny = np.array([1]*3 + [-1]*2)\n\n\nsource\n\n\n1.2 plot_binary_classification_2d\n\n plot_binary_classification_2d (X, y, labels=[1, -1], label_names=['正例',\n                                '负例'], label_colors=['blue', 'red'],\n                                label_markers=['o', 'x'], x_names=['x(1)',\n                                'x(2)'], point_size=100, text_offset=(0.1,\n                                0), point_names=None, title='数据点可视化',\n                                size=(9, 6))\n\n\n# 显示图表\nfig, ax = plot_binary_classification_2d(X, y)\n\n\n\n\n\n\n\n\n要求找出上图的最大间隔分离超平面，以及对应的分类决策函数；\n然后再图上画出分离超平面、间隔边界及支持向量。\n\n\n1.3 解题\n\n1.3.1 解法一：几何观察法（考试写填空题）\n由图像可知，分离超平面应当在x4和x5构成的直线的上方，x1和x3构成直线的下方。\n注意到这两条直线的斜率不同。如果是x1和x4的中线作为分割超平面，x3无法分对。\n所以应当是x1和x3联合起来一起作为正例的支持向量，然后x5对他们构成的直线做垂直线，然后垂直线的中线就是最大间隔的分割超平面。\n\nfig, ax = plot_binary_classification_2d(X, y, title=\"SVM可视化\")\n# 绘制x1x3构成的直线\nx1, x3 = X[0], X[2]\nline_x = np.array([x1[0], x3[0]])\nline_y = np.array([x1[1], x3[1]])\n# ax.plot(line_x, line_y, color='green', linestyle='--', label='间隔边界')\nax.axline((x1[0], x1[1]), (x3[0], x3[1]), color='green', linestyle='--', label='间隔边界')\n\n# 计算x1x3直线的斜率和截距\nslope = (line_y[1] - line_y[0]) / (line_x[1] - line_x[0])\nintercept = line_y[0] - slope * line_x[0]\n\n# 计算x5到x1x3直线的垂线交点P\nx5 = X[4]\nperpendicular_slope = -1 / slope\nperpendicular_intercept = x5[1] - perpendicular_slope * x5[0]\np_x = (intercept - perpendicular_intercept) / (perpendicular_slope - slope)\np_y = slope * p_x + intercept\n\n# 绘制垂线交点P\nax.plot(p_x, p_y, 'o', color='orange', label='交点P')\nax.text(p_x + 0.1, p_y, f' P ({p_x}, {p_y})', fontsize=12, ha='left')\n\n# 计算垂线中点\nmid_x = (p_x + x5[0]) / 2\nmid_y = (p_y + x5[1]) / 2\nax.plot(mid_x, mid_y, 'o', color='orange', label='中点 M')\nax.text(mid_x + 0.1, mid_y, f' M ({mid_x}, {mid_y})', fontsize=12, ha='left')\n\n\n# 绘制箭头：中点到交点\nax.annotate('', xy=(p_x, p_y), xytext=(mid_x, mid_y),\n            arrowprops=dict(facecolor='orange', arrowstyle=\"-&gt;\"))\n\n# 绘制箭头：中点到x5\nax.annotate('', xy=(x5[0], x5[1]), xytext=(mid_x, mid_y),\n            arrowprops=dict(facecolor='orange', arrowstyle=\"-&gt;\"))\n\n# 绘制Px5的中垂线\nmid_x = (p_x + x5[0]) / 2\nmid_y = (p_y + x5[1]) / 2\nmid_slope = -(x5[0] - p_x) / (x5[1] - p_y)\nmid_intercept = mid_y - mid_slope * mid_x\nx_values = np.linspace(mid_x - 1, mid_x + 1, 100)\ny_values = mid_slope * x_values + mid_intercept\n# ax.plot(x_values, y_values, color='black', linestyle='-', label='分割超平面')\nax.axline((mid_x, mid_y), slope=mid_slope, color='black', linestyle='-', label='分割超平面')\n\n\n\n# 计算过x5点且斜率与x1x3相同的直线方程\nx5_line_x = np.array([x5[0], x5[0] + 1])  # 创建一个x值数组，第二个点x值比x5大1\nx5_line_y = slope * x5_line_x + (x5[1] - slope * x5[0])  # 计算对应的y值\n\n# 绘制过x5点的直线\n# ax.plot(x5_line_x, x5_line_y, color='green', linestyle='--', label='间隔边界')\n# 绘制过x5点且斜率与x1x3相同的直线\nax.axline((x5[0], x5[1]), slope=slope, color='green', linestyle='--', label='间隔边界')\n\n# 标注支持向量\n\nsupport_vector_indices = [1, 3, 5]  # 假设x1, x3, x5的索引分别是0, 2, 4\nfor idx in support_vector_indices:\n    i = idx-1\n    ax.scatter(X[i, 0], X[i, 1], marker='o', facecolors='none', \n               edgecolors='purple', s=100*2,  # color='purple',\n               label='支持向量' if i == 0 else \"\")\n\n# 添加图例\nax.legend()\n# ax.set_xlim([0, 6])\n# ax.set_ylim([0, 4])\nfig.set_size_inches(9, 6)\n\n# 这一句非常重要，要不然图中的垂直线都不垂直\nax.set_aspect('equal', adjustable='box') # https://stackoverflow.com/questions/17990845/how-do-i-equalize-the-scales-of-the-x-axis-and-y-axis\n\nax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n注记\n\n\n\n本解法不太好写在考试的解答题里面，可以写在选择题填空题里面加快速度。不对于AI研究而言，关键是无法适用于高维的情况自动求解。\n\n\n\n\n1.3.2 解法二：手算推导法（考试写解答题）\n我们不用对偶问题，直接用原始问题来求。也就是\n\\[\n\\min_{w, b} \\frac{1}{2} ||w||^2 \\\\\ns.t. y_i (w \\cdot x_i + b) -1 \\ge 0 , \\forall i = 1,2,...,N\\\\\n\\]\n记 w = (A, B), b=C\n\\[\nA+2B+C \\ge 1 \\\\\n2A+3B+C \\ge 1 \\\\\n3A+3B+C \\ge 1 \\\\\n2A+B+C \\le -1 \\\\\n3A+2B+C \\le -1 \\\\\n\\]\n\nfrom sympy import symbols, solve, And\n\n# 定义变量\nA, B, C = symbols('A B C')\nl = [A, B, C]\n\n# 定义不等式组\ninequalities = [\n    A + 2*B + C &gt;= 1,\n    2*A + 3*B + C &gt;= 1,\n    3*A + 3*B + C &gt;= 1,\n    2*A + B + C &lt;= -1,\n    3*A + 2*B + C &lt;= -1\n]\n\n# 解不等式组\nsolutions = [solve(inequalities, (i)) for i in l]\n\n\nsolutions[0]\n\n\\(\\displaystyle A \\geq - 2 B - C + 1 \\wedge A \\geq - \\frac{3 B}{2} - \\frac{C}{2} + \\frac{1}{2} \\wedge A \\geq - B - \\frac{C}{3} + \\frac{1}{3} \\wedge A \\leq - \\frac{2 B}{3} - \\frac{C}{3} - \\frac{1}{3} \\wedge A \\leq - \\frac{B}{2} - \\frac{C}{2} - \\frac{1}{2} \\wedge -\\infty &lt; A \\wedge A &lt; \\infty\\)\n\n\n\nsolutions[1]\n\n\\(\\displaystyle B \\geq - A - \\frac{C}{3} + \\frac{1}{3} \\wedge B \\geq - \\frac{2 A}{3} - \\frac{C}{3} + \\frac{1}{3} \\wedge B \\geq - \\frac{A}{2} - \\frac{C}{2} + \\frac{1}{2} \\wedge B \\leq - 2 A - C - 1 \\wedge B \\leq - \\frac{3 A}{2} - \\frac{C}{2} - \\frac{1}{2} \\wedge -\\infty &lt; B \\wedge B &lt; \\infty\\)\n\n\n\nsolutions[2]\n\n\\(\\displaystyle C \\geq - 3 A - 3 B + 1 \\wedge C \\geq - 2 A - 3 B + 1 \\wedge C \\geq - A - 2 B + 1 \\wedge C \\leq - 3 A - 2 B - 1 \\wedge C \\leq - 2 A - B - 1 \\wedge -\\infty &lt; C \\wedge C &lt; \\infty\\)\n\n\n可见这个优化问题对于考场上来说其实是不现实的，太多可能性了，没法推导出具体的东西。我们可以用凸二次规划来求解。\n\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# 定义目标函数\ndef objective(x):\n    A, B = x\n    return 0.5 * (A**2 + B**2)\n\n# 定义线性不等式约束\ndef constraint(x):\n    A, B = x\n    return np.array([\n        A + 2*B + 1,    # A + 2B + C &gt;= 1，这里C默认为1\n        2*A + 3*B + 1,  # 2A + 3B + C &gt;= 1\n        3*A + 3*B + 1,  # 3A + 3B + C &gt;= 1\n       -2*A - B - 1,   # 2A + B + C &lt;= -1\n       -3*A - 2*B - 1  # 3A + 2B + C &lt;= -1\n    ])\n\n# 约束条件，类型为'ineq'表示不等式约束\ncon = {'type': 'ineq', 'fun': constraint}\n\n# 初始猜测值\nx0 = [0, 0]\n\n# 调用 minimize 函数求解\nsol = minimize(objective, x0, constraints=con, method='SLSQP')\n\n# 输出结果\nif sol.success:\n    print('最优解：', sol.x)\n    print('目标函数的最小值：', sol.fun)\nelse:\n    print('求解失败')\n\n最优解： [-0.66666667  0.33333333]\n目标函数的最小值： 0.2777777777777774\n\n\n由于解法1已经进行了详细可视化，这里我们只是计算确认了一下，可视化的结果与解法1一样，因而不再赘述重画。\n我们还可以使用对偶问题，然后观察 \\(\\alpha\\)是否严格大于0，来发现支持向量，然后再用解法1中作中垂线的方法来求分离超平面，这里篇幅有限，就不再详细介绍了。\n\n\n1.3.3 解法三：使用Python和机器学习库（科研使用）\n参考 https://scikit-learn.org/0.19/auto_examples/svm/plot_iris.html\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, datasets\n\n\nsource\n\n\n\n1.4 try_svm_and_plot_for_binary_2d\n\n try_svm_and_plot_for_binary_2d (X, y, C=1.0, x_names=['x(1)', 'x(2)'])\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\n\n\n\n\n\ny\n\n\n\n\n\nC\nfloat\n1.0\n软间隔的惩罚项, &gt;0\n\n\nx_names\nlist\n[‘x(1)’, ‘x(2)’]\n\n\n\n\n\nsource\n\n\n1.5 plot_contours\n\n plot_contours (ax, clf, xx, yy, **params)\n\n\nsource\n\n\n1.6 make_meshgrid\n\n make_meshgrid (x, y, h=0.02)\n\n\ntry_svm_and_plot_for_binary_2d(X, y)\npass\n\n\n\n\n\n\n\n\n上面的两个图是是线性支持向量机，理论上应该和我们上面的结果一样，然而看起来却有点不同。\n这是因为我们使用的是软间隔支持向量机，C参数设置为1太小了，C趋近于无穷的时候，才和硬间隔情况一样。我们修改C重试一下。\n\ntry_svm_and_plot_for_binary_2d(X, y, C=1000000)\npass\n\n\n\n\n\n\n\n\n这一次图1和我们的结果是一样的了。 由于解法1中可视化很全面，我们对于支持向量、分割平面不再赘述重画。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A5",
      "支持向量机的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A5/p_assignment5_yecanming.html#sec-2",
    "href": "theory_assignments/A5/p_assignment5_yecanming.html#sec-2",
    "title": "支持向量机的深入理解",
    "section": "2 第二题——理解软间隔支持向量机以及其对偶形式",
    "text": "2 第二题——理解软间隔支持向量机以及其对偶形式\n题目如下 &gt; 线性支持向量机还可以定义为以下形式: &gt; \\[\\min_{w,b,\\xi}\\frac{1}{2}||w||^2+C\\sum_{i=1}^{N}\\xi_i^2\\] &gt; \\[s.t.\\ y_i(w\\cdot x_i+b)\\geq1-\\xi_i,\\ i=1,2,\\cdots,N \\\\ \\xi_i\\geq0,\\ i=1,2,\\cdots,N\\] &gt; &gt; 试求其对偶形式。\n\n2.1 审题\n\n题目中“还可以定义为以下形式”是什么意思？题目中给的形式是李航书上的哪个形式的变种吗？\n\n实际上，题目给的形式是李航书上软间隔线性支持向量机的凸二次规划问题（原始问题）的形式的变种。\n统计学习书126页给出的优化问题是 \\[\\min_{w,b,\\xi}\\frac{1}{2}||w||^2+C\\sum_{i=1}^{N}\\xi_i\\]\n约束条件与本题一样，但是优化目标本题变种形式是\\(\\xi_i^2\\)，原本的形式是 \\(\\xi_i\\)\n\n变种问题有什么意义？\n\n引入软间隔的时候，我们约束条件都是说，用每个样本自己的松弛变量（slack variable）把它拉回正轨，让函数间隔大于1。\n为了防止学习器摆烂，直接用松弛变量结束游戏，最小化的目标问题中加入惩罚项，惩罚松弛变量。\n所以具体怎么惩罚是可以人为规定的。\n函数间隔正是分对了，负是分错了，负的多的分错的多，需要拉回1所需要的松弛变量大。松弛变量是正数，因为不能反着拉。\n如果分对了，松弛变量\n李航的书缺乏proper reference，所以读者只好自己找找是谁提出了这个变种。\n\n论文指出，https://orsj.org/wp-content/or-archives50/pdf/e_mag/Vol.60_03_262.pdf\nslack varible的惩罚项平方对于非线性问题的优化更好。\n但是这个这里不是针对SVM讲的，我不确定SVM里面的slack variable与论文中说的一般的优化问题的是否是一个含义。\n\n\n在目前常用的SVM里面用到的是哪个形式？\n\n根据sklearn，https://scikit-learn.org/stable/modules/svm.html#svc\nSVC使用的还是书上的那个普通形式，不是本题的形式。\n\n\n\n\n2.2 解题\n对于原问题 &gt; \\[\\min_{w,b,\\xi}\\frac{1}{2}||w||^2+C\\sum_{i=1}^{N}\\xi_i^2\\] &gt; \\[s.t.\\ y_i(w\\cdot x_i+b)\\geq1-\\xi_i,\\ i=1,2,\\cdots,N \\\\ \\xi_i\\geq0,\\ i=1,2,\\cdots,N\\]\n构建拉格朗日函数。为此，为不等式约束引入一组拉格朗日乘子 \\(\\alpha\\ge 0\\) \\(\\beta\\ge 0\\)。\n\\[ L(w, b, \\xi, \\alpha, \\beta) = \\frac{1}{2}||w||^2+C\\sum_{i=1}^{N}\\xi_i^2  - \\sum_{i=1}^{N}\\alpha_i[y_i(w\\cdot x_i+b)-1+\\xi_i] - \\sum_{i=1}^{N}\\beta_i\\xi_i \\]\n那么原问题就等价于求解让 \\[ \\min_{w,b,\\xi} \\max_{\\alpha, \\beta} L(w, b, \\xi, \\alpha, \\beta) \\] 最小的那个 \\(w, b, \\xi\\) 值， 因为这相当于遍历了所有的 \\(w, b, \\xi\\) 组合，如果不符合约束 \\(\\alpha, \\beta\\)一下子就可以飞到正无穷，然后把整个值变的很高，这样的\\(w, b, \\xi\\) 自然就被排除了，剩下的满足约束条件的, \\(\\alpha, \\beta\\)不敢轻举妄动，只好点出最优值0, 这个情况下搜索就和原本的一模一样，同时我们还去掉了约束（引入了拉格朗日乘子 \\(\\alpha, \\beta \\ge 0\\)的新约束，当然\\(\\xi \\ge 0\\)也别忘了）。\n而原问题的对偶问题就是翻转一下极小极大为极大极小，即：\n\\[ \\max_{\\alpha, \\beta} \\min_{w,b,\\xi} L(w, b, \\xi, \\alpha, \\beta) \\]\n\n假如外围\\(\\max\\)问题遍历过程中给定了 \\(\\alpha, \\beta\\)的具体值，我们就可以求解里面的\\(\\min\\)问题，这个时候暂时把\\(\\alpha, \\beta\\)当做常数，而里面的问题可以求导来求解。\n令下面式子为0 \\[\\nabla_w L(w, b, \\xi, \\alpha, \\beta) = w - \\sum_{i=1}^N \\alpha_i y_i x_i  = 0\\] \\[\\nabla_b L(w, b, \\xi, \\alpha, \\beta) = - \\sum_{i=1}^N \\alpha_i y_i = 0\\]\n\n\\[\\nabla_{\\xi_i} L(w, b, \\xi, \\alpha, \\beta) = 2\\cdot C \\cdot \\xi_i - \\alpha_i - \\beta_i = 0\\]\n其中第三个式子和统计学习127页的普通形式不同，我们的是平方过的，所以求导后还和 \\(\\xi\\)有关。 还要注意第三个式子是很容易犯错的，最好对每一个具体的 \\(\\xi_i\\)求导，而不是对一个整体向量 \\(\\xi\\)求导。\n得 \\[w = \\sum_{i=1}^N \\alpha_i y_i x_i\\] \\[\\sum_{i=1}^N \\alpha_i y_i = 0\\] \\[ \\xi_i  = \\frac{1}{2\\cdot C} (\\alpha_i + \\beta_i)\\]\n由于求导数为0是取得极值的必要条件，所以在取得min的情况下，可以代入上面的式子回到L，所以可以说 \\[\\min_{w,b,\\xi} L(w, b, \\xi, \\alpha, \\beta) = (\\frac{1}{2}(\\sum_{i=1}^N \\alpha_i y_i x_i)^2 ) + (C \\sum_{i=1}^N \\frac{1}{2\\cdot C} (\\alpha_i + \\beta_i)) - \\sum_{i=1}^{N}\\alpha_i[y_i((\\sum_{j=1}^N \\alpha_j y_j x_j) \\cdot x_i+b)-1+\\frac{1}{2\\cdot C} (\\alpha_i + \\beta_i)] - \\sum_{i=1}^{N}\\beta_i\\frac{1}{2\\cdot C} (\\alpha_i + \\beta_i)\n\\]\n\n由于 \\(\\alpha, \\beta, C\\)是常数，很多项对于优化无用, 所以\n\\[\\argmin_{w,b, \\xi} L(w, b, \\xi, \\alpha, \\beta) = \\argmin_{w,b} M(w, b)\\]\n我们定义 \\[\nM(w, b) = (\\frac{1}{2}(\\sum_{i=1}^N \\alpha_i y_i x_i)^2 ) - \\sum_{i=1}^{N}\\alpha_i[y_i((\\sum_{j=1}^N \\alpha_j y_j x_j) \\cdot x_i+b)]\n\\]\n平常确实是这样，但是这里我们其实不能消去\\(\\alpha, \\beta, C\\)，因为 我们下一步要最大化函数，所以我们只能老老实实代入原本的L。\n\n经过一番激烈化简，我们得到 在min的情况下，\n\\[\n\\min_{w,b,\\xi} L(w, b, \\xi, \\alpha, \\beta) = -\\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{N}\\alpha_i-\\frac{1}{4C}\\sum_{i=1}^{N}(\\alpha_i+\\beta_i)^2\n\\]\n注意和统计学习书127页比，多了 \\(-\\frac{1}{4C}\\sum_{i=1}^{N}(\\alpha_i+\\beta_i)^2\\)\n接下来 求解 \\(\\max_{\\alpha, \\beta} \\min_{w,b,\\xi} L(w, b, \\xi, \\alpha, \\beta)\\)\n等价于求解 \\[\n\\max_{\\alpha, \\beta} -\\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{N}\\alpha_i-\\frac{1}{4C}\\sum_{i=1}^{N}(\\alpha_i+\\beta_i)^2\n\\]\n完整地来说还有乘子以及刚才求导带来的约束条件 \\[\n\\sum_{i=1}^N \\alpha_i y_i = 0\\\\\n\\alpha_i \\geq 0\\\\   \n\\beta_i \\geq 0\\\\\n\\xi_i  = \\frac{1}{2\\cdot C} (\\alpha_i + \\beta_i) \\ge 0\n\\]\n注意之所有有最后一个式子，是因为 \\(\\xi_i \\ge 0\\)也是一个没有被处理掉的约束条件，所以我们需要这样来重新表达为对 \\(\\alpha, \\beta\\)的约束条件，如果这个忘记了式子就不对了。不过我们马上就发现, 惩罚代价\\(C\\gt 0\\)严格大于0，所以这个约束自然是满足的，当场就可以去掉。\n李航书上最后把 \\(\\mu_i\\)去掉了，简化了问题为\\(\\alpha\\)的最大化问题，这里我们能不能一样操作呢？答案是肯定的。\n我们注意到优化问题 其实对于 \\(\\beta\\) 来说很简单，因为最后一项是正数，所以 其他东西给定时，\\(\\beta_i = 0\\)就可以让问题取到最大，同时这永远不会违反约束条件。所以我们的问题又可以进一步简化到只和 \\(\\alpha\\) 有关！\n\\[\n\\max_{\\alpha} -\\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{N}(\\alpha_i-\\frac{1}{4C}\\alpha_i^2) \\\\\ns.t. \\sum_{i=1}^N \\alpha_i y_i = 0\\\\\n\\alpha_i \\geq 0\\\\   \n\\]\n上面这个就是软间隔支持向量机变种形式的原始问题的对偶问题化简后的形式！\n\n李航书上进一步推导了一下此时对应的分割超平面的形式，这个超平面的分类决策函数的式子才叫做SVM的对偶形式，所以我们还要再推导一下。\n由于问题仍然是凸二次规划问题，所以根据书上定理C.2， 对偶问题和原问题也是等价的，根据C.3还额外可以满足KKT条件(约束满足、刚才的求导=0满足，而且额外地，要不乘子为0，要不约束为0)，所以类似于 书上定理7.3， $$ w^* = _{i=1}^N _i^* y_i x_i \\\n_i[y_i(wx_i+b)-1+_i] = 0 \\\n_i_i = 0 $$ 其中后面两个式子是KKT条件特别的部分，告诉我们要不约束是0，要不乘子为0。\n这里和书上有所不同，\\(\\beta_i=0\\) \\(\\xi_i\\)不一定是0,\\(\\xi_i  = \\frac{1}{2\\cdot C}\\alpha_i\\)\n如果存在一个 \\(\\alpha_i^* &gt; 0\\) (即支持向量), 那么$y_i(wx_i+b)-1+_i = y_i(wx_i+b)-1+_i =0 $ 我们可以根据支持向量去反推出 \\(b^*\\)。\n\\[\nb^* = \\frac{1- \\frac{1}{2\\cdot C}\\alpha_i}{y_i} - w^* \\cdot x_i\n\\]\n所以分类决策函数为 \\[\nf(x) = \\text{sign}(w^* \\cdot x + b^*)\n\\] 为题目所求对偶形式。\n\n\n2.3 题目扩展问题",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A5",
      "支持向量机的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A1/p_assignment1_yecanming.html#第一题",
    "href": "theory_assignments/A1/p_assignment1_yecanming.html#第一题",
    "title": "从数据集中进行分布参数估计: 以伯努利分布为例",
    "section": "第一题",
    "text": "第一题\n题目如下\n\n说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型n次独立的数据生成结果，其中k次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。\n\n\n审题\n\n题目出处？（题目中的概念是哪一本书的定义？）\n\n李航《统计学习方法》\n\n李航对于“模型”的定义是什么？\n\n见下一个疑问\n\n李航的书里是怎么定义“统计学习方法三要素”的？\n\n方法=模型+策略+算法\n模型 model\n\n书上定义：所要学习的条件概率分布或者决策函数；需要给出一个假设空间来包括所有可能的这个分布或者函数。\n相当于定义了输入输出，定义搜索的空间\n这一道题中“伯努利模型”意思是这个模型要学习的就是一个不知道参数的伯努利分布\n\n策略 strategy\n\n书上定义：按照什么样的准则从假设空间中学习或者选择最优的模型。损失函数度量一次预测的好坏，风险函数度量平均意义下的好坏。\n相当于定义了“How to measure?”\n风险函数是联合分布下期望的损失函数值\n\n算法 algorithm\n\n书上定义：根据策略，通过计算方法求解最优模型，通过不同的最优化算法，比如解析解或者数值计算。\n相当于定义了How to search/Optimize“\n\n\n伯努利分布 Bernoulli distribution 复习\n\n=两点分布=0-1分布\n伯努利试验：单次实验的结果或1或0；与泊松实验不同\n\n\n\n\n解题\n\n1. 伯努利模型的极大似然估计\n\n1.1 三要素的识别\n\n模型\n\n所要学习的分布：\\(X\\sim Bern(p)\\)\n\nP(X=1) = p, P(X=0) = 1-p\n统一一下形式: \\(P(x) = p^x(1-p)^{(1-x)}\\)， \\(x\\in\\set{0, 1}\\)\n\n注：如果p=1或者0，这个式子定义不良，我们需要补充规定\\(0^0=1\\)。\n\n\n参数空间: \\(p\\in[0, 1]\\)\n假设空间：\\(\\mathcal{F}=\\{P_p|P_p(x)=p^x(1-p)^{(1-x)}, p\\in [0, 1]\\}\\)\n\n注：李航书16页中的集合表示是错误的\n\n如果按照李航书中的表示，这里我们会写成\\(\\mathcal{F}=\\{P|P_p(x)=p^x(1-p)^{(1-x)}, p\\in [0, 1]\\}\\)\n然而，这个集合只有一个元素“P”，P是固定的单一函数（是关于p和x的二元函数），形式已经完全确定了（就是上面的伯努利分布的形式）。\n只有一个元素自然不能表示“所有可能的条件概率分布或决策函数”，我们必须用\\(P_p\\)写在左边，右边指出了p具有取值范围，这才正确地用集合表示法获得了所有分布的一个集合。\n\n\n注：这里条件概率分布没有条件（或者说条件为空），因为我们是在做density estimation\n\n策略\n\n策略是说，给定一个猜测的参数p，还有观测数据\\(x_{1:n}\\)，可以评价p猜测的是否合理。\n最大似然估计用似然概率的大小来评价\n似然概率是指，给定p之后，观测数据出现的概率\n\\(Like(p) = P(x_{1:n} | p)\\)， 由于数据i.i.d.,\n\\(Like(p) =\\prod_{i=1}^n P(x_i|p) = \\prod_{i=1}^n p^{x_i}(1-p)^{(1-x_i)}\\)\n题目中，没有告诉我们每个\\(x_i\\)是多少，只是告诉我们\\(\\sum_{i=1}^{n}x_i = k\\)\n不过这个也足够我们化简上式为\\(Like(p) = p^{k}(1-p)^{(n-k)}\\)\n注：\\(\\binom{n}{k}p^k(1-p)^{(n-k)}\\)是典型的错误答案，虽然不影响求解的结果\n\n。错误答案中的概率表示做n次伯努利实验得到k次正例的所有情况\n但是本题中我们只进行了一次“n次伯努利实验”，有具体的实验结果\\(x_{1:n}\\)， 不是进行了多次”n次伯努利实验”然后统计\\(k_{1:m}\\)，是其中具体的一次情况。\n那样的话我们的模型就变成了二项分布，而不是本题的伯努利分布模型。\n\n\n算法\n\n极大似然估计的算法就是找到\\(p\\)让似然概率最大化。\n\\(\\displaystyle \\mathop{\\arg\\max}_{p} Like(p)= p^{k}(1-p)^{(n-k)}\\)\n对于本模型可以获得解析解，具体1.2所示。\n\n\n\n\n1.2 具体的求解\n求函数\\(Like(p)\\)的最小值，首先显然\\(Like(p)\\)是连续可导的，所以最小值一定在critical point或者边缘0, 1上。\n\\(Like^\\prime(p)= kp^{k-1}(1-p)^{(n-k)}-(n-k)p^k(1-p)^{(n-k-1)}\\)\n我们还可以学习一下python的sympy库辅助我们求导，防止人工求导抄错了\n\n\n代码\nfrom sympy import *\np, n, k = symbols('p n k')\nlike = p**k * (1-p)**(n-k)\nlike_prime = diff(like, p)\nlike_prime\n\n\n\\(\\displaystyle \\frac{k p^{k} \\left(1 - p\\right)^{- k + n}}{p} + \\frac{p^{k} \\left(1 - p\\right)^{- k + n} \\left(k - n\\right)}{1 - p}\\)\n\n\n令\\(Like^{\\prime}(p) = 0\\) 。这些p称为critical point，这些点可能是极值点可能不是。\n\\(kp^{k-1}(1-p)^{(n-k)}=(n-k)p^k(1-p)^{(n-k-1)}\\)\n\\(k(1-p) = (n-k)p\\)\n\\(k-kp = (n-k)p\\)\n\\(k = np\\)\n\\(p=\\frac{n}{k}\\) 为唯一解\n同样的，我们可以用Python做验证\n\n\n代码\neq = Eq(like_prime, 0)\nsolutions:list = solve(eq, p) \nassert len(solutions)!=0\npo = solutions[0]\npo\n\n\n\\(\\displaystyle \\frac{k}{n}\\)\n\n\n代入并且比较Like(0), Like(1)和Like(p)， 发现\\(Like(p)\\ge Like(1)\\and Like(p)\\ge Like(0)\\)，所以\\(Like(p)\\)就是最小值（之一，如果n=k或者k=0）。\n此时，\\(Like(p) = \\left(\\frac{k}{n}\\right)^{k} \\left(\\frac{- k + n}{n}\\right)^{- k + n}\\)\nPython可以代入p为求解出来的p，得到上面的表达式。\n\n\n代码\nlike_po = like.subs(p, po)\nlike_po\n\n\n\\(\\displaystyle \\left(\\frac{k}{n}\\right)^{k} \\left(- \\frac{k}{n} + 1\\right)^{- k + n}\\)\n\n\n\n\n\n2. 伯努利模型的贝叶斯估计\n注：在PRML书中，贝叶斯估计也叫做Maximum a Posterior(MAP, 极大后验估计)\n\n2.1 三要素的识别\n\n模型\n\n与上文1.1一致，都是伯努利模型，不再赘述。\n\n策略\n\n策略是说，给定一个猜测的参数p，还有观测数据\\(x_{1:n}\\)，可以评价p猜测的是否合理。\n最大似然估计用p的似然概率（实际上是观测数据的出现概率）来估计，而贝叶斯估计用p的后验概率来估计。\n后验概率是\\(P(p|x_{1:n})\\), 根据贝叶斯公式\n\\(P(p|x_{1:n}) =\\frac{P(x_{1:n}|p)*P(p)}{P(x_{1:n})} = \\frac{likelihood*prior}{evidence}\\)\n\n算法\n\n极大后验估计的算法就是找到\\(p\\)让后验概率最大化。\n\\(\\displaystyle \\mathop{\\arg\\max}_{p} P(p|x_{1:n})= \\frac{P(x_{1:n}|p)*P(p)}{P(x_{1:n})}\\)\n对于本模型，对于不同的先验概率P(p)会有不同的情况，有一些可以获得解析解，具体2.2所示。\n\n\n\n\n2.2 具体的求解\n由于题目中没有给出p的先验概率分布，\n\n2.2.1 不妨认为参数p服从均匀分布，\\(p\\sim U[0, 1]\\), 也就是说p的先验概率为均匀分布，那么$P(p) = =1,p$\n\n注，这P是连续随机变量的概率密度函数\n\n\\(P(p|x_{1:n})\\)的分母是一个正的相对于p的常数，对于求最大值而言可以去除。\n那么此时原优化目标变为 \\(\\displaystyle \\mathop{\\arg\\max}_{p} P(x_{1:n}|p)*P(p) = P(x_{1:n}|p)\\)， 贝叶斯估计退化为极大似然估计，我们得到的结论和过程与上文1.2所述完全一致。\n\n\n2.2.2 如果认为参数p服从\\(\\beta\\)分布，我们能获得更加有意思的结果，这个在PRML书中有讲到。\n\\(\\beta\\)分布的密度函数是这样的\\(P(p) = \\beta(p;a,b) = \\frac{p^{a-1}(1-p)^{b-1}}{C}\\), a和b是这个分布的参数，C是使得概率密度函数积分为1的一个常数，在这里不重要。\n\\(\\displaystyle \\mathop{\\arg\\max}_{p} P(x_{1:n}|p)*P(p) = P(x_{1:n}|p)*\\beta(p;a,b)\\)\n求解极值问题等价于求解log之后的极值问题。\n\n\n代码\na, b = symbols('a b')\nbeta = p**(a-1)*(1-p)**(b-1)\nposterior = like*beta\nposterior = log(posterior)\nposterior\n\n\n\\(\\displaystyle \\log{\\left(p^{k} p^{a - 1} \\left(1 - p\\right)^{b - 1} \\left(1 - p\\right)^{- k + n} \\right)}\\)\n\n\n类似于1.2，我们来求导数。\n\n\n代码\nposterior_prime = diff(posterior, p)\neq = Eq(posterior_prime, 0)\nsolutions:list = solve(eq, p) \nsolutions\n\n\n[0**(1/(a + k - 1)),\n (a + k - 1)/(a + b + n - 2),\n 1 - 0**(1/(k - n)),\n 1 - 0**(1/(b - k + n - 1))]\n\n\n可以得到critical point为0, 1和 \\(\\frac{a + k - 1}{a + b + n - 2}\\)，同样的可以发现第三个解比较通用，涵盖了前两个解的情况，所以贝叶斯估计的结果是\\(p = \\frac{a + k - 1}{a + b + n - 2}\\)。如果a=b=1,那么和最大似然估计的结果一样。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A1",
      "从数据集中进行分布参数估计: 以伯努利分布为例"
    ]
  },
  {
    "objectID": "theory_assignments/A1/p_assignment1_yecanming.html#第二题",
    "href": "theory_assignments/A1/p_assignment1_yecanming.html#第二题",
    "title": "从数据集中进行分布参数估计: 以伯努利分布为例",
    "section": "第二题",
    "text": "第二题\n\n通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损\n失函数是对数损失函数时，经验风险最小化等价于极大似然估计。\n\n\n审题\n\n题目出处？（题目中的概念是哪一本书的定义？）\n\n李航《统计学习方法》\n\n李航书中“经验风险”和“对数损失函数”是怎么定义的？\n\n经验风险\\(R_{emp}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i))\\)\n对数损失函数\\(Loss(Y, P(Y|X)) = -logP(Y|X)\\)\n\n\n\n\n解题\n根据题意，当损失函数是对数损失函数时，经验风险为\n\\(R_{emp}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i))=\\frac{1}{N}\\sum_{i=1}^{N}-logP(y_i|x_i)\\)\n经验风险最小化是指\n\\(f = \\mathop{\\arg\\min}_{f} R_{emp}(f) = \\mathop{\\arg\\min}_{f} -\\sum_{i=1}^{N}logP(y_i|x_i)=\\mathop{\\arg\\max}_{f}\\sum_{i=1}^{N}logP(y_i|x_i)\\)\n由于log函数的性质，\n\\(f = \\mathop{\\arg\\max}_{f}\\prod_{i=1}^{N}P(y_i|x_i) = \\mathop{\\arg\\max}_{f}\\prod_{i=1}^{N}\\frac{P(y_i, x_i)}{P(x_i)}\\)，由于evidence概率\\(P(x_i)\\)与模型的参数无关，可以认为是一个常数，所以在优化中可以去除，注意这是重要的一个推导。\n\\(f = \\mathop{\\arg\\max}_{f}\\prod_{i=1}^{N}P(y_i, x_i) = \\mathop{\\arg\\max}_{f}\\prod_{i=1}^{N}P(y_i, x_i| f)\\)， 注意，在上文中李航书中的条件概率省略了f（而PRML书是没有省略的），比如上文的\\(P(Y|X)\\)实际上是\\(P(Y|X, f)\\)，这里我们为了和似然做比较，显式地加回来。\n由于数据i.i.d.\n\\(f = \\mathop{\\arg\\max}_{f}P(Y,X|f)\\), 而这就是极大似然估计，给定一个f，求出现这个数据集中的(X, Y)的出现概率，这个叫做似然。因此得证。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A1",
      "从数据集中进行分布参数估计: 以伯努利分布为例"
    ]
  },
  {
    "objectID": "theory_assignments/A1/p_assignment1_yecanming.html#附加题",
    "href": "theory_assignments/A1/p_assignment1_yecanming.html#附加题",
    "title": "从数据集中进行分布参数估计: 以伯努利分布为例",
    "section": "附加题",
    "text": "附加题\n\n考虑一个回归模型 $ f \\(,它的目标变量为\\)t=f(x,w,^2)+$，其中 \\(\\varepsilon\\) 是一个随机噪声，\\(\\varepsilon\\) 的概率密度为： \\[p(x)=\\frac{q}{2(2\\sigma ^2)^{\\frac{1}{q}}\\Gamma (\\frac{1}{q})}\\exp(-\\frac{|x|^q}{2\\sigma ^2})\\] 给定观测数据集 \\(Data=\\{(X,t)\\}= \\{(x_1,t_1)...(x_N,t_N)\\}\\),求f 关于参数 w 和 \\(\\sigma^2\\) 的对数似然函数。\n\n\n审题\n\n题目出处？\n\n推测是PRML上的\n\n\\(\\Gamma\\)是什么函数？\n\nΓ函数 - 维基百科，自由的百科全书 (wikipedia.org)\n是阶乘函数的一个扩展\n\n\n\n\n解题\n本题我们不知道f的形式，但是题目告诉了我们ground truth，也就是t的真实情况是一个已知的f函数加上一个噪声，f函数的未知参数需要我们根据极大似然估计来求出。\n似然函数本来是问我们，假如已知了\\(w,\\sigma^2\\)，对应数据集Data出现的概率是多少，也就是\\(P(Data|w,\\sigma^2)\\)。\n如果有了\\(w,\\sigma^2\\), f也知道，我们算出来的预测\\(\\hat{t}=f(x,w,\\sigma^2)\\)与t之间有差值，如果我们\\(w,\\sigma^2\\)就是真相，那么对应的差值就是真正的\\(\\varepsilon\\)，那么它就应该服从题目描述的那个分布，这个情况下，我们就能算出来\\(P(\\varepsilon)\\)，这个\\(P(\\varepsilon)\\)就是我们给定\\(w,\\sigma^2\\)情况下数据出现的概率。\n\\(LogLike(w,\\sigma^2) = logP(Data|w,\\sigma^2) = \\sum_{i=1}^{N}logP(\\varepsilon_i|w,\\sigma^2)) = \\sum_{i=1}^{N}log p(t_i-f(x_i, w,\\sigma^2); w,\\sigma^2)\\)\n带入题目给的概率密度p，这个式子变为\n$LogLike(w,^2) = _{i=1}^{N} ( (-) ) $\n利用log的性质\n\\(LogLike(w,\\sigma^2) = \\sum_{i=1}^{N} \\left( \\log(q) - \\log(2(2\\sigma^2)^{\\frac{1}{q}}\\Gamma(\\frac{1}{q})) - \\frac{|t_i - f(x_i, w, \\sigma^2)|^q}{2\\sigma^2} \\right)\\)\n最后一项和求和有关，其他都没有关系\n\\(LogLike(w,\\sigma^2) = N \\log(q) - N \\log(2(2\\sigma^2)^{\\frac{1}{q}}\\Gamma(\\frac{1}{q})) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} |t_i - f(x_i, w, \\sigma^2)|^q\\)\n由于没法继续进行化简，这个式子就是我们给出的答案。\n当我们做极大似然估计的时候，q和N是常数，所以损失函数为\n\\(Loss(w,\\sigma^2) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} |t_i - f(x_i, w, \\sigma^2)|^q + N \\log(2(2\\sigma^2)^{\\frac{1}{q}}\\Gamma(\\frac{1}{q}))\\)\n我们可以看到，这是用了误差绝对值的q次方来惩罚，然后后面增加了一个正则项防止\\(\\sigma^2\\)的值太大。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A1",
      "从数据集中进行分布参数估计: 以伯努利分布为例"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#绪论",
    "href": "coding_projects/P2_SVM/00svm.html#绪论",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "1 绪论",
    "text": "1 绪论",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#代码与文档格式说明",
    "href": "coding_projects/P2_SVM/00svm.html#代码与文档格式说明",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "2 代码与文档格式说明",
    "text": "2 代码与文档格式说明\n本文档使用Jupyter Notebook编写，所以同时包括了实验文档和实验代码。\n本次实验项目采用了 Quarto + nbdev 的系统来发布Jupyter Notebook, 因而我们的实验文档导出为pdf和html格式可以进行阅读，而我们的代码也导出为python模块形式，可以作为代码库被其他项目使用。\n我们这样做的好处是，避免单独管理一堆 .py 文件，防止代码冗余和同步混乱，py文件和pdf文件都是从.ipynb文件导出的，可以保证实验文档和代码的一致性。\n\n\n\n\n\n\n重要\n\n\n\n可以通过以下命令安装我们实验的代码：\npip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git\n我们的代码导出为了python模块形式，通过以下命令导入：\nfrom thu_big_data_ml.svm import *\n\n\nhttps://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git 是我们本次大数据机器学习课程实验的代码仓库地址，\n而这次作业中，我开发的另一个用于图像分类科研的开源项目有名的分类框架 (NamableClassify)也相应地进行了代码更新，把我们这次作业实现的SVM算法加入到了其中。接下来我们也会用到这个项目中的一些代码（比如分类评测指标）来完成本次作业。我还构建了我们课题组的基础依赖库ScholarlyInfrastructure，对标fastcore库，对AI科研经常会用到的一些基础性地、和Python语言的表达力有关的代码进行了整理，比如PyTorch模型检查、清晰的日志、实验参数管理、异常处理、argmax自动函数优化等。这里我们用到了实验参数管理功能，把SVM的超参数表达为随机变量，随即使用元参数优化算法进行搜索。\npip install git+https://github.com/2catycm/NamableClassify.git\npip install git+https://github.com/THU-CVML/ScholarlyInfrastructure.git\nfrom namable_classify import *\nfrom scholarly_infrastructure import *\n以上代码库开源在github，欢迎各位同学、老师们提出宝贵意见，或者加入我们的开发一起完善，构建更加优质的科研工具。\n\n\n\n\n\n\n重要\n\n\n\n本文档具有一定的交互性，建议使用浏览器打开html文件，这样比pdf文件阅读体验更佳。\n由于这次项目作业内容太多，为了便于管理，我们将项目文档和代码分为了不同几个部分。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#实验目的与项目要求",
    "href": "coding_projects/P2_SVM/00svm.html#实验目的与项目要求",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "3 实验目的与项目要求",
    "text": "3 实验目的与项目要求\n\n老师给我们的要求是\n\n⼿动实现一个 SVM 分类器，熟悉 SVM 的原理与优化求解 SVM 分类器的算法的过程。\nMNIST 数据集分类，报告你在测试集上的准确率，与已有SVM库进行对比。\n对 SVM 分类器训练的超参数(包括收敛终止条件，学习率等)进行调优\n构建使用 kernel 方法的 SVM 分类器\n对比不同 SVM 方法\n\n\n作为Top1大学的学生，我们不仅需要完成以上内容，还需要进行一些深入的思考和探索。\n\n现有最流行的SVM分类的实现是sklearn以及其背后的libsvm，由于C++编写，确实在CPU上运行很快。但是，如果我们需要在GPU上运行，是否可以考虑用CUDA等方法来加速呢？我们决定尝试一下实现速度更快的SVM分类器。\nsklearn自带的调参GridSearchCV和RandomizedSearchCV都具有一定的局限性。参考谷歌调参手册，我们使用科学的实验设计来对SVM分类算法的元参数进行搜索，从而实现更高的分类精度，并且获得一些insight，便于我们后续科研中使用SVM。\n实现自己的kernel方法。实现之后，不仅像2那样参考谷歌调参手册和假设检验来比较数值上的性能，还使用可视化工具来对不同核函数的效果进行比较。\n除了李航《统计学习方法》的介绍逻辑，也补充阅读周志华的《机器学习》西瓜书，加深对SVM的理解。进一步阅读深度学习时代的SVM前沿论文，探索一些更加新的SVM策略，为后续科研提供参考。\n\n事不宜迟，我们开始动手吧！",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#实验数据",
    "href": "coding_projects/P2_SVM/00svm.html#实验数据",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "4 实验数据",
    "text": "4 实验数据\n\nMNIST 数据库是由 Yann et. al. 提供的⼿写数字数据库⽂件, 官网地址为 http://yann.lecun.com/exdb/mnist/。 主要包含了 60000 张的训练图像和 10000 张的测试图像\n\n类似于上一次Project（KD树实现KNN），我们使用 sklearn CI（持续集成）测试用例的load_digits数据集，而不只是使用原始的MNIST数据集，来加快实验的效率。并且在划分数据集时，train_test_split应当使用stratify参数，以确保每一类样本的比例相同。\n\nfrom scholarly_infrastructure.logging.nucleus import logger, print\nfrom sklearn.datasets import load_digits, fetch_openml\n\n\n# dataset_dict_uci_digits = load_digits(as_frame=True)\ndataset_dict_uci_digits = load_digits(as_frame=False)\ndataset_dict_full_mnist = fetch_openml(\"mnist_784\", as_frame=True)\ndataset_dict_uci_digits.keys(), dataset_dict_full_mnist.keys()\n\n\n\n\n\n(\n    dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR']),\n    dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n)\n\n\n\n\ndataset_dict_uci_digits.target_names\n\n\n\n\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\n\nsource\n\n4.1 sklearn_to_X_y_categories\n\n sklearn_to_X_y_categories (dataset_dict)\n\n\n\nExported source\nimport pandas as pd\nimport numpy as np\n\n\n\n\nExported source\ndef sklearn_to_X_y_categories(dataset_dict):\n    X = dataset_dict['data']\n    y = dataset_dict['target']\n    if isinstance(X, pd.DataFrame):\n        X:np.array = X.values\n    if isinstance(y, pd.Series):\n        y:np.array = y.values\n    # if y.dtype.name == 'category':\n    #     categories = y.dtype.categories\n    # else:\n    X = X.astype(np.float32)\n    y = y.astype(np.int64)\n    categories = np.unique(y)\n    # print(str((X.shape, X.dtype, y.shape, y.dtype, categories)))\n    print(X.shape, X.dtype, y.shape, y.dtype, categories)\n    return X, y, categories\n\n\n\nX, y, categories = sklearn_to_X_y_categories(dataset_dict_uci_digits)\nX_full, y_full, categories_full = sklearn_to_X_y_categories(dataset_dict_full_mnist)\n\nSat 2024-11-16 22:11:02.268075\n\n\n\nINFO     ((1797, 64), dtype('float32'), (1797,), dtype('int64'), array([0, 1, 2, 3, 4, 5, 6, 7, 8,    nucleus.py:55\n         9]))                                                                                                      \n\n\n\nSat 2024-11-16 22:11:02.537849\n\n\n\nINFO     ((70000, 784), dtype('float32'), (70000,), dtype('int64'), array([0, 1, 2, 3, 4, 5, 6, 7, 8, nucleus.py:55\n         9]))                                                                                                      \n\n\n\n划分数据集为训练集和测试集。 注意这里与官方的mnist划分有所不同，但是是合理而且科学的，因为正确使用了stratify参数。\n\nsource\n\n\n4.2 make_train_val_test\n\n make_train_val_test (X, y, val_size=0.1, test_size=0.2, random_state=42,\n                      normalize=True)\n\n\n\nExported source\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nExported source\ndef make_train_val_test(X, y, val_size=0.1, test_size=0.2, random_state=42, normalize=True):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, \n                                                        stratify=y)\n    # print(len(X_train), len(X_test))\n    if normalize:\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n    # 进一步划分出验证集，用于调参、early stopping等。\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, \n                                                    stratify=y_train)\n    print(len(X_train), len(X_val), len(X_test))\n    return X_train, X_val, X_test, y_train, y_val, y_test\n\n\n\nX_train, X_val, X_test, y_train, y_val, y_test = make_train_val_test(X, y)\nX_train_full, X_val_full, X_test_full, y_train_full, y_val_full, y_test_full = make_train_val_test(X_full, y_full)\n\nSat 2024-11-16 22:11:02.748631\n\n\n\nINFO     (1293, 144, 360)                                                                             nucleus.py:55\n\n\n\nSat 2024-11-16 22:11:07.325810\n\n\n\nINFO     (50400, 5600, 14000)                                                                         nucleus.py:55\n\n\n\n获得 PyTorch 格式 的Dataset， 进一步得到 PyTorch Lightning 的 DataModule\n\nsource\n\n\n4.3 get_torch_dataset\n\n get_torch_dataset (X, y)\n\n\n\nExported source\nimport torch\nimport lightning as L\n\n\n\n\nExported source\ndef get_torch_dataset(X, y):\n    X_tensor = torch.tensor(X, dtype=torch.float32)\n    y_tensor = torch.tensor(y, dtype=torch.long)\n    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n    return dataset\n\n\n\ntrain_set = get_torch_dataset(X_train, y_train)\nval_set = get_torch_dataset(X_val, y_val)\ntest_set = get_torch_dataset(X_test, y_test)\ntrain_set_full = get_torch_dataset(X_train_full, y_train_full)\nval_set_full = get_torch_dataset(X_val_full, y_val_full)\ntest_set_full = get_torch_dataset(X_test_full, y_test_full)\n\n\nimport lightning as L\n\n\ndata_module = L.LightningDataModule.from_datasets(\n    train_dataset=train_set, \n    val_dataset=val_set, \n    test_dataset=test_set, \n    predict_dataset=test_set, \n    batch_size=128,  \n    num_workers=4\n)\ndata_module_full = L.LightningDataModule.from_datasets(\n    train_dataset=train_set_full, \n    val_dataset=val_set_full, \n    test_dataset=test_set_full, \n    predict_dataset=test_set_full, \n    batch_size=128,  \n    num_workers=4\n)\n\n\nsource\n\n\n4.4 process_sklearn_dataset_dict\n\n process_sklearn_dataset_dict (dataset_dict:dict,\n                               return_type:Literal['numpy','torch','lightn\n                               ing','pandas','all'])\n\n\n\nExported source\nfrom typing import Literal\n\n\n\n\nExported source\nReturnType = Literal['numpy', 'torch', 'lightning', 'pandas', 'all']\n\ndef process_sklearn_dataset_dict(dataset_dict:dict, return_type:ReturnType):\n    X, y, categories = sklearn_to_X_y_categories(dataset_dict)\n    X_train, X_val, X_test, y_train, y_val, y_test = make_train_val_test(X, y)\n    train_set = get_torch_dataset(X_train, y_train)\n    val_set = get_torch_dataset(X_val, y_val)\n    test_set = get_torch_dataset(X_test, y_test)\n    data_module = L.LightningDataModule.from_datasets(\n        train_dataset=train_set, \n            val_dataset=val_set, \n            test_dataset=test_set, \n            predict_dataset=test_set, \n            batch_size=128,  \n            num_workers=4\n        )\n    if return_type == 'numpy':\n        return X_train, X_val, X_test, y_train, y_val, y_test\n    elif return_type == 'torch':\n        return train_set, val_set, test_set\n    elif return_type == 'lightning':\n        return data_module  \n    elif return_type == 'pandas':\n        raise NotImplementedError(\"Pandas not implemented yet\") # 这里可以用 dataset_dict 的 frame, 但是 train test split 还有预处理。\n    elif return_type == 'all':\n        return X_train, X_val, X_test, y_train, y_val, y_test, train_set, val_set, test_set, data_module, categories\n    else:\n        raise ValueError(f\"Invalid return_type: {return_type}\")",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#理论回顾",
    "href": "coding_projects/P2_SVM/00svm.html#理论回顾",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "5 理论回顾",
    "text": "5 理论回顾\n\n5.1 SVM有哪些优化形式？我们选择哪种来实现代码？\n参考论文1和论文2，以及sklearn代码库中的分法，支持向量机（SVM）的优化方法最主要地分为两大流派：\n\n使用hinge loss（或者周志华西瓜书SVM章节提到的其他surrogate loss）对线性支持向量机软间隔原始问题进行随机梯度下降SGD（或者西瓜书提到坐标下降也可以）。\n使用SMO算法（或者通用的凸二次规划算法）来求解Kernel SVM的对偶问题（也可以求解Linear Kernel）。\n\n这是两个不同形式的问题：\n\n参数保存上，（我个人认为）后者是非参数化方法，需要保存训练集中的支持向量，可能会有很多个，而前者训练成功后就是w和b，可以认为是参数化方法。\n前者与现代的深度学习方法非常兼容，可以端到端地优化，作为深度学习方法的一个特殊loss。而后者虽然也有很多文章将CNN预训练的feature加上SVC去做分类器，但是本身的优化问题是不一样的优化问题。前者的优化难度和神经网络类似（不是简单，是很难），后者却对数据量非常敏感，数据量大的时候会很慢（不少论文提到对大数据集使用SVM仍然是研究热点，西瓜书指出其时间复杂度理论上不可能低于O(m^2)）。\n后者支持核方法，而前者有论文和博客指出，SGD不可能优化Kernel Method的SVM。\n对于前者，论文3说使用GD来优化的情况下，对线性可分数据集而言，hard margin SVM和Logistic Regression是等价的。\n\n\n\n5.2 SVM如何实现多分类？\n李航书上介绍的SVM是用于二分类问题的，然而本次项目我们需要做MNIST手写数字分类，这需要多分类，因而我们必须了解SVM如何实现多分类。\n周志华西瓜书告诉我们认为普通的二分类分类器，可以通过ovr或者ovo策略来实现多分类。那么SVM本身有没有更加独特的技巧去实现多分类呢？\n我们参考这个课件。\n目前，构造SVM多类分类器的方法主要有两类：\n\n直接法（也就是我说的独特的方法）：直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。\n间接法（所有二分类器都可以这么操作得到多分类器）：主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one（OvO）和one-against-all（OvR）两种。具体来说，\n\n一对多法（One-Versus-Rest, OvR）：训练时依次把某个类别的样本归为一类，其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。\n一对一法（One-Versus-One, OvO）：将n个类别两两配对，产生n(n-1)/2个二分类任务，获得n(n-1)/2个分类器，新样本交给这些分类器，得到n(n-1)/2个结果，最终结果投票产生。\n\n\n\n\n5.3 SVM如何实现概率输出？\n尽管李航书第一章把SVM是归类为非概率模型，实际上SVM经过一定的操作，是可以得到概率输出的。经典机器学习sklearn库的学习器有一个重要的API，predict_proba()，而sklearn中的SVC同样支持该API的调用。\n那么SVM概率输出有哪些方法呢？是否要用到点和分离超平面的几何间隔呢？经过资料查询，我发现SVM的概率输出几种方法：\n\nSigmoid函数转换：可以将实轴上的数值投射到[0,1]上，即将一个输出实值抓化为一个概率值。比如一个分类器的分界线为0，大于0标为+1，小于0标为-1；如果使用sigmoid函数套一下输出值，我们就可以说，输出为0时标为+1的概率为0.5；输出为2时标为+1的概率为0.8等。\nPlatt Scaling：这是libsvm中使用的一种方法，核心思想是把分类的结果作为新的训练集，用logistics回归再训练一个关系，得到具体的概率值。\nCalibratedClassifierCV：在scikit-learn中，可以使用专门的函数CalibratedClassifierCV对训练好的分类器模型进行校准，校准过程用到了cross-validation。\n\n在使用predict_proba()函数时，返回的是一个n行k列的数组，第i行第j列上的数值是模型预测第i个预测样本为某个标签的概率，并且每一行的概率和为1。\n\n\n5.4 相关工作\n类似于我们这次Project的，实现SVM的代码仓库有哪些？\n教育学习目的的库：\n\nhttps://github.com/Kaslanarian/libsvm-sc-reading?tab=readme-ov-file\n\n这篇文章写得非常用心，阅读libsvm源码解读地非常详细。\n\nhttps://github.com/lzx1019056432/Be-Friendly-To-New-People/tree/master/SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA\n\n作者历时一个月，终于实现了SMO版本的SVM。但是我们做这个Project只有一周，我们要站在巨人的肩膀上实现地更好。\n\nhttps://github.com/Learner0x5a/SVM-SMO\n\n作者推导良久，终于搞懂了SVM以及SMO的公式，实现了符合sklearn接口的SVM。\n\nhttps://github.com/shicaiwei123/svm-smo?tab=readme-ov-file\n\n作者使用numpy实现了 SMO，并且使用ovo策略实现了多分类。\n\nhttps://github.com/kazuto1011/svm-pytorch\n\n作者使用早期版本的PyTorch实现了SVM。\n\nhttps://bytepawn.com/svm-with-pytorch.html\n\n这篇文章实现了二分类情况下，更早期PyTorch版本下实现的SVM。并且开源到github jupyter notebook。\n\n\n实际部署在工业界的Python库：\n\nsklearn 本质上调用了 libsvm\n\n注意sklearn很长一段时间不会利用GPU优化SVM！ https://stackoverflow.com/questions/35292741/what-svm-python-modules-use-gpu\n\nhttps://pypi.org/project/svmlight/\n\n非Python语言的库\n\nC++ libsvm https://github.com/cjlin1/libsvm\n\nGPU升级版，基于CUDA/C++实现 https://mklab.iti.gr/results/gpu-accelerated-libsvm/\n\nRust https://athemathmo.github.io/rusty-machine/doc/rusty_machine/learning/svm/index.html\nRust https://docs.rs/linfa-svm/latest/linfa_svm/\n\n可以看出这次Project的难度不小，我们需要对SVM的原理有深刻的理解，而且需要有较强的工程能力，才能手动实验一个SVM。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/00svm.html#实验内容",
    "href": "coding_projects/P2_SVM/00svm.html#实验内容",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论",
    "section": "6 实验内容",
    "text": "6 实验内容\n\n6.1 分类的评价指标\n开尔文爵士曾说，如果你连measure都做不到，谈不上improve。所以我们先measure。\n\n\nExported source\nfrom namable_classify.metrics import compute_classification_metrics\n\n\n\ncompute_classification_metrics?\n\nSignature:\ncompute_classification_metrics(\n    y_true: numpy.ndarray,\n    y_pred_logits: numpy.ndarray = None,\n    logits_to_prob: bool = False,\n    y_pred: numpy.ndarray = None,\n    labels: list[int | str] | None = None,\n    supress_warnings: bool = True,\n    y_pred_metrics_only: bool = False,\n)\nDocstring: &lt;no docstring&gt;\nFile:      ~/repos/novelties/cv/cls/NamableClassify/namable_classify/metrics.py\nType:      function\n\n\n这里涵盖了 from sklearn.metrics import roc_auc_score, top_k_accuracy_score, matthews_corrcoef, f1_score, precision_score, recall_score, log_loss, balanced_accuracy_score, cohen_kappa_score, hinge_loss, accuracy_score 当结果有意义的时候，这些指标都会被计算，用于评价模型的精度。\n\n\n6.2 调库实现SVM\n为了给我们后面的实验一个参照，我们调用现有代码库的SVM，关注其精度与速度的情况。 当然如果我们Project在此收尾，只能酌情被扣除分数。 在本节之后，我们将使用 PyTorch 和 numpy 这样的基础科学计算库，来在GPU和CPU上实现SVM及其优化。\n\n\n\n\n\n\n重要\n\n\n\n本次Project首先展示了几个常用的SVM库的精度与速度，并且对其进行调参；随后本次Project基于基础科学计算库手写实现了SVM及其优化，和前面的库的精度与速度进行了对比。\n\n\n接下来的内容请见文件 01sv_use_lib\n\n\n6.3 实现 Hinge Loss+SGD 版本的 Soft Margin Linear SVM\n我们现在来实现与from sklearn.linear_model import SGDClassifier等价的 SVM，但是我们基于PyTorch实现，在GPU上面运行，期望能在大型数据集上比sklearn的实现快。\n这部分内容请见文件 02svm_handy_crafted_linear\n\n\n6.4 对手动实现的SVM进行调参\n这部分内容请见文件 02svm_handy_crafted_linear\n\n\n6.5 附加题: 对比不同 kernel 方法下的 SVM 分类器 （对完整SVM进行调参）\n这一题本质上是让我们以 kernel 的选择（也包括选择线性Kernel）作为目标元参数，其他参数作为冗余或固定元参数，进行调参实验，发现不同 kernel 方法下的 SVM 分类器的分类效果数值上的区别及其显著性，并且从可视化分析上也作出进一步解释。\n这部分内容请见 03svm_kernel_hpo\n\n\n6.6 附加题: 构建使用 kernel 方法的 SVM 分类器 （手动实现SMO）\n这也就是让我们手动实现 SMO 优化算法以及Kernel Method。\n这部分内容请见 04svm_handy_crafted_kernel",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/kernel_hpo.html",
    "href": "coding_projects/P2_SVM/kernel_hpo.html",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——03不同Kernel的SVM超参数优化",
    "section": "",
    "text": "本文是更高效的支持向量机算法实现及其在手写数字识别中的应用系列文章第03篇——不同Kernel的SVM超参数优化。\n\ndataset_dict_uci_digits = load_digits(as_frame=False)\nX_train, X_val, X_test, y_train, y_val, y_test, train_set, val_set, test_set, data_module, categories = process_sklearn_dataset_dict(dataset_dict_uci_digits, 'all')\n# dataset_dict_full_mnist = fetch_openml(\"mnist_784\", as_frame=True)\n# X_train_full, X_val_full, X_test_full, y_train_full, y_val_full, y_test_full, train_set_full, val_set_full, test_set_full, data_module_full, categories_full = process_sklearn_dataset_dict(dataset_dict_full_mnist, 'all')\n\n(1797, 64) float32 (1797,) int64 [0 1 2 3 4 5 6 7 8 9]\n1293 144 360\n\n\n\n0.1 附加题: 对比不同 kernel 方法下的 SVM 分类器 （对完整SVM进行调参）\n这一题本质上是让我们以 kernel 的选择（也包括选择线性Kernel）作为目标元参数，其他参数作为冗余或固定元参数，进行调参实验，发现不同 kernel 方法下的 SVM 分类器的分类效果数值上的区别及其显著性，并且从可视化分析上也作出进一步解释。\n为了让问题简单清晰，我们再这一节不用我们自己实现的SVM（我们刚才实现的Linear Soft Margin SGD SVM），而是直接使用成熟的经过检验的，刚才我们测试出来最快的 Thunder SVM 库（与sklearn接口兼容，速度更快，使用GPU）。这样我们就可以专注于调参优化问题本身，而不是关注具体实现细节。\n\n0.1.1 科学调参的原则与方法\n我在上次Project作业KD树中详细描述了谷歌AI团队《深度学习调优指南》的思想，涉及到的概念包括目标元参数、冗余元参数和固定元参数，贝叶斯优化、演化计算、近似随机搜索，科学实验的控制变量法与调参实验设计中的探索与利用、调参结果的假设检验分析等。这里我们不再赘述，需要的话可以阅读上次作业的文档。\n\n\n0.1.2 搜索空间定义\n我们使用dataclass，要求传入函数的参数是强类型，而且有一个随机概率分布，这样方便定义调参。这里用到我自己写的scholarly_infrastructure库的一个核心功能，对Python标准的dataclass进行了改进。\n\nsource\n\n\n\n0.2 SupportVectorClassifierConfig\n\n SupportVectorClassifierConfig (C:float=1.0, kernel:str='rbf',\n                                degree:int=3,\n                                gamma:Union[str,float]='scale',\n                                coef0:float=0.0, shrinking:bool=True,\n                                probability:bool=False, tol:float=0.001,\n                                cache_size:float=200, class_weight:Union[d\n                                ict,str,NoneType]=None,\n                                verbose:bool=False, max_iter:int=-1,\n                                decision_function_shape:str='ovr',\n                                break_ties:bool=False,\n                                random_state:Optional[int]=None)\n\n\n\nExported source\nfrom scholarly_infrastructure.rv_args.nucleus import RandomVariable, experiment_setting\nfrom optuna.distributions import IntDistribution, FloatDistribution, CategoricalDistribution\nfrom typing import Optional, Union\n\n\n\n\nExported source\n@experiment_setting\nclass SupportVectorClassifierConfig:\n    # 惩罚系数 C\n    C: float = ~RandomVariable(\n        default=1.0,\n        description=\"Regularization parameter. The strength of the regularization is inversely proportional to C.\",\n        distribution=FloatDistribution(1e-5, 1e2, log=True)\n    )\n    \n    # 核函数类型\n    kernel: str = ~RandomVariable(\n        default=\"rbf\",\n        description=\"Kernel type to be used in the algorithm.\",\n        distribution=CategoricalDistribution(choices=[\"linear\", \"poly\", \"rbf\", \"sigmoid\",\n                                                      \"precomputed\"\n                                                      ])\n    )\n    \n    # 多项式核函数的度数\n    degree: int = ~RandomVariable(\n        default=3,\n        description=\"Degree of the polynomial kernel function ('poly').\",\n        distribution=IntDistribution(1, 10, log=False)\n    )\n    \n    # 核函数系数 gamma\n    gamma: Union[str, float] = ~RandomVariable(\n        default=\"scale\",\n        description=\"Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\",\n        distribution=CategoricalDistribution(choices=[\"scale\", \"auto\"])  # 可以添加浮点数分布视需求\n    )\n    \n    # 核函数独立项 coef0\n    coef0: float = ~RandomVariable(\n        default=0.0,\n        description=\"Independent term in kernel function. It is significant in 'poly' and 'sigmoid'.\",\n        distribution=FloatDistribution(0, 1)\n    )\n    \n    # 收缩启发式算法\n    shrinking: bool = ~RandomVariable(\n        default=True,\n        description=\"Whether to use the shrinking heuristic.\",\n        distribution=CategoricalDistribution(choices=[True, False])\n    )\n    \n    # 是否启用概率估计\n    probability: bool = ~RandomVariable(\n        default=False,\n        description=\"Whether to enable probability estimates. Slows down fit when enabled.\",\n        distribution=CategoricalDistribution(choices=[True, False])\n    )\n    \n    # 停止准则的容差 tol\n    tol: float = ~RandomVariable(\n        default=1e-3,\n        description=\"Tolerance for stopping criterion.\",\n        distribution=FloatDistribution(1e-6, 1e-1, log=True)\n    )\n    \n    # 内核缓存的大小（MB）\n    cache_size: float = ~RandomVariable(\n        default=200,\n        description=\"Specify the size of the kernel cache (in MB).\",\n        distribution=FloatDistribution(50, 500, log=False)\n    )\n    \n    # 类别权重 class_weight\n    class_weight: Optional[Union[dict, str]] = ~RandomVariable(\n        default=None,\n        description=\"Set C of class i to class_weight[i]*C or use 'balanced' to adjust weights inversely to class frequencies.\",\n        distribution=CategoricalDistribution(choices=[None, \"balanced\"])\n    )\n    \n    # 是否启用详细输出\n    verbose: bool = ~RandomVariable(\n        default=False,\n        description=\"Enable verbose output (may not work properly in a multithreaded context).\",\n        distribution=CategoricalDistribution(choices=[True, False])\n    )\n    \n    # 最大迭代次数\n    max_iter: int = ~RandomVariable(\n        default=-1,\n        description=\"Hard limit on iterations within solver, or -1 for no limit.\",\n        distribution=IntDistribution(-1, 1000, log=False)\n    )\n    \n    # 决策函数形状\n    decision_function_shape: str = ~RandomVariable(\n        default=\"ovr\",\n        description=\"Whether to return a one-vs-rest ('ovr') decision function or original one-vs-one ('ovo').\",\n        distribution=CategoricalDistribution(choices=[\"ovo\", \"ovr\"])\n    )\n    \n    # 是否打破决策函数平局\n    break_ties: bool = ~RandomVariable(\n        default=False,\n        description=\"If True, break ties according to the confidence values of decision_function when decision_function_shape='ovr'.\",\n        distribution=CategoricalDistribution(choices=[True, False])\n    )\n    \n    # 随机种子 random_state\n    random_state: Optional[int] = ~RandomVariable(\n        default=None,\n        description=\"Controls random number generation for probability estimates. Ignored when probability=False.\",\n        distribution=IntDistribution(0, 100)  # 根据需求设置范围\n    )\n\n\n\n# show_dataframe_doc(SupportVectorClassifierConfig)[:1]\nSupportVectorClassifierConfig.show_dataframe_doc()[:1]\n# SupportVectorClassifierConfig.get_optuna_search_space(frozen_rvs={\"verbose\", \"cache_size\", \"random_state\"})\n\n\n\n\n\n\n\n\n\n\n\nname\ntype\ndefault\ndefault_factory\ninit\nrepr\nhash\ncompare\nmetadata\nkw_only\ndescription\ndistribution\n\n\n\n\n0\nC\n&lt;class 'float'&gt;\n1.0\n&lt;dataclasses._MISSING_TYPE object at 0x7faee47...\nTrue\nTrue\nNone\nTrue\nNone\n&lt;dataclasses._MISSING_TYPE object at 0x7faee47...\nRegularization parameter. The strength of the ...\nFloatDistribution(high=100.0, log=True, low=1e...\n\n\n\n\n\n\n\n\n\nExported source\nfrom dataclasses import asdict\n\n\n\n0.2.1 定义目标函数\n\nsource\n\n\n\n0.3 evaluate_svm\n\n evaluate_svm (config:__main__.SupportVectorClassifierConfig, X_train,\n               y_train, trial:optuna.trial._trial.Trial=None,\n               critical_metric='acc1_pred', num_of_repeated=5)\n\n\n\nExported source\nimport optuna\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\n\ndef evaluate_svm(config:SupportVectorClassifierConfig, X_train, y_train,\n                 trial:optuna.Trial = None, \n                 critical_metric=\"acc1_pred\", num_of_repeated=5):\n    # 使用k fold交叉验证，相当于做了5次独立实验。\n    kf = KFold(n_splits=num_of_repeated, shuffle=True, random_state=config.random_state)\n    \n    \n    result_dict = dict()\n\n    metric_names = set()\n    \n    # 进行5折交叉验证\n    for experiment_index, (train_index, test_index) in enumerate(kf.split(X_train)):\n        # 分割训练集和测试集\n        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n        \n        # 创建分类器实例\n        model = SVC(**asdict(config))\n        \n        # 训练模型\n        model.fit(X_train_fold, y_train_fold)\n        \n        # 预测测试集\n        y_pred = model.predict(X_test_fold)\n        \n        # 计算准确率\n        single_run_result = compute_classification_metrics(y_test_fold, y_pred=y_pred, labels=list(range(10)), y_pred_metrics_only=True)\n        \n        metric_names.update(single_run_result.keys())\n        single_run_result = {f\"{k}-run{experiment_index}\":v for k, v in single_run_result.items()}\n        result_dict|=single_run_result\n        \n        if trial is not None:\n            for k, v in single_run_result.items():\n                trial.set_user_attr(k, v)\n            trial.report(single_run_result[f\"{critical_metric}-run{experiment_index}\"], experiment_index)\n    for metric_name in metric_names:\n        all_runs_results = [result_dict[f\"{metric_name}-run{i}\"] for i in range(num_of_repeated)]\n        result_dict[f\"{metric_name}-mean\"] = sum(all_runs_results) / len(all_runs_results)\n        if trial is not None:\n            trial.set_user_attr(f\"{metric_name}-mean\", result_dict[f\"{metric_name}-mean\"])\n    if trial is not None:\n        trial.set_user_attr(f\"num_of_repeated\", num_of_repeated)\n    return result_dict\n\n\n\nimport numpy as np\n\n\n# 把 X_train 和 X_val 重新合并 \nX_train_val = np.vstack((X_train, X_val))\ny_train_val = np.hstack((y_train, y_val))\n\n\nevaluate_svm(SupportVectorClassifierConfig(kernel='linear'), X_train_val, y_train_val).keys()\n\n\n\n\n\ndict_keys(['matthews_corrcoef-run0', 'f1-run0', 'precision-run0', 'recall-run0', 'balanced_accuracy-run0', 'cohen_kappa-run0', 'acc1_pred-run0', 'matthews_corrcoef-run1', 'f1-run1', 'precision-run1', 'recall-run1', 'balanced_accuracy-run1', 'cohen_kappa-run1', 'acc1_pred-run1', 'matthews_corrcoef-run2', 'f1-run2', 'precision-run2', 'recall-run2', 'balanced_accuracy-run2', 'cohen_kappa-run2', 'acc1_pred-run2', 'matthews_corrcoef-run3', 'f1-run3', 'precision-run3', 'recall-run3', 'balanced_accuracy-run3', 'cohen_kappa-run3', 'acc1_pred-run3', 'matthews_corrcoef-run4', 'f1-run4', 'precision-run4', 'recall-run4', 'balanced_accuracy-run4', 'cohen_kappa-run4', 'acc1_pred-run4', 'balanced_accuracy-mean', 'f1-mean', 'acc1_pred-mean', 'recall-mean', 'precision-mean', 'matthews_corrcoef-mean', 'cohen_kappa-mean'])\n\n\n\n固定元参数定义\n\nsource\n\n\n0.4 objective_svm\n\n objective_svm (trial:optuna.trial._trial.Trial, X_train_val, y_train_val,\n                num_of_repeated=5, critical_metric='acc1_pred',\n                critical_reduction='mean')\n\n\n\nExported source\nfixed_meta_params = SupportVectorClassifierConfig(\n    probability = False, # 暂时不研究，只关注 acc1_pred\n    # 与性能无关\n    cache_size  = 200, \n    verbose = False,\n    random_state = 42, # 今天我们根据 K Fold 来做重复实验，不根据随机种子来做重复实验\n)\nfrozen_rvs = {\"probability\", \"cache_size\", \"verbose\", \"random_state\"}\n\n\n\n\nExported source\ndef objective_svm(trial:optuna.Trial, X_train_val, y_train_val, num_of_repeated=5, critical_metric=\"acc1_pred\", critical_reduction=\"mean\"):\n    config:SupportVectorClassifierConfig = SupportVectorClassifierConfig.optuna_suggest(\n        trial, fixed_meta_params, frozen_rvs=frozen_rvs)\n    try:\n        cross_val_results = evaluate_svm(config, X_train_val, y_train_val, \n                                        trial=trial,\n                                        critical_metric=critical_metric, num_of_repeated=num_of_repeated)\n        critical_metric_name = f\"{critical_metric}-{critical_reduction}\"\n        critical_result = cross_val_results[critical_metric_name]\n    except ValueError as e:\n        # logger.exception(e)\n        logger.warning(f\"Trial {trial.number} failed with error: {e}, we consider this as a pruned trial since we believe such failure is due to the implicit constraints of the problem. \")\n        raise optuna.exceptions.TrialPruned()\n    return critical_result\n\n\n\n0.4.1 执行调参搜索\n\n\nExported source\nfrom thu_big_data_ml.help import runs_path\n\n\n\n\nExported source\nstudy_path = runs_path / \"optuna_studies.db\"\nsqlite_url = f\"sqlite:///{study_path}\"\n\n\n\n\nExported source\nfrom optuna.samplers import *\nfrom optuna.pruners import *\nimport json\n\n\n\n\nExported source\nstudy = optuna.create_study(\n    study_name=\"svm kernel hpo 11.17 3.0\", \n    storage=sqlite_url, \n    load_if_exists=True, \n    sampler=QMCSampler(seed=42), # 谷歌建议\n    pruner=WilcoxonPruner(), # 对重复实验进行假设检验剪枝\n    direction=\"maximize\")\nstudy.set_user_attr(\"contributors\", [\"Ye Canming\"])\nstudy.set_user_attr(\"fixed_meta_parameters\", json.dumps(asdict(fixed_meta_params)))\n\n\nExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n  sampler=QMCSampler(seed=42), # 谷歌建议\n&lt;ipython-input-1-ad5a12a62694&gt;:6: ExperimentalWarning: WilcoxonPruner is experimental (supported from v3.6.0). The interface can change in the future.\n  pruner=WilcoxonPruner(), # 对重复实验进行假设检验剪枝\n\n\n接下来运行\n\n# %%capture cap\nstudy.optimize(objective_svm, n_trials=100)\n\n\nstudy.optimize(objective_svm, n_trials=100)\n\n\n\n0.4.2 分析实验结果\n首先加载调参实验的结果，实验分析的时候，不用重新再跑一次实验，这两个是分开的\n\nstudy = optuna.load_study(\n    study_name=\"svm kernel hpo 11.17 3.0\", \n    storage=sqlite_url)\n\n\n0.4.2.1 最好的模型是哪个？\n\nstudy.best_params\n\n\n\n\n\n{\n    'C': 1.7782794100389216,\n    'kernel': 'poly',\n    'degree': 3,\n    'gamma': 'auto',\n    'coef0': 0.25,\n    'shrinking': False,\n    'tol': 1.7782794100389246e-05,\n    'class_weight': None,\n    'max_iter': 750,\n    'decision_function_shape': 'ovo',\n    'break_ties': False\n}\n\n\n\n\nstudy.best_value\n\n\n\n\n\n0.9902584204413472\n\n\n\n\n\n0.4.2.2 Optuna 可视化分析结果\n可以通过下面的命令对我们刚才保存调参结果的数据库文件进行可视化展示：\noptuna-dashboard sqlite:///optuna_studies.db --port 18081\n\n\n我们也可以把这些图用代码画在本文档中\n\nfrom optuna.visualization import plot_contour\nfrom optuna.visualization import plot_edf\nfrom optuna.visualization import plot_intermediate_values\nfrom optuna.visualization import plot_optimization_history\nfrom optuna.visualization import plot_parallel_coordinate\nfrom optuna.visualization import plot_param_importances\nfrom optuna.visualization import plot_rank\nfrom optuna.visualization import plot_slice\nfrom optuna.visualization import plot_timeline\n\n\nplot_param_importances(study)\n\n                                                \n\n\n这个图非常有用，提示了我们元参数的重要性，这其实也是元参数的敏感性。如果目标值对某个参数过于敏感，那么它必须是冗余元参数，在其他变量变动的时候需要重新调参，而如果不是很敏感，我们就可以先固定它的值缩小搜索范围。\n从图中可以看出，kernel是最重要的选择。\nmax_iter 很重要的话就意味着我们给的搜索空间max_iter可能还不够，有些方法潜在地需要更多的迭代次数才能收敛。在深度学习调参项目中，我们下一轮的实验迭代可能就要考虑修改搜索空间。这里我们只是做作业，所以暂时忽略。tol也很重要意味着其实我们tol可以给得更小，说明更小对优化精度是有用的。\n网上的资料指出，C和gamma的选择对SVM的性能影响很大，然而在我们的200次实验观测中，可以看到gamma的影响并不是很大，至少在sklearn的两个自动选择gamma的方法来说，这两个自动选择都是合理的，可能网上的建议是说手动指定gamma的float会有很大影响。\n\nplot_intermediate_values(study)\n\n                                                \n\n\n0-4是不同的K Fold下的结果。可以看出有些参数下不是那么稳定，特别是整体值比较差的的时候，随机波动也比较大。\n\nplot_parallel_coordinate(study, params=[\"kernel\", \"C\", \"gamma\"])\n\n                                                \n\n\n这个图其实我个人觉得意义不大，虽然很多调参软件都会有，看起来很炫酷，但是我觉得无法从图中读到什么有用的insight。因为好的值和坏的值图中交叉来交叉去，没法直接看出相关关系。\n\nplot_contour(study, params=[\"C\", 'tol', 'coef0'])\n\n                                                \n\n\n等高线图，看起来C比较大的时候颜色更深、\n\nplot_slice(study)\n\n                                                \n\n\n这个图比较有用，可以看到每个随机变量不同值的影响。\n\nplot_rank(study, params=['C', 'tol', 'kernel'])\n\n                                                \n\n\n\n\n0.4.2.3 以 kernel 为目标元参数进行假设检验分析——期望改进分析\n\ndf = study.trials_dataframe()\ndf.head()\n\n\n\n\n\n\n\n\n\n\n\nnumber\nvalue\ndatetime_start\ndatetime_complete\nduration\nparams_C\nparams_break_ties\nparams_class_weight\nparams_coef0\nparams_decision_function_shape\n...\nuser_attrs_precision-run2\nuser_attrs_precision-run3\nuser_attrs_precision-run4\nuser_attrs_recall-mean\nuser_attrs_recall-run0\nuser_attrs_recall-run1\nuser_attrs_recall-run2\nuser_attrs_recall-run3\nuser_attrs_recall-run4\nstate\n\n\n\n\n0\n0\nNaN\n2024-11-17 02:54:45.626373\n2024-11-17 02:54:45.788622\n0 days 00:00:00.162249\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nFAIL\n\n\n1\n1\nNaN\n2024-11-17 02:55:18.722161\n2024-11-17 02:55:18.797816\n0 days 00:00:00.075655\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nFAIL\n\n\n2\n2\n0.956165\n2024-11-17 02:56:10.992341\n2024-11-17 02:56:11.578482\n0 days 00:00:00.586141\n0.004186\nTrue\nNone\n0.708073\novr\n...\n0.961807\n0.957685\n0.964761\n0.956196\n0.951926\n0.954759\n0.954058\n0.958502\n0.961732\nCOMPLETE\n\n\n3\n3\nNaN\n2024-11-17 02:56:11.607921\n2024-11-17 02:56:11.738309\n0 days 00:00:00.130388\n0.191854\nTrue\nNone\n0.000000\novr\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPRUNED\n\n\n4\n4\n0.749492\n2024-11-17 02:56:11.754529\n2024-11-17 02:56:12.693953\n0 days 00:00:00.939424\n0.031623\nFalse\nNone\n0.500000\novr\n...\n0.839718\n0.859636\n0.849986\n0.761556\n0.733830\n0.775699\n0.789870\n0.766079\n0.742302\nCOMPLETE\n\n\n\n\n5 rows × 60 columns\n\n\n\n\ntarget = \"value\"\ntreatment = \"params_kernel\"\n\n\nintersted_cols = [c for c in df.columns if c.startswith(\"params\") or \"user_attrs\" in c or c==\"value\"]\n# intersted_cols = [c for c in df.columns if c.startswith(\"params\") or c==\"value\"]\ndfi = df[intersted_cols].dropna(subset=[target])\ndfi.head()\n\n\n\n\n\n\n\n\n\n\n\nvalue\nparams_C\nparams_break_ties\nparams_class_weight\nparams_coef0\nparams_decision_function_shape\nparams_degree\nparams_gamma\nparams_kernel\nparams_max_iter\n...\nuser_attrs_precision-run1\nuser_attrs_precision-run2\nuser_attrs_precision-run3\nuser_attrs_precision-run4\nuser_attrs_recall-mean\nuser_attrs_recall-run0\nuser_attrs_recall-run1\nuser_attrs_recall-run2\nuser_attrs_recall-run3\nuser_attrs_recall-run4\n\n\n\n\n2\n0.956165\n0.004186\nTrue\nNone\n0.708073\novr\n1.0\nscale\nlinear\n182.0\n...\n0.947915\n0.961807\n0.957685\n0.964761\n0.956196\n0.951926\n0.954759\n0.954058\n0.958502\n0.961732\n\n\n4\n0.749492\n0.031623\nFalse\nNone\n0.500000\novr\n5.0\nscale\nrbf\n499.0\n...\n0.801343\n0.839718\n0.859636\n0.849986\n0.761556\n0.733830\n0.775699\n0.789870\n0.766079\n0.742302\n\n\n5\n0.990258\n1.778279\nFalse\nNone\n0.250000\novo\n3.0\nauto\npoly\n750.0\n...\n0.985863\n0.988889\n0.981481\n1.000000\n0.989942\n0.991154\n0.986591\n0.989747\n0.982219\n1.000000\n\n\n6\n0.130139\n0.000562\nFalse\nbalanced\n0.750000\novr\n8.0\nscale\nsigmoid\n249.0\n...\n0.013542\n0.010105\n0.010453\n0.038927\n0.120000\n0.100000\n0.100000\n0.100000\n0.100000\n0.200000\n\n\n8\n0.984688\n13.335214\nFalse\nbalanced\n0.125000\novo\n9.0\nscale\nlinear\n875.0\n...\n0.990013\n0.982012\n0.975091\n0.993521\n0.984161\n0.982063\n0.988435\n0.981054\n0.975855\n0.993398\n\n\n\n\n5 rows × 55 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfig, ax = plt.subplots()\nsns.boxplot(data=dfi, x=treatment, y=target, ax=ax)\ndfi.plot(x=treatment, y=target, ax=ax, kind='scatter', c='red')\n\n\nuniform与distance方法平均准确率箱线图对比\n\n\n\n&lt;Axes: xlabel='params_kernel', ylabel='value'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n从中可以看出, linear和 poly 平均值比较高，而且太集中了画不出图。 而 rbf 和 sigmoid 则是有很多结果比较低，平均值在中间。\n除了箱线图，还可以画分布图，来展示不同kernel对精度的影响。\n\nsns.displot(data=dfi, x=target, kde=True, kind=\"hist\")\nplt.ylabel(\"频数\")\nsns.displot(data=dfi, x=target, hue=treatment, kde=True, kind=\"hist\")\nplt.ylabel(\"频数\")\n\n\n\n\n\nText(22.89317438271604, 0.5, '频数')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们在同时比较多个方法，可以用ANOVA检验吗？ 可以使用我之前写的代码，看看ANOVA的条件是否满足。\n\nfrom thu_big_data_ml.big_data_analytics.anova import test_normality_group, homogeneity_of_variance\n\n\ntest_normality_group(dfi, interesting_col=target, hue_col=treatment)\n\n\n\n\n\n\n\n\n\n\n\nlinear\npoly\nrbf\nsigmoid\n\n\n\n\nKolmogorov-Smirnov\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nAnderson-Darling\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nD'Agostino-Pearson\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\n\n\n\n\n\n\nlog_transform = lambda data_column: np.log(data_column+np.min(data_column)+1)  # 保证 大于0 \ntest_normality_group(dfi, interesting_col=target, hue_col=treatment, transform=log_transform)\n\n\n\n\n\n\n\n\n\n\n\nlinear\npoly\nrbf\nsigmoid\n\n\n\n\nKolmogorov-Smirnov\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nAnderson-Darling\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nD'Agostino-Pearson\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\n\n\n\n\n\n\nhomogeneity_of_variance(dfi, interesting_col=target, hue_col=treatment)\n\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n\n\n\n\n\n\n{\n    'ratio_largest_to_smallest': 1.7386168726213924,\n    'bartlett_result': BartlettResult(statistic=12.750075189817064, pvalue=0.005209469719008144)\n}\n\n\n\n看来我们的数据并不服从正态分布，就算经过了log变换也不服从。 而且bartlett假设检验显著地发现方差齐性不满足，虽然经验法则说勉强可以接受&lt;2的方差差异。\n\nfrom thu_big_data_ml.big_data_analytics.anova import auto_anova_for_df, auto_kruskal_for_df\n\n\nauto_anova_for_df(dfi, interesting_col=target, hue_col=treatment)\n\n\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares (SS)\nDegrees of Freedom (df)\nMean Square (MS)\nF\np\np_excel\n\n\n\n\n0\nBetween\n4.040434\n3\n1.346811\n18.119793\n3.648672e-10\n4.007048e-10\n\n\n1\nWithin\n11.818181\n159\n0.074328\nNaN\nNaN\nNaN\n\n\n2\nTotal\n15.858614\n162\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n尽管ANOVA的使用条件不满足，但是我们勉强使用ANOVA，可以看到ANOVA方法的p值很小，很显著地不同kernel之间存在显著差异！\n接下来我们使用 Kruskal-Wallis 检验，这个检验不需要方差齐性和正态性满足，就可以对多列样本进行比较\n\nres = auto_kruskal_for_df(dfi, interesting_col=target, hue_col=treatment)\nif res.pvalue &lt; 0.05:\n    print(\"There is a significant difference between the kernel functions.\")\nres\n\nMon 2024-11-18 21:43:36.212606\n\n\n\nINFO     There is a significant difference between the kernel functions.                              nucleus.py:53\n\n\n\n\n\n\n\nKruskalResult(statistic=89.11831011539, pvalue=3.3878339514086004e-19)\n\n\n\nKruskal-Wallis H-test tests的零假设是 不同组的中位数之间没有显著差异。看来我们可以拒绝原假设，认为不同kernel的SVM的中位数有显著差异。\n刚才我们检验出来存在显著差异，但是不知道具体是谁比谁大有显著性，所以我们还需要使用post-hoc类型的假设检验来进行进一步的分析。\n首先刚才检验的是中位数有显著差异，我们来求一下分组的中位数。\n\nimport pandas as pd\n\n\nmedians = df.groupby(treatment)[target].median().sort_values(ascending=False)\nmedians\n\n\n\n\n\nparams_kernel\npoly           0.989559\nlinear         0.985383\nsigmoid        0.650010\nrbf            0.516373\nprecomputed         NaN\nName: value, dtype: float64\n\n\n\n\norder = medians.index[:-1]\n\nDunn’s test就是针对 Kruskal-Wallis one-way analysis 对应的 post-hoc 检验方法（之一，还有其他的）。\n\n\nExported source\nimport scikit_posthocs as sp\nfrom scikit_posthocs import posthoc_dunn\n\n\n\nres = posthoc_dunn(dfi, val_col=target, group_col=treatment, \n             sort=True, p_adjust='holm')\n\n# 按照中位数大小排序\nres = res.reindex(order)\nres = res[order]\nres\n\n\n\n\n\n\n\n\n\n\n\npoly\nlinear\nsigmoid\nrbf\n\n\nparams_kernel\n\n\n\n\n\n\n\n\npoly\n1.000000e+00\n3.388027e-08\n1.939419e-12\n2.481610e-07\n\n\nlinear\n3.388027e-08\n1.000000e+00\n6.615530e-02\n1.597734e-01\n\n\nsigmoid\n1.939419e-12\n6.615530e-02\n1.000000e+00\n9.446169e-01\n\n\nrbf\n2.481610e-07\n1.597734e-01\n9.446169e-01\n1.000000e+00\n\n\n\n\n\n\n\n\n# res &lt; 0.05\nheatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\nsp.sign_plot(res, **heatmap_args)\n\n\n\n\n\n(&lt;Axes: ylabel='params_kernel'&gt;, &lt;matplotlib.colorbar.Colorbar object at 0x7f3af82283a0&gt;)\n\n\n\n\n\n\n\n\n\n\n\n\n\n从结果表可以看出，poly非常显著地优于其他三个方法，是最好的方法。而linear虽然看起来中位数比剩下两个方法高，但是不显著。\n以上的结果似乎不符合读者的直觉，你可能会说“kernel method不是很厉害吗，SVM重要的方法之一哎，怎么会不行呢？”\n需要注意的是，我们刚才的实验随机采样了很多参数，kernel method也有厉害的参数，也有不厉害的参数。那我们刚才严格的假设检验如何解读呢？\n正确的解读应该是这样的。假如有一个小白，不懂SVM，让他随机选择一个参数来调用sklearn库。我们是调过参的，我们告诉他，你是小白，如果你用rbf和sigmoid，你随便选别的参数，你很容易犯错误，让指标特别低。相反地，如果你用linear或者poly，你随便调其他的参数都无所谓，你大概率是能得到较好的结果的。\n这就是我们上面的研究的意义，一个新的随机用户在随机场景下使用你的方法来替代其他方法时，他得到的期望改进。我们的结果就是 linear 和 poly的期望更高。但是这不意味着专家不能用rbf 和 sigmoid经过仔细调参得到更好的结果。\n\n\n0.4.2.4 以 kernel 为目标元参数进行假设检验分析——最优对比分析\n\nmax_rows = dfi.loc[dfi.groupby(treatment)[target].idxmax()]\nmax_rows\n\n\n\n\n\n\n\n\n\n\n\nvalue\nparams_C\nparams_break_ties\nparams_class_weight\nparams_coef0\nparams_decision_function_shape\nparams_degree\nparams_gamma\nparams_kernel\nparams_max_iter\n...\nuser_attrs_precision-run1\nuser_attrs_precision-run2\nuser_attrs_precision-run3\nuser_attrs_precision-run4\nuser_attrs_recall-mean\nuser_attrs_recall-run0\nuser_attrs_recall-run1\nuser_attrs_recall-run2\nuser_attrs_recall-run3\nuser_attrs_recall-run4\n\n\n\n\n24\n0.985383\n60.429639\nTrue\nbalanced\n0.343750\novr\n6.0\nscale\nlinear\n656.0\n...\n0.990013\n0.985716\n0.974978\n0.990491\n0.984965\n0.985093\n0.988435\n0.984900\n0.975855\n0.990541\n\n\n5\n0.990258\n1.778279\nFalse\nNone\n0.250000\novo\n3.0\nauto\npoly\n750.0\n...\n0.985863\n0.988889\n0.981481\n1.000000\n0.989942\n0.991154\n0.986591\n0.989747\n0.982219\n1.000000\n\n\n45\n0.979820\n77.736503\nFalse\nbalanced\n0.015625\novo\n4.0\nauto\nrbf\n453.0\n...\n0.981515\n0.985716\n0.971346\n0.983036\n0.979199\n0.972401\n0.983471\n0.984758\n0.971617\n0.983750\n\n\n57\n0.937369\n0.835363\nFalse\nbalanced\n0.171875\novr\n2.0\nscale\nsigmoid\n797.0\n...\n0.934272\n0.942155\n0.938151\n0.939654\n0.936771\n0.942251\n0.931733\n0.938035\n0.936699\n0.935135\n\n\n\n\n4 rows × 55 columns\n\n\n\n\ncritical_metric = \"acc1_pred\"\nnum_repeated = 5\nkfold_metrics = [f\"user_attrs_{critical_metric}-run{i}\" for i in range(num_repeated)]\n\n\nintereting_df =  max_rows[[treatment]+kfold_metrics]\nintereting_df = intereting_df.set_index(treatment)\nintereting_df\n\n\n\n\n\n\n\n\n\n\n\nuser_attrs_acc1_pred-run0\nuser_attrs_acc1_pred-run1\nuser_attrs_acc1_pred-run2\nuser_attrs_acc1_pred-run3\nuser_attrs_acc1_pred-run4\n\n\nparams_kernel\n\n\n\n\n\n\n\n\n\nlinear\n0.986111\n0.989583\n0.986063\n0.975610\n0.989547\n\n\npoly\n0.993056\n0.986111\n0.989547\n0.982578\n1.000000\n\n\nrbf\n0.975694\n0.982639\n0.986063\n0.972125\n0.982578\n\n\nsigmoid\n0.940972\n0.934028\n0.940767\n0.937282\n0.933798\n\n\n\n\n\n\n\n\nanalysis_df = intereting_df.transpose()\nanalysis_df = analysis_df.reset_index(drop=False)\nanalysis_df = analysis_df.rename(columns={analysis_df.columns[0]: 'runs'})\nanalysis_df = analysis_df.rename_axis('index')\nanalysis_df\n\n\n\n\n\n\n\n\n\n\nparams_kernel\nruns\nlinear\npoly\nrbf\nsigmoid\n\n\nindex\n\n\n\n\n\n\n\n\n\n0\nuser_attrs_acc1_pred-run0\n0.986111\n0.993056\n0.975694\n0.940972\n\n\n1\nuser_attrs_acc1_pred-run1\n0.989583\n0.986111\n0.982639\n0.934028\n\n\n2\nuser_attrs_acc1_pred-run2\n0.986063\n0.989547\n0.986063\n0.940767\n\n\n3\nuser_attrs_acc1_pred-run3\n0.975610\n0.982578\n0.972125\n0.937282\n\n\n4\nuser_attrs_acc1_pred-run4\n0.989547\n1.000000\n0.982578\n0.933798\n\n\n\n\n\n\n\n\narray_data = analysis_df.drop(analysis_df.columns[0], axis=1).values\narray_data\n\n\n\n\n\narray([[0.98611111, 0.99305556, 0.97569444, 0.94097222],\n       [0.98958333, 0.98611111, 0.98263889, 0.93402778],\n       [0.98606272, 0.98954704, 0.98606272, 0.94076655],\n       [0.97560976, 0.9825784 , 0.97212544, 0.93728223],\n       [0.98954704, 1.        , 0.9825784 , 0.93379791]])\n\n\n\n\nanalysis_df.columns[1]\n\n\n\n\n\n'linear'\n\n\n\n\nfrom scikit_posthocs import __convert_to_block_df\n\n\nanalysis_df_regular, _, _, _ = __convert_to_block_df(array_data)\nanalysis_df_regular = analysis_df_regular.rename(columns={'blocks': 'runs', \n                                                          'groups': treatment, 'y':target})\nanalysis_df_regular[treatment] = analysis_df_regular[treatment].apply(lambda x: analysis_df.columns[1+x])\nanalysis_df_regular\n\n\n\n\n\n\n\n\n\n\n\nruns\nparams_kernel\nvalue\n\n\n\n\n0\n0\nlinear\n0.986111\n\n\n1\n1\nlinear\n0.989583\n\n\n2\n2\nlinear\n0.986063\n\n\n3\n3\nlinear\n0.975610\n\n\n4\n4\nlinear\n0.989547\n\n\n5\n0\npoly\n0.993056\n\n\n6\n1\npoly\n0.986111\n\n\n7\n2\npoly\n0.989547\n\n\n8\n3\npoly\n0.982578\n\n\n9\n4\npoly\n1.000000\n\n\n10\n0\nrbf\n0.975694\n\n\n11\n1\nrbf\n0.982639\n\n\n12\n2\nrbf\n0.986063\n\n\n13\n3\nrbf\n0.972125\n\n\n14\n4\nrbf\n0.982578\n\n\n15\n0\nsigmoid\n0.940972\n\n\n16\n1\nsigmoid\n0.934028\n\n\n17\n2\nsigmoid\n0.940767\n\n\n18\n3\nsigmoid\n0.937282\n\n\n19\n4\nsigmoid\n0.933798\n\n\n\n\n\n\n\n现在我们对五折交叉验证的结果来对四个方法进行假设检验。 这一次我们该使用 Friedman 检验, 这也是一个不需要正态性和方差齐性的检验方法，某种程度上论文会选择这个而非 Kruskal-Wallis。 刚才我们不用是因为刚才每一组的样本量不一致，而 Friedman 检验要求样本量一致\n\nimport scipy.stats as ss\n\n\nres = ss.friedmanchisquare(*array_data.T)\nif res.pvalue &lt; 0.05:\n    print(\"Reject null hypothesis. Therefore, the data is significantly different.\")\nres\n\nMon 2024-11-18 21:44:18.996180\n\n\n\nINFO     Reject null hypothesis. Therefore, the data is significantly different.                      nucleus.py:53\n\n\n\n\n\n\n\nFriedmanchisquareResult(statistic=13.653061224489791, pvalue=0.003417529443793913)\n\n\n\nNemenyi 是其中的一个 对应于 Friedman 的测试。\n首先我们需要计算4个方法的平均排名（在同一个cv fold上，相互之间的排名），这个是 判断哪个方法更好的核心依据。\n\navg_rank = analysis_df_regular.groupby('runs').value.rank(pct=True).groupby(analysis_df_regular.params_kernel).mean().sort_values(ascending=False)\navg_rank\n\n\n\n\n\nparams_kernel\npoly       0.950\nlinear     0.775\nrbf        0.525\nsigmoid    0.250\nName: value, dtype: float64\n\n\n\n按照平均排名重新排序\n\nanalysis_df = analysis_df[avg_rank.index]\nanalysis_df\n\n\n\n\n\n\n\n\n\n\nparams_kernel\npoly\nlinear\nrbf\nsigmoid\n\n\nindex\n\n\n\n\n\n\n\n\n0\n0.993056\n0.986111\n0.975694\n0.940972\n\n\n1\n0.986111\n0.989583\n0.982639\n0.934028\n\n\n2\n0.989547\n0.986063\n0.986063\n0.940767\n\n\n3\n0.982578\n0.975610\n0.972125\n0.937282\n\n\n4\n1.000000\n0.989547\n0.982578\n0.933798\n\n\n\n\n\n\n\n\narray_data = analysis_df.values\narray_data\n\n\n\n\n\narray([[0.99305556, 0.98611111, 0.97569444, 0.94097222],\n       [0.98611111, 0.98958333, 0.98263889, 0.93402778],\n       [0.98954704, 0.98606272, 0.98606272, 0.94076655],\n       [0.9825784 , 0.97560976, 0.97212544, 0.93728223],\n       [1.        , 0.98954704, 0.9825784 , 0.93379791]])\n\n\n\n\nimport scikit_posthocs as sp\n\n\n# res = sp.posthoc_nemenyi_friedman(analysis_df_regular, \n#                                   block_col=\"runs\", \n#                                   group_col=treatment, y_col=target, sort=True)\nres = sp.posthoc_nemenyi_friedman(array_data) \nres\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n1.000000\n0.826788\n0.158925\n0.003389\n\n\n1\n0.826788\n1.000000\n0.611061\n0.049612\n\n\n2\n0.158925\n0.611061\n1.000000\n0.532733\n\n\n3\n0.003389\n0.049612\n0.532733\n1.000000\n\n\n\n\n\n\n\n\nsp.sign_plot(res, xticklabels=avg_rank.index, yticklabels=avg_rank.index, **heatmap_args)\n\n\n\n\n\n(&lt;Axes: &gt;, &lt;matplotlib.colorbar.Colorbar object at 0x7f3b1845e0e0&gt;)\n\n\n\n\n\n\n\n\n\n\n\n\n\n从检验的结果图可以看出，poly和linear方法明显优于sigmoid，而其他方法之间就没有足够的实验证据来进行比较。 这说明sigmoid方法即使调到了较优的超参数，还是显著比前两个方法要弱一些，不建议新手使用。\n\nplt.title('Critical difference diagram of average score ranks')\nsp.critical_difference_diagram(avg_rank, res)\npass\n\n\n\n\n\n\n\n\n\n\n\n我们还画出了 Critical difference diagram。 图中靠右边的方法平均排名高，左边的方法平均排名低。 排名的差距是否具有统计上的显著性，关键看差距是否大于图中的黑色实线的长度。\n我们可以看到poly几乎就要显著优于rbf了，而rbf几乎就要显著优于sigmoid了，但是都还差一点不太显著。\n\n\n0.4.2.5 如何解释 poly kernel 为什么显著优于 sigmoid kernel? SVM决策边界可视化分析\n如果是2维或者3维的数据，我们可以画图来解释SVM工作的原理，绘制决策边界，但是我们现在是 64维 (UCI digits) 或者 728维 (MNIST) 的输入数据。这一方面可以参考这一个工具mlxtend，对SVM的可视化非常全面。\n对于深度学习模型来说，深度学习最后一层的特征往往被认为是表示学习的结果，用来进行降维可视化，但是我们这里 SVM 是单层的模型，没有对特征进行变换，输入的维度就已经是特征。直接对输入的数据特征进行降维可视化，完全无法展示SVM的能力，因为SVM并不是一个特征提取器。\n综合stackoverflow讨论 和 quora讨论，我认为有两个主要方法。\n\n对降维后的数据重新使用不同kernel的SVM来学习，进一步绘制决策边界。使用刚才每一个kernel下调参最优的SVM参数来进行训练。\nSVM的概率输出，概率本身就是一个重要的信息，体现了不同SVM的决策有何不同。类似与Fisher提出的LDA分类方法自己也是一种降维方法，带概率输出的SVM把输入维度映射到类别维度上的概率值，本身是一种降维手法，而且体现了不同参数SVM的学习有何不同。\n\n如果不是为了看SVM的能力，而是为了解释kernel method的能力，我们还可以使用 KernelPCA 的可视化进行分析。\n首先我们调取最优的训练参数\n\nfrom sklearn.svm import SVC\n\n\n# 提取以 'params_' 开头的列\nparam_cols = [col for col in max_rows.columns if col.startswith('params_')]\n\n# 去掉 'params_' 前缀并重命名列\nmax_rows_params = max_rows[param_cols].rename(columns=lambda x: x[len('params_'):])\n\n# 将每一行转换为字典的列表\ndict_list = max_rows_params.to_dict('records')\ndict_list[0]\n\n\n\n\n\n{\n    'C': 60.42963902381333,\n    'break_ties': True,\n    'class_weight': 'balanced',\n    'coef0': 0.34375,\n    'decision_function_shape': 'ovr',\n    'degree': 6.0,\n    'gamma': 'scale',\n    'kernel': 'linear',\n    'max_iter': 656.0,\n    'shrinking': True,\n    'tol': 0.008058421877614822\n}\n\n\n\noptuna优化时，把数据类型有些变成了float，需要更正。\n\nfrom dataclasses import fields\nfrom typing import get_args, Union\n\n\nsource\n\n\n\n\n0.5 dict_to_dataclass\n\n dict_to_dataclass (dataclass_type, data_dict)\n\n\n\nExported source\ndef dict_to_dataclass(dataclass_type, data_dict):\n    converted_dict = {}\n    for field in fields(dataclass_type):\n        field_name = field.name\n        field_type = field.type\n        if field_name in data_dict:\n            value = data_dict[field_name]\n            # 处理 Union 类型\n            if getattr(field_type, '__origin__', None) is Union:\n                # 获取 Union 中的所有类型\n                types = get_args(field_type)\n                # 选择第一个非 NoneType 的类型\n                non_none_types = [t for t in types if t is not type(None)]\n                target_type = non_none_types[0] if non_none_types else None\n                # print(target_type)\n                if target_type not in [dict, list, tuple]: # TODO 递归处理\n                    converted_dict[field_name] = target_type(value)\n                else:\n                    converted_dict[field_name] = value\n            else:\n                converted_dict[field_name] = field_type(value)\n    return dataclass_type(**converted_dict)\n\n\n\n# 将 dict_list 中的参数转换为 SupportVectorClassifierConfig 的实例列表\nconfigs = [dict_to_dataclass(SupportVectorClassifierConfig, params) for params in dict_list]\n# 根据 dict_list 初始化 SVC 列表\nsvc_list = [SVC(**asdict(config)) for config in configs]\nsvc_list[0]\n\nSVC(C=60.42963902381333, break_ties=True, class_weight='balanced',\n    coef0=0.34375, degree=6, kernel='linear', max_iter=656,\n    tol=0.008058421877614822)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiNot fittedSVC(C=60.42963902381333, break_ties=True, class_weight='balanced',\n    coef0=0.34375, degree=6, kernel='linear', max_iter=656,\n    tol=0.008058421877614822) \n\n\n然后我们先使用第一种分析方法，做降维。\n\nfrom sklearn.decomposition import PCA\n\n\n# 定义 PCA 模型，设定降维后的维度，例如 n_components=10\npca = PCA(n_components=2)\n\n# 对 X_train 进行降维\nX_train_reduced = pca.fit_transform(X_train)\n\n# 对 X_test 进行降维\nX_test_reduced = pca.transform(X_test)\n\n# 查看 pca 的一些指标\npca.explained_variance_ratio_\n\n\n\n\n\narray([0.12330114, 0.10126638], dtype=float32)\n\n\n\n可视化\n\nlabels = [svc.kernel for svc in svc_list]\nlabels[0]\n\n\n\n\n\n'linear'\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_decision_regions\nimport matplotlib.gridspec as gridspec\nimport itertools\n\n\ngs = gridspec.GridSpec(2, 2)\n\nfig = plt.figure(figsize=(10,8))\n\nfor clf, lab, grd in zip(svc_list,\n                         labels,\n                         itertools.product([0, 1], repeat=2)):\n\n    clf.fit(X_train_reduced, y_train)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=X_train_reduced, y=y_train, clf=clf, legend=2)\n    plt.title(lab)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n0.5.0.1 如何解释 poly kernel 为什么显著优于 sigmoid kernel? Kernel SVM概率输出的画图分析\n首先在没有降维的数据集上按照最优参数来训练SVC。注意为了速度，刚才调参的时候没有probality=True，现在为了分析需要有。\n\nsvc_list = [SVC(**(asdict(config)| dict(probability=True)) )  for config in configs]\nsvc_list = [svc.fit(X_train, y_train) for svc in svc_list]\n\n得到 y_pred_prob\n\ny_pred_train_probs = [svc.predict_proba(X_train) for svc in svc_list]\ny_pred_test_probs = [svc.predict_proba(X_test) for svc in svc_list]\n\n\nsource\n\n\n\n0.6 draw_probs\n\n draw_probs (y_pred_prob, y_test, interested_class:int)\n\n\n\nExported source\nimport seaborn as sns\n\n\n\n\nExported source\ndef draw_probs(y_pred_prob, y_test, interested_class:int):\n    sns.scatterplot(y_pred_prob[y_test!=interested_class][:, interested_class], label=f\"is not {interested_class}\")\n    sns.scatterplot(y_pred_prob[y_test==interested_class][:, interested_class], label=f\"is {interested_class}\", color=\"red\")\n\n\n\n# 对所有的 y_pred_train_probs 和 y_pred_test_probs，调用 draw_probs 函数并绘制图形\n# intersted_class = 0\nintersted_class = 3\nfor i, model_name in enumerate(labels):\n    train_probs = y_pred_train_probs[i]\n    test_probs = y_pred_test_probs[i]\n    \n    # 创建左右并排的图形\n    plt.figure(figsize=(12, 5))\n    \n    # 绘制训练集的概率分布图\n    plt.subplot(1, 2, 1)\n    draw_probs(train_probs, y_train, interested_class=intersted_class)\n    plt.title(f'{model_name} - Training Set')\n    \n    # 绘制测试集的概率分布图\n    plt.subplot(1, 2, 2)\n    draw_probs(test_probs, y_test, interested_class=intersted_class)\n    plt.title(f'{model_name} - Test Set')\n    \n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们在图上可以比较明显地看出，sigmoid相比其他方法，probabilities 会往上和往下飘，是否为这个类别的分隔的不是很开，所以最后的效果不如poly。而其他方法可能测试集会稍微没有训练集分隔得开。\n除了直接画出来概率的散点图，还有一些更加成熟的机器学习绘图分析，可以更加直观地看到模型的差距在哪。\n\nimport scikitplot as skplt\nimport scikitplot as skplt\nimport matplotlib.pyplot as plt\n\n\n# 假设 labels 是模型名称的列表，与预测概率列表对应\n# labels = ['linear', 'poly', 'rbf', 'sigmoid']\n\nfor i, model_name in enumerate(labels):\n    train_probs = y_pred_train_probs[i]\n    test_probs = y_pred_test_probs[i]\n    \n    # 创建左右并排的图形\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # 绘制训练集的 ROC 曲线\n    skplt.metrics.plot_roc(y_train, train_probs, ax=ax1)\n    ax1.set_title(f'{model_name} - Training Set')\n    \n    # 绘制测试集的 ROC 曲线\n    skplt.metrics.plot_roc(y_test, test_probs, ax=ax2)\n    ax2.set_title(f'{model_name} - Test Set')\n    \n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n图中可以明显看到 sigmoid kernel方法在 类别 1和8上面表现不佳。而poly的曲线接近完美。\n\n0.6.0.1 如何解释 poly kernel 为什么显著优于 sigmoid kernel? Kernel PCA 可视化\n\nfrom sklearn.decomposition import KernelPCA\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\n# labels = ['linear', 'poly', 'rbf', 'sigmoid']\n\nfor kernel in labels:\n    # 使用 Kernel PCA 将数据降维到 3 维\n    kpca = KernelPCA(n_components=3, kernel=kernel)\n    X_train_reduced = kpca.fit_transform(X_train)\n    X_test_reduced = kpca.transform(X_test)\n    \n    # 创建一个包含两个子图的图形\n    fig = plt.figure(figsize=(12, 6))\n    \n    # 绘制训练集的 3D 散点图\n    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n    scatter1 = ax1.scatter(\n        X_train_reduced[:, 0], X_train_reduced[:, 1], X_train_reduced[:, 2],\n        c=y_train, cmap='viridis', marker='o', edgecolor='k', s=40\n    )\n    ax1.set_title(f'Kernel PCA with {kernel} kernel (Training Set)')\n    ax1.set_xlabel('Component 1')\n    ax1.set_ylabel('Component 2')\n    ax1.set_zlabel('Component 3')\n    legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Classes\")\n    ax1.add_artist(legend1)\n    \n    # 绘制测试集的 3D 散点图\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    scatter2 = ax2.scatter(\n        X_test_reduced[:, 0], X_test_reduced[:, 1], X_test_reduced[:, 2],\n        c=y_test, cmap='viridis', marker='^', edgecolor='k', s=40\n    )\n    ax2.set_title(f'Kernel PCA with {kernel} kernel (Test Set)')\n    ax2.set_xlabel('Component 1')\n    ax2.set_ylabel('Component 2')\n    ax2.set_zlabel('Component 3')\n    legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Classes\")\n    ax2.add_artist(legend2)\n    \n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.7 附加题: 构建使用 kernel 方法的 SVM 分类器 （手动实现SMO）\n在 02svm_handy_crafted_linear 中，我们已经手动实现了 基于梯度下降方法的 Linear SVM 分类器。在这一节，我们将手动实现 基于 SMO 方法的 SVM 分类器，以便于我们可以更好地理解 SVM 的原理。\n接下来的内容请见文件 04svm_handy_crafted_kernel\n本次Project的目录请见绪论 00svm。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——03不同Kernel的SVM超参数优化"
    ]
  },
  {
    "objectID": "coding_projects/P1_KNN/kd_tree.html",
    "href": "coding_projects/P1_KNN/kd_tree.html",
    "title": "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用",
    "section": "",
    "text": "代码复现说明\n我们的代码导出为了python模块形式",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_KNN",
      "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用"
    ]
  },
  {
    "objectID": "coding_projects/P1_KNN/kd_tree.html#实验目的",
    "href": "coding_projects/P1_KNN/kd_tree.html#实验目的",
    "title": "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用",
    "section": "1 实验目的",
    "text": "1 实验目的\n\n老师给我们的要求是 1. 完成 KD 树算法，并利⽤实现的算法完成数字识别任务 2. 对所建模型进行分析评判。\n\n我们不仅完成以上内容，还进行了 1. 参考谷歌调参手册，使用科学的实验设计来对KNN分类算法的元参数进行搜索，从而实现更高的分类精度。 2. 参考前沿论文，尝试修改KD树的训练策略，从而对KD树的推理速度进行改进。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_KNN",
      "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用"
    ]
  },
  {
    "objectID": "coding_projects/P1_KNN/kd_tree.html#实验数据",
    "href": "coding_projects/P1_KNN/kd_tree.html#实验数据",
    "title": "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用",
    "section": "2 实验数据",
    "text": "2 实验数据\n\nMNIST 数据库是由 Yann et. al. 提供的⼿写数字数据库⽂件, 官网地址为 http://yann.lecun.com/exdb/mnist/。 主要包含了 60000 张的训练图像和 10000 张的测试图像\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n# 获取MNIST数据集,并抽样一部分数据以便后续的计算\nidx = np.random.choice(70000,5000,replace=False)\nmnist = fetch_openml(\"mnist_784\")\nX, y = mnist.data.to_numpy(), mnist.target.to_numpy().astype('int')\nX = X[idx]\ny = y[idx]\n# 划分数据集为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n以上代码有几个小问题，我们需要改进一下 1. 由于网络环境问题，fetch_openml(“mnist_784”) 是无法跑通的，会卡死。 事实上，给sklearn贡献过代码的同学可能知道，sklearn还有一个load_digits数据集，这个数据集是sklearn CI（持续集成）测试用例的一部分。这个回归测试通过测试贡献者的新做的改进是否导致性能不如以前的版本，来决定是否接受更改。 因此，我们使用load_digits数据集代替mnist_784数据集来完成这个项目。\nhttps://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_digits.html\n\n划分数据集时，train_test_split应当使用stratify参数，以确保每一类样本的比例相同。\nimport过多，应该只导入需要的模块。\n\n\nfrom sklearn.datasets import load_digits\ndataset_dict = load_digits()\ndataset_dict.keys()\n\ndict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n\n\n\nimport numpy as np\nX:np.array = dataset_dict['data']\ny:np.array = dataset_dict['target']\nX.shape, X.dtype, y.shape, y.dtype\n\n((1797, 64), dtype('float64'), (1797,), dtype('int64'))\n\n\n划分数据集为训练集和测试集\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, \n                                                    stratify=y)\nlen(X_train), len(X_test)\n\n(1437, 360)",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_KNN",
      "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用"
    ]
  },
  {
    "objectID": "coding_projects/P1_KNN/kd_tree.html#实验内容",
    "href": "coding_projects/P1_KNN/kd_tree.html#实验内容",
    "title": "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用",
    "section": "3 实验内容",
    "text": "3 实验内容\n\n3.1 KNN和KD树的关系是什么？什么叫基于KD树的KNN算法？\n在我们开始实验内容之前，有必要澄清这一理论上的概念。\nKNN（K-Nearest Neighbor）算法是一种基本的机器学习算法，既可以用于分类也可以用于回归。 对于新的一个测试样本（未知类别或标签值）来说，它和训练集中每一个样本都有距离，从而存在离测试样本最近的K个样本（当然训练集要大于K啦），然后根据这些样本的已知标签来决定测试样本的标签。\n\n我今天学习的《自然辩证法课》上正好讲到一个哲学概念叫做“类比推理”与“演绎推理”。古希腊的哲学家们则发展了形式逻辑，比如亚里士多德的三段论，我们在《数理逻辑导论》课上还了解了罗素、哥德尔等人对整套逻辑的进一步发展。而中国古代的先贤很喜欢类比推理，比如孟子要提倡“舍生而取义者也”，偏偏不和你论证为什么要舍生取义（后文也有一点论证），而是先跟你说他观察到了“二者不可得兼，舍鱼而取熊掌者也。”，然后他认为这两个事情很像，然后告诉你所以要舍生取义；又比如孟子想要说“天将降大任于是人也，必先苦其心志”，他先给了你一个训练集，说好多“降大任”的“人”都是被“苦其心志的”。这个推理看起来很扯，实际上也是也是有一定的统计意义的。\n\n而KD树（k-dimensional tree）是一种用于组织k维空间数据的树形数据结构，它是一种特殊的二叉树。KD树将k维空间进行分割，每个节点代表一个k维超矩形区域。KD树的主要作用是在高维空间中快速地进行最近邻查找，它能够显著减少在KNN算法中计算所有训练样本与测试样本之间距离的需求，从而提高效率。\nKNN不一定要使用KD树来进行近邻搜索，事实上还有其他更加高效的数据结构，比如Ball Tree。如果我们说默认的KNN是用暴力方法计算所有距离的逐一比较的话，我们可以说KD树不是KNN算法的一部分，而是KNN算法的一个优化工具，用于在高维空间中快速查找最近邻。\n\n\n3.2 基于sklearn的KNN算法实现手写数字识别\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n# 创建KNeighborsClassifier模型，使用kd树作为搜索算法\nknn = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n\n# 在训练集上训练模型\nknn.fit(X_train, y_train)\n\n# 在测试集上进行预测\ny_pred = knn.predict(X_test)\n\n# 评估模型性能\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n\nKNN Accuracy: 98.61%\n\n\n\n\n3.3 自己实现KD树\n\nsource\n\n\n3.4 euclidean_distance\n\n euclidean_distance (x1, x2)\n\n\nsource\n\n\n3.5 build_kd_tree\n\n build_kd_tree (X, depth=0)\n\n\nsource\n\n\n3.6 Node\n\n Node (data, left=None, right=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n# 这里我们需要注意使用PriorityQueue的一个坑点，same priority 下 会崩溃； PriorityQueue文档没写，heapq写了\n# https://docs.python.org/3/library/heapq.html\nclass TestNode:\n    def __init__(self, point):\n        self.point = point\n\n\ntest1 = [\n    (-13.30413469565007, 1.2),\n    (-9.327379053088816, 0.0),\n    (-13.30413469565007, 1.4),\n]\ntest2 = [\n    (-13.30413469565007, TestNode(1.2)),\n    (-9.327379053088816, TestNode(0.0)),\n    (-13.30413469565007, TestNode(1.4)),\n]\n\ntest3 = [\n    (0, TestNode(1.2)),\n    (1, TestNode(0.0)),\n    (2, TestNode(1.4)),\n]\n\ntest_pq = PriorityQueue()\nfor t in test1:\n    test_pq.put(t)\nprint(test_pq.get())\ntest_pq = PriorityQueue()\nfor t in test3:\n    test_pq.put(t)\nprint(test_pq.get())\n# 注意这种情况下报错\n# for t in test2:\n#     test_pq.put(t)\n# print(test_pq.get())\n\n(-13.30413469565007, 1.2)\n(0, &lt;__main__.TestNode object&gt;)\n\n\n\nsource\n\n\n3.7 knn_classifier\n\n knn_classifier (X_train, y_train, X_test, k=3)\n\n\nsource\n\n\n3.8 search_kd_tree\n\n search_kd_tree (tree, target, k=3)\n\n\n# 构建KD树\nkd_tree = build_kd_tree(X_train)\n\n\n# 使用KNN算法进行分类\nk_neighbors = 3\ny_pred = knn_classifier(X_train, y_train, X_test, k_neighbors)\n\n# 评估分类性能\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n\nKNN Accuracy: 98.61%\n\n\n\n\n3.9 超参数调优\n实验题目要求我们对 knn 进⾏超参数的搜索。那么什么是超参数搜索呢？为此我们需要理解两个概念——超参数和搜索。\n\n3.9.1 什么是参数？什么是超参数？什么是元参数？\n在大数据分析中，我们往往不知道数据的总体，只能获得数据的一个采样。然而我们对数据的总体是什么分布非常感兴趣，这些未知的分布，我们假设可能是由一些参数来决定的，我们需要根据采样出来的数据对总体的参数进行参数估计（Parameter Estimation）。比如说总体是高斯分布，那么高斯分布的均值和方差就是参数。\n刚才我们说了参数是什么，那么什么是超参数呢？参数估计我们通常会用极大似然估计方法，但是相比于贝叶斯参数估计来说有一定的局限性。在贝叶斯机器学习中，我们认为参数本身也是有一个概率分布的，而不是确定的值，而描述参数分布的参数，我们称之为超参数。当然，我们可以认为超参数也有其分布，那么就有对应的超超参数，这种多层嵌套的结构称为贝叶斯网络。\n对应到机器学习和深度学习中，参数是指参数化模型的权重。但是我们没有在使用贝叶斯估计，并没有说这些模型权重具有一定的分布，那么超参数是怎么一回事呢？事实上，根据谷歌团队提出的《深度学习调优指南》(Godbole 等 2023)，深度学习社区错误地把学习率、批处理大小、正则化系数等参数叫做超参数，这是错误的。他们确实决定了模型的假设空间的不同，决定了最终的性能，而且在模型训练过程中不发生变化，而是决定了训练过程，但是他们本身并不是先验分布的参数，严格来说不应该叫做超参数，应该叫做元参数。\n\n\n3.9.2 什么是搜索？\n搜索是人工智能中的重要的方法(Russell 和 Norvig 2016)。搜索包括约束可满足问题和最优化问题，以及带有约束的优化问题。 这里我们说的超参数优化，一般来说是带有约束的优化问题。 其中约束是指，有些超参数组合如果错误地选择，会导致机器学习系统崩溃，或者算法无法收敛。\n然而这些约束我们很可能是不知道的，需要调参算法本身尝试。 有时候我们发现的约束可能暗示着代码存在错误，或者深度学习模型本身的优化过程不够稳定，如果是后者，可以通过Gradient Clip, 降低学习率等方法来缓解。\n\n\n3.9.3 KNN和KD树有哪些元参数？\n上文我们辨析了KNN和KD树的关系，即是否选用KD树作为KNN的近邻搜索算法，本身是KNN的一个元参数，KNN也可以选择Ball Tree、Brute Force等其他近邻搜索算法。\nKD树本身也有一些元参数，比如分割方式、节点的选择方式等，这些元参数会影响KD树的构建和搜索的系统性能（时间复杂度、空间复杂度），但是不会影响到机器学习的性能（分类准确率、ROC-AUC等指标）。因为不影响机器学习的性能，在本节我们不讨论KD树的元参数如何调优。我们会在下一节，附加题中，讨论不同的KD树构建方式对搜索速度的影响。\n那么KNN作为一个机器学习算法，有哪些元参数需要调优呢？参考sklearn的KNeighborsClassifier类的参数说明，我们可以看到以下参数\n\n# help(KNeighborsClassifier)\n# 使用 ipython的 ? 可以更好地看到 函数和类的docstring信息。\nKNeighborsClassifier?\n\nInit signature:\nKNeighborsClassifier(\n    n_neighbors=5,\n    *,\n    weights='uniform',\n    algorithm='auto',\n    leaf_size=30,\n    p=2,\n    metric='minkowski',\n    metric_params=None,\n    n_jobs=None,\n)\nDocstring:     \nClassifier implementing the k-nearest neighbors vote.\n\nRead more in the :ref:`User Guide &lt;classification&gt;`.\n\nParameters\n----------\nn_neighbors : int, default=5\n    Number of neighbors to use by default for :meth:`kneighbors` queries.\n\nweights : {'uniform', 'distance'}, callable or None, default='uniform'\n    Weight function used in prediction.  Possible values:\n\n    - 'uniform' : uniform weights.  All points in each neighborhood\n      are weighted equally.\n    - 'distance' : weight points by the inverse of their distance.\n      in this case, closer neighbors of a query point will have a\n      greater influence than neighbors which are further away.\n    - [callable] : a user-defined function which accepts an\n      array of distances, and returns an array of the same shape\n      containing the weights.\n\n    Refer to the example entitled\n    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`\n    showing the impact of the `weights` parameter on the decision\n    boundary.\n\nalgorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n    Algorithm used to compute the nearest neighbors:\n\n    - 'ball_tree' will use :class:`BallTree`\n    - 'kd_tree' will use :class:`KDTree`\n    - 'brute' will use a brute-force search.\n    - 'auto' will attempt to decide the most appropriate algorithm\n      based on the values passed to :meth:`fit` method.\n\n    Note: fitting on sparse input will override the setting of\n    this parameter, using brute force.\n\nleaf_size : int, default=30\n    Leaf size passed to BallTree or KDTree.  This can affect the\n    speed of the construction and query, as well as the memory\n    required to store the tree.  The optimal value depends on the\n    nature of the problem.\n\np : float, default=2\n    Power parameter for the Minkowski metric. When p = 1, this is equivalent\n    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected\n    to be positive.\n\nmetric : str or callable, default='minkowski'\n    Metric to use for distance computation. Default is \"minkowski\", which\n    results in the standard Euclidean distance when p = 2. See the\n    documentation of `scipy.spatial.distance\n    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and\n    the metrics listed in\n    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n    values.\n\n    If metric is \"precomputed\", X is assumed to be a distance matrix and\n    must be square during fit. X may be a :term:`sparse graph`, in which\n    case only \"nonzero\" elements may be considered neighbors.\n\n    If metric is a callable function, it takes two arrays representing 1D\n    vectors as inputs and must return one value indicating the distance\n    between those vectors. This works for Scipy's metrics, but is less\n    efficient than passing the metric name as a string.\n\nmetric_params : dict, default=None\n    Additional keyword arguments for the metric function.\n\nn_jobs : int, default=None\n    The number of parallel jobs to run for neighbors search.\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`\n    for more details.\n    Doesn't affect :meth:`fit` method.\n\nAttributes\n----------\nclasses_ : array of shape (n_classes,)\n    Class labels known to the classifier\n\neffective_metric_ : str or callble\n    The distance metric used. It will be same as the `metric` parameter\n    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n    'minkowski' and `p` parameter set to 2.\n\neffective_metric_params_ : dict\n    Additional keyword arguments for the metric function. For most metrics\n    will be same with `metric_params` parameter, but may also contain the\n    `p` parameter value if the `effective_metric_` attribute is set to\n    'minkowski'.\n\nn_features_in_ : int\n    Number of features seen during :term:`fit`.\n\n    .. versionadded:: 0.24\n\nfeature_names_in_ : ndarray of shape (`n_features_in_`,)\n    Names of features seen during :term:`fit`. Defined only when `X`\n    has feature names that are all strings.\n\n    .. versionadded:: 1.0\n\nn_samples_fit_ : int\n    Number of samples in the fitted data.\n\noutputs_2d_ : bool\n    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n    otherwise True.\n\nSee Also\n--------\nRadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\nKNeighborsRegressor: Regression based on k-nearest neighbors.\nRadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\nNearestNeighbors: Unsupervised learner for implementing neighbor searches.\n\nNotes\n-----\nSee :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation\nfor a discussion of the choice of ``algorithm`` and ``leaf_size``.\n\n.. warning::\n\n   Regarding the Nearest Neighbors algorithms, if it is found that two\n   neighbors, neighbor `k+1` and `k`, have identical distances\n   but different labels, the results will depend on the ordering of the\n   training data.\n\nhttps://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n\nExamples\n--------\n&gt;&gt;&gt; X = [[0], [1], [2], [3]]\n&gt;&gt;&gt; y = [0, 0, 1, 1]\n&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier\n&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)\n&gt;&gt;&gt; neigh.fit(X, y)\nKNeighborsClassifier(...)\n&gt;&gt;&gt; print(neigh.predict([[1.1]]))\n[0]\n&gt;&gt;&gt; print(neigh.predict_proba([[0.9]]))\n[[0.666... 0.333...]]\nFile:           ~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/neighbors/_classification.py\nType:           ABCMeta\nSubclasses:     \n\n\n其中这几个参数是和分类准确率有关的 - n_neighbors, 也就是k - weights，检索出来的k个点用来决策，这些点一样重要吗？ - 我们李航书学的基础版本是uniform，而distance方法不一样在于 - 每一个点的投票权是距离的-1次方。（哈哈为什么不是像万有引力那样是-2次方） - p和metric和metric_params, 要怎么计算距离？\n而 algorithm leaf_size n_jobs 三个参数暂时和我们无关。\n\nfrom sklearn.metrics.pairwise import distance_metrics\ndistance_metrics().keys()\n\ndict_keys(['cityblock', 'cosine', 'euclidean', 'haversine', 'l2', 'l1', 'manhattan', 'precomputed', 'nan_euclidean'])\n\n\n\n\n3.9.4 具体要怎么调参呢？\n如果我们就把调参问题当做搜索问题，那么它就是一个无梯度黑盒最优化问题。对于这类问题，最平凡（trivial）的搜索方法是全盘遍历（grid search），然而当搜索空间太大的时候，这就不是很高效了。一些基础的改进是贪心算法和随机化搜索方法，比如爬山法、随机采样法、模拟退火法等(Russell 和 Norvig 2016)。而要想得到最先进（SOTA）的性能，演化计算和贝叶斯优化是两个最好的方法，也是目前人工智能仍然活跃的科研方向(Russell 和 Norvig 2016)。\n然而调参问题并不完全是搜索问题。Google的《深度学习调优指南》(Godbole 等 2023)指出，调参是一个“探索与利用”（exploration and exploitation）的过程。我的理解是，在我们做深度学习研究的时候，我们其实更想知道，我们的方法对于那些超参数敏感，在其他方法也调到最优超参的情况下我的方法是否仍然显著优于其他方法，而不只是说我的方法在单单一个超参数上优于其他方法（选择“我的方法”还是“其他近期SOTA方法”就是一个离散型目标元参数）。因此，我们需要在调参的过程中理解不同的参数对于结果的影响。这其实也是作为科学家和研究者我们做科学实验的过程。调参的实质不是乱试，而是“控制变量”，参数就是自变量和无关变量，评价指标就是因变量。不过，与我们高中生物课学习的“控制变量法”稍有不同，无关变量不一定是控制相等，在计算资源充足时，无关变量应该控制到最优，所以这里有优化问题。\n对于具体的调参算法和代码而言，我们当然可以用sklearn默认提供的GridSearchCV、RandomizedSearchCV等方法，我猜做这个作业的大部分同学用的是这两个。但是刚才我们也说了，GridSearch代价太高，而RandomizedSearchCV以及贝叶斯优化、演化计算忙于“利用”，而没有进行单一变量原则，无法通过科学实验“探索”出我们想获得的insight。根据Google的建议，在探索阶段最适合的算法其实是准随机搜索算法（quasi random search）。\n因此，我们遵循google指南，使用Optuna+Ray Tune中的Quasi Random Search实现来进行调参。\n此外，我还实现了一个“学生实验算法”，这个算法从优化上来说是一种交替优化（alternating optimization）或者叫做多阶段优化（multi-stage optimization）的方法，即先固定一个超参数，然后在这个超参数下进行优化，再固定另一个超参数，再进行优化，以此类推，直到所有超参数都优化完毕。这个算法的好处是遵循了单一变量原则和无关变量控制相等原则，可以探索出很多结论。我把这个算法写成了一个pypi库，可见github连接。\n在这里我们也做一个科学实验，实验假设是在其他参数最优时，使用”distance”的KNN比普通的”uniform”KNN的效果好。 这样我们有一个研究的目标，相当于我们扮演那个提出”distance”方法的科学家，要和其他人的方法做比较才能发论文。\n\n\n3.9.5 代码实现调优\n首先我们需要定义KNN元参数的分布空间\n然后我们定义评价函数\n\nsource\n\n\n\n3.10 evaluate_knn\n\n evaluate_knn (weights:str, n_neighbors:int, distance_metric:str,\n               random_seed:int=42)\n\n\nsource\n\n\n3.11 objective\n\n objective (meta_parameters)\n\n接下来我们要定义使用的搜索算法。\n\nfrom ray.tune.search import ConcurrencyLimiter\nfrom ray.tune.search.optuna import OptunaSearch\nfrom optuna.samplers import QMCSampler\n# quasi random search\nsampler = QMCSampler()\nalgo = OptunaSearch(sampler=sampler)\nalgo = ConcurrencyLimiter(algo, max_concurrent=4)\n\nExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n  sampler = QMCSampler()\n\n\ntuner = tune.Tuner(\n    objective,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_score\",\n        mode=\"max\",\n        num_samples=100,\n        # num_samples=3,\n        search_alg=algo,\n    ),\n    param_space=search_space,\n)\nresults:tune.ResultGrid  = tuner.fit()\n\nexperiment_dir = \"/home/ycm/ray_results/objective_2024-10-22_23-27-35\"\n# https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html\nrestored_tuner = tune.Tuner.restore(experiment_dir, objective)\nresults = restored_tuner.get_results()\n\n\nresults.errors\n\n[]\n\n\n\n3.11.1 调优结果分析\n\nfrom ray.train import Result\nbest_result:Result = results.get_best_result()\n{k:v for k,v in best_result.metrics.items() if \"score\" in k}, best_result.config\n\n({'mean_score': 0.9860796554394116,\n  'std_score': 0.003124647521844644,\n  'score_0': 0.9861111111111112,\n  'score_1': 0.9895833333333334,\n  'score_2': 0.9825783972125436,\n  'score_3': 0.9825783972125436,\n  'score_4': 0.9895470383275261},\n {'weights': 'distance', 'n_neighbors': 1, 'distance_metric': 'euclidean'})\n\n\n\ndf = results.get_dataframe(\n    filter_metric=\"mean_score\", filter_mode=\"max\"\n)\ndf.head()\n\n\n\n\n\n\n\n\nmean_score\nstd_score\nscore_0\nscore_1\nscore_2\nscore_3\nscore_4\ntimestamp\ncheckpoint_dir_name\ndone\n...\ntime_total_s\npid\nhostname\nnode_ip\ntime_since_restore\niterations_since_restore\nconfig/weights\nconfig/n_neighbors\nconfig/distance_metric\nlogdir\n\n\n\n\n0\n0.978421\n0.008356\n0.972222\n0.993056\n0.972125\n0.972125\n0.982578\n1729610862\nNone\nFalse\n...\n0.142350\n302368\namax\n10.103.10.61\n0.142350\n1\nuniform\n8\nl2\n9db3a177\n\n\n1\n0.972854\n0.006012\n0.972222\n0.982639\n0.965157\n0.968641\n0.975610\n1729610871\nNone\nFalse\n...\n0.249111\n303174\namax\n10.103.10.61\n0.249111\n1\nuniform\n15\nnan_euclidean\nad504238\n\n\n2\n0.978424\n0.007435\n0.972222\n0.989583\n0.968641\n0.982578\n0.979094\n1729610864\nNone\nFalse\n...\n0.072539\n302745\namax\n10.103.10.61\n0.072539\n1\ndistance\n17\ncosine\nc0464454\n\n\n3\n0.986080\n0.003125\n0.986111\n0.989583\n0.982578\n0.982578\n0.989547\n1729610866\nNone\nFalse\n...\n0.051633\n302934\namax\n10.103.10.61\n0.051633\n1\ndistance\n1\neuclidean\n5cc5dc31\n\n\n4\n0.974937\n0.009465\n0.975694\n0.989583\n0.961672\n0.968641\n0.979094\n1729610869\nNone\nFalse\n...\n0.401711\n303051\namax\n10.103.10.61\n0.401711\n1\nuniform\n10\nnan_euclidean\n8bd53b66\n\n\n\n\n5 rows × 24 columns\n\n\n\n\nintersted_cols = [c for c in df.columns if c.startswith(\"config\") or \"score\" in c]\ndfi = df[intersted_cols]\ndfi.head()\n\n\n\n\n\n\n\n\nmean_score\nstd_score\nscore_0\nscore_1\nscore_2\nscore_3\nscore_4\nconfig/weights\nconfig/n_neighbors\nconfig/distance_metric\n\n\n\n\n0\n0.978421\n0.008356\n0.972222\n0.993056\n0.972125\n0.972125\n0.982578\nuniform\n8\nl2\n\n\n1\n0.972854\n0.006012\n0.972222\n0.982639\n0.965157\n0.968641\n0.975610\nuniform\n15\nnan_euclidean\n\n\n2\n0.978424\n0.007435\n0.972222\n0.989583\n0.968641\n0.982578\n0.979094\ndistance\n17\ncosine\n\n\n3\n0.986080\n0.003125\n0.986111\n0.989583\n0.982578\n0.982578\n0.989547\ndistance\n1\neuclidean\n\n\n4\n0.974937\n0.009465\n0.975694\n0.989583\n0.961672\n0.968641\n0.979094\nuniform\n10\nnan_euclidean\n\n\n\n\n\n\n\n首先我们从整体上来看两个方法（distance和uniform）的性能差异。\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfig, ax = plt.subplots()\nsns.boxplot(data=dfi, x='config/weights', y='mean_score', ax=ax)\ndfi.plot(x='config/weights', y='mean_score', ax=ax, kind='scatter', c='red')\n\n\n\n\nuniform与distance方法平均准确率箱线图对比\n\n\n\n\n以上的结果并没有控制变量，是直接进行了一个统计。相关性不代表因果性，所以上面的结果仅仅代表了在我们调参采样过程中，自变量“weights”与因变量“mean_score”的一定的相关性。 如果我们不知道每一次实验具体的其他的无关变量，上面的图我们也可以做一个合理的假设检验（验证我们的实验假设的零假设是否要拒绝！）。\n根据论文(Demšar 2006)，在机器学习中应该使用mann-whitney U检验和Wilcoxon signed-rank检验，因为这两个检验对样本的分布没有假定，而其他的一些检验比如t检验不太适用与样本分布不符合假设分布的情况。其中对于 “不知道每一次实验的其他无关变量是什么”的情况，也就是说自变量取“distance”和“uniform”得到的两列样本是独立（independent）的时候，应当使用mann-whitney U检验。\n\nfrom scipy.stats import mannwhitneyu\n\n\ngrouped = dfi.groupby('config/weights')\ngroup_mean_scores = {name:group['mean_score'] for name, group in grouped}\nscores_for_distance = group_mean_scores['distance']\nscores_for_uniform = group_mean_scores['uniform']\nu, p = mannwhitneyu(scores_for_distance, scores_for_uniform, \n                    alternative='greater' # 实验备则假设，distance 方法更好\n                    )\nif p &lt; 0.05:\n    print(\"Reject null hypothesis! `distance` is significantly better than `uniform`\")\n\nReject null hypothesis! `distance` is significantly better than `uniform`\n\n\n刚才我们只是整体分析。 接下来我们要寻找控制其他变量最优时，两个方法各自最优的参数是什么？以及这两个方法对哪些超参数比较敏感？\n我们先回答第一个问题，我们从刚才的表格筛选一下。\n\nmax_rows = dfi.loc[df.groupby('config/weights')['mean_score'].idxmax()]\nmax_rows\n\n\n\n\n\n\n\n\nmean_score\nstd_score\nscore_0\nscore_1\nscore_2\nscore_3\nscore_4\nconfig/weights\nconfig/n_neighbors\nconfig/distance_metric\n\n\n\n\n3\n0.98608\n0.003125\n0.986111\n0.989583\n0.982578\n0.982578\n0.989547\ndistance\n1\neuclidean\n\n\n36\n0.98608\n0.003125\n0.986111\n0.989583\n0.982578\n0.982578\n0.989547\nuniform\n1\nl2\n\n\n\n\n\n\n\n这里我们可以对5次实验的结果进行统计分析，由于这五次实验是相关的，即这五次实验每一次用的同一个fold去训练，所以这里我们不应当用mann-whitney U检验，这一次我们要用Wilcoxon signed-rank检验。\n\nfrom scipy.stats import wilcoxon\n\n\nscores_for_distance = [v for k, v in max_rows.iloc[0].to_dict().items() if k.startswith('score_')]\nscores_for_uniform = [v for k, v in max_rows.iloc[1].to_dict().items() if k.startswith('score_')]\nu, p = wilcoxon(scores_for_distance, scores_for_uniform, \n                zero_method='zsplit',\n                    alternative='greater' # 实验备则假设，distance 方法更好\n                    )\nif p&gt; 0.05:\n    print(\"Null hypothesis cannot be rejected, so I have to accept it. \")\n\nNull hypothesis cannot be rejected, so I have to accept it. \n\n\n/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n  res = hypotest_fun_out(*samples, **kwds)\n/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Sample size too small for normal approximation.\n  res = hypotest_fun_out(*samples, **kwds)\n\n\n原来，当我们控制无关变量最优时，两个方法的性能能达到一致。具体来说，这里种找到的最优超参数正好是让knn的k为1，所以这个情况下distance方法和n_neighbors方法没有区别。按照谷歌调参手册的科研方法，对于这个数据集来说就无法说明这两个方法的优劣了。\n然而，我个人认为，一个方法之所以被学术界认为有价值，在于这个方法能被其他人follow和cite。什么样的方法能对其他人的工作有帮助，什么样的方法就有价值。形式化一点来说，对 “其他人的工作”这个随机分布而言，我们的方法“应用上去之后，比不应用我们的方法或者使用其他方法更好”这个随机变量的期望值就是我们做科研应该追求的价值。\n需要注意的是，“其他人的工作”由于他们计算资源以及研究者认知的局限，是比较不可能为你的方法调整整个实验流程其他的元参数或者说无关变量的。换句话说，如果你的方法需要其他人为你的方法来调参才能表现良好，那么你的方法的价值其实也是比较有限的。\n在这里我们就遇到这个情况，在大部分随机的无关变量上，我们看到假设检验拒绝了零假设，说明distance方法期望地来说是对其他研究人员有帮助的，然而当调参到最优时，他们又都能达到最好。\n现在我们回答第二个问题，这两个方法分别对其他元参数的敏感性如何? 首先分析对n_neighbors的敏感性。这个是通过quasi random search采样的。\n\nimport copy\n\n\nsource\n\n\n\n3.12 regplot\n\n regplot (*args, line_kws=None, marker=None, scatter_kws=None, **kwargs)\n\n\nf = plt.figure()\nax = f.add_subplot(1,1,1)\nline_dict = {}\nfor name, group in grouped:\n    # plt.scatter(group['config/n_neighbors'], group['mean_score'], label=name)\n    # p = sns.regplot(x='config/n_neighbors', y='mean_score', data=dfi, fit_reg=True, ax=ax)\n    k, b = regplot(x='config/n_neighbors', y='mean_score', data=group, label=name, fit_reg=True)\n    line_dict[name] = (k, b)\n    \n\n# sns.lmplot(x='config/n_neighbors', y='mean_score', data=dfi, hue=\"config/weights\", fit_reg=True)\n# 使用整数x坐标轴\nplt.xticks(range(1, 21))\n# plt.xlabel('n_neighbors')\n# plt.ylabel('mean_score')\nplt.legend()\n# plt.title(\"Relationship between n_neighbors and mean_score\")\nplt.show()\n# p.get_lines()[0].get_xdata(), p.get_lines()[0].get_ydata()\nfor name, (k, b) in line_dict.items():\n    print(f\"For {name}, the regression line is y = {k:.2e}x + {b:.2e}\")\n\n\n\n\n\n\n\n图 1: Relationship between n_neighbors and mean_score\n\n\n\n\n\nFor distance, the regression line is y = -9.18e-04x + 9.87e-01\nFor uniform, the regression line is y = -9.86e-04x + 9.84e-01\n\n\n从图 图 1 中可以看出，在数字识别问题上，无论是distance方法还是uniform方法，都是neighbors数量越多，精度反而越低。\n从斜率上来看可能会以为这个问题很小，只是稍微减少了精度，但是从视觉上好像确实下降地很明显。我们为了从统计上说明清楚到底下降地显不显著，可以进一步通过皮尔森相关系数以及斯皮尔曼相关系数对应的假设检验来验证这个问题。\n\nfrom scipy.stats import pearsonr, spearmanr\n\n\ndef test_correlation_with(x, y, data, test_func, alpha=0.05):\n    correlation, p_value = test_func(data[x], data[y])\n    print(f\"{test_func.__name__}  correlation coefficient: between {x} and {y}: {correlation}, p-value: {p_value}\")\n    if p_value &lt; alpha:\n        print(\"The correlation is significant!\")\n    else:\n        print(\"The correlation is not significant.\")\n\ntest_correlation_with('config/n_neighbors', 'mean_score', dfi, pearsonr)\ntest_correlation_with('config/n_neighbors', 'mean_score', dfi, spearmanr)\n\npearsonr  correlation coefficient: between config/n_neighbors and mean_score: -0.8148057329177487, p-value: 6.1435506488484e-25\nThe correlation is significant!\nspearmanr  correlation coefficient: between config/n_neighbors and mean_score: -0.8085147488740115, p-value: 2.6833127946483235e-24\nThe correlation is significant!\n\n\n\n\n3.13 附加任务: 尝试使⽤不同的策略来构建 KD 树，使得在分类阶段可以有更快的分类效率\n注意我们这里探索要修改的目标是构建 KD 树的过程，也就是要改变KD树的结构，而不是修改KNN分类算法，主要也不是修改KD树的搜索算法。 这里我们的目标是让搜索的效率更高。\n文献@KD-means中总结了KD树构造时的一些常见策略，其中最重要的就是splitting method。分割一个父节点的时候，我们需要决定1. 在哪个数据维度（𝑠𝑑）上进行划分 2. 这个维度上哪个值作为划分点。对于第一点，作者选择范围最广的维度（𝑚𝑎𝑥 − 𝑚𝑖𝑛）来进行划分。\n对于第二点，作者选择了滑动中点分割规则，因为它比其他经典规则提供了更优化的数据组织。这种规则不会产生空节点或数据空间非常稀疏的节点。与选择中位数作为切割值的经典规则不同，滑动中点分割规则选择点的中间值（（最大值𝑚𝑎𝑥 + 最小值𝑚𝑖𝑛）/ 2），这样做成本更低。\n作者还提到KD树的构建过程中可以限制KD树的深度。但是我不太懂如果限制了深度，不是叶子节点的地方在搜索时应该如何处理，退化为暴力吗？\n在我们实现新的算法之前，我们首先测试一下没改进之前的算法的速度。\n\n\n\n5.07 s ± 100 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n现在我们来实现更快的KD树。\n\n# 复用上面的一些定义\nNode, euclidean_distance\n\n(__main__.Node, &lt;function __main__.euclidean_distance(x1, x2)&gt;)\n\n\n\nsource\n\n\n3.14 fast_build_kd_tree\n\n fast_build_kd_tree (X, axis_order_list:list, strategy='median', depth=0)\n\n\nsource\n\n\n3.15 fast_search_kd_tree\n\n fast_search_kd_tree (tree, target, axis_order_list:list, k=3)\n\n\nsource\n\n\n3.16 FastKDTree\n\n FastKDTree (X, split_value_strategy='median',\n             axis_order_strategy='range')\n\nInitialize self. See help(type(self)) for accurate signature.\n我们发现如果是用middle策略，由于数字识别数据集的分布特性，中点能划分的点太少，无法成功建树。\n\n# tree = FastKDTree(X, split_value_strategy=\"median\")\ntree = FastKDTree(X_train, split_value_strategy=\"median\")\n\n[ 0 32 39 31 24 56 16  8 40 47 48 23  1 57 15 55 33 38  7  9 30 25 10  4\n 14 13 12 11  6  5  3  2 28 29 26 27 19 20 21 22 17 18 42 41 36 37 35 34\n 46 45 44 43 51 52 50 49 54 53 58 59 60 61 62 63]\n\n\n\nfor i in range(len(X_train)):\n    k_nearest = tree.search_kd_tree(X_train[0], 1)\n    where = np.where((X_train == k_nearest[0]).all(axis=1))\n    where = where[0]\n    assert len(where) == 1\n\n\n# k_nearest = tree.search_kd_tree(X_test[0], 2)\n# k_nearest = tree.search_kd_tree(X_train[0], 2)\n# k_nearest, X_train[0]\n# k_nearest = tree.search_kd_tree(X_test[0], 2)\n# k_nearest\ny_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)\naccuracy_score(y_test, y_pred) # 确保数值正确\n\n0.9861111111111112\n\n\n\n\n\n5.15 s ± 107 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n我们发现速度变慢了！ 如果使用方差最大策略呢？会不会更好？\n\ntree = FastKDTree(X_train, split_value_strategy=\"median\", axis_order_strategy='variance')\ny_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)\naccuracy_score(y_test, y_pred) # 确保数值正确\n\n[ 0 32 39 56 24 16 31  8 40 48 47 23 15  1 57 55  7 63 49 41 25  9 22  6\n 33 17 38 14 30 11 62  3 46  4 59  2 12 54 60 58 51 52 10 45 50  5 18 19\n 37 29 61 36 27 53 13 28 26 20 21 35 34 44 43 42]\n\n\n0.9861111111111112\n\n\n\n\n\n5.5 s ± 217 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n甚至更慢！为了避免是因为我们实现新的方法有一定的overhead，我们对原本的划分策略也做一次测速。\n\ntree = FastKDTree(X_train, split_value_strategy=\"median\", axis_order_strategy='simple')\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n5.37 s ± 310 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\ny_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)\naccuracy_score(y_test, y_pred) # 确保数值正确\n\n0.9861111111111112\n\n\n根据以上结果，我们初步得出结论，range划分方法比simple方法快，而simple方法比variance方法快。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_KNN",
      "深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#代码与文档格式说明",
    "href": "coding_projects/P1_ANOVA/anova.html#代码与文档格式说明",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "1 代码与文档格式说明",
    "text": "1 代码与文档格式说明\n本文档使用Jupyter Notebook编写，所以同时包括了实验文档和实验代码。\n本次实验项目采用了 Quarto + nbdev 的系统来发布Jupyter Notebook, 因而我们的实验文档导出为pdf和html格式可以进行阅读，而我们的代码也导出为python模块形式，可以作为代码库被其他项目使用。\n我们这样做的好处是，避免单独管理一堆 .py 文件，防止代码冗余和同步混乱，py文件和pdf文件都是从.ipynb文件导出的，可以保证实验文档和代码的一致性。\n\n\n\n\n\n\n重要\n\n\n\n可以通过以下命令安装我们实验的代码：\npip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git\npip install matplotlib seaborn openpyxl scipy statsmodels\n我们的代码导出为了python模块形式，通过以下命令导入：\nfrom thu_big_data_ml.big_data_analytics.anova import *\n\n\n\n\n\n\n\n\n重要\n\n\n\n本文档具有一定的交互性，建议使用浏览器打开html文件，这样比pdf文件阅读体验更佳。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#recall-and-write-down-the-assumptions-which-one-way-anova-are-based-on.",
    "href": "coding_projects/P1_ANOVA/anova.html#recall-and-write-down-the-assumptions-which-one-way-anova-are-based-on.",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "2 1. Recall and write down the assumptions which one-way ANOVA are based on.",
    "text": "2 1. Recall and write down the assumptions which one-way ANOVA are based on.\n我们首先复习一下课件和上课的笔记：\n\n\n\nimage.png\n\n\n可知，one way ANOVA的假设（什么情况下可以进行该分析）是\n\n数据独立采样。\n不同组的方差一样。\n每一个组的数据都是服从正态分布。\n\n课件后面还提到，如果不同组的数据的样本量一样大就更好了，叫做Balanced design\n\n其中有些我们课上还没听懂的疑难问题，列出如下：\n\n假设1的问题\n\n概率论中独立是什么意思来着？\nANOVA到底要求是谁和谁独立？\n\n假设2的问题\n\n经验法则太经验了吧，不能通过假设检验来确定方差是否相等吗？\n老师说的方差不一样时还可以勉强用ANOVA，具体的数据处理方法是什么？\n\n假设3的问题\n\n课上没讲“residuals”是啥？\n为什么老师说第三个假设不重要就算不满足也可以做ANOVA，有什么证据吗？\n\n这三个假设具体在ANOVA后面的分析的哪一步被用到了？",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#state-the-null-h0-and-the-alternative-h1-hypotheses",
    "href": "coding_projects/P1_ANOVA/anova.html#state-the-null-h0-and-the-alternative-h1-hypotheses",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "3 2. State the null (H0) and the alternative (H1) hypotheses",
    "text": "3 2. State the null (H0) and the alternative (H1) hypotheses\n\nFocus on two columns: Category (Col[2]) and Average Age (Col[7]).\nTaking feature Average Age as an example, we want to measure whether the average age varied significantly across the categories. Clearly state the null (H0) and the alternative (H1) hypotheses for this task\n\n依题意，我们需要考察群类型和群员平均年龄的关系，首先假设检验这个关系是否存在。群类型是离散型随机变量，那么有关系就是说不同群类型下的年龄分布有所不同，使用ANOVA的时候，我们就是想说至少他们的均值是不同的。我们认为把实际上年龄分布相同但是被错误认为不同的概率要很小，所以把这个当做一类错误，即错误拒绝零假设的概率。因此，\n\n零假设 H0: The mean Average Age (Col[7])s of all Category (Col[2] groups are equal. 按照不同类型分组的数据中，平均年龄这一列的每组的平均值是相等的。\n\ngroups也称 sub-populations\n\n备择假设 H1: Not all mean Average Age (Col[7])s of all Category (Col[2] groups are equal. 至少存在一个群类型i和群类型j，这两个类型分组的数据的平均年龄是不相等的，从而所有群类型的平均年龄的平均值并非全都相等。\n\n注意这里并不会去说具体谁和谁不一样，需要post-hoc分析才知道。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#use-my-favorite-statistics-analysis-software.",
    "href": "coding_projects/P1_ANOVA/anova.html#use-my-favorite-statistics-analysis-software.",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "4 3. Use my favorite statistics analysis software.",
    "text": "4 3. Use my favorite statistics analysis software.\n\nUse your favorite statistics analysis software, like Matlab, R, Excel, SPSS or …\n\n这里我选择最喜欢的Python，灵活度最高，可编程性强，生态丰富，不过有人说里面的统计库有时候没有R的输出的专业。没关系啦。\n注意到老师课堂上使用了Excel演示，我们有时间的话也稍微掌握一下。Excel的设计其实感觉很棒。\n\n4.1 3.a Draw the empirical probability density function and Test normality\n\nDraw the empirical probability density function of Col[7], i.e. the empirical pdf of average age. Does the data in this dimension follow Gaussian distribution? Test normality of Col[7].\n\n\n4.1.1 文件读取\n首先我们读取Excel文件到Python 的 pandas DataFrame\n\nfrom thu_big_data_ml.help import lib_repo_path\ndata_excel_path = \"data.xlsx\"\ndata_excel_path = lib_repo_path/\"notebooks/coding_projects/P1_ANOVA\"/data_excel_path\n\n\nimport pandas as pd\ndf = pd.read_excel(data_excel_path, sheet_name=\"data\")\ndf.head()\n\n\n\n\n\n\n\n\n群名\n群类别\n群人数\n消息数\n稠密度\n性别比\n平均年龄\n年龄差\n地域集中度\n手机比例\n会话数\n无回应比例\n夜聊比例\n图片比例\n\n\n\n\n0\n**手酒吧\n1\n63\n315\n0.051715\n0.882353\n26.681818\n6.409413\n0.222222\n0.088889\n23\n0.434783\n0.085714\n0.069841\n\n\n1\n**秀嘉园\n1\n73\n2\n0.010274\n0.579710\n27.500000\n9.042524\n0.406780\n0.000000\n2\n1.000000\n1.000000\n0.000000\n\n\n2\n**ˇ⒊無黒\\噵丶⒈群\n1\n73\n4\n0.024163\n0.750000\n23.415385\n4.699893\n0.287879\n0.500000\n4\n1.000000\n0.000000\n0.250000\n\n\n3\n**海网管工作联系基地\n1\n91\n14\n0.006105\n0.901639\n29.409091\n2.854965\n0.340426\n0.142857\n7\n1.000000\n0.250000\n0.000000\n\n\n4\ntbsgame.net/bbs\n1\n133\n2112\n0.011107\n0.961832\n30.319672\n4.669866\n0.110236\n0.167140\n327\n0.532110\n0.104640\n0.037879\n\n\n\n\n\n\n\n\ndf_category_info = pd.read_excel(data_excel_path, sheet_name=\"category_info\")\ndf_category_info.head()\n\n\n\n\n\n\n\n\n编号\n主题\n数量\n\n\n\n\n0\n1\n游戏\n484\n\n\n1\n2\n同学会\n300\n\n\n2\n3\n业主\n196\n\n\n3\n4\n投资理财\n425\n\n\n4\n5\n行业交流\n635\n\n\n\n\n\n\n\n因为是从0开始编号，所以题目说的第七列是\n\ndf.columns, df.columns[7-1]\n\n(Index(['群名', '群类别', '群人数', '消息数', '稠密度', '性别比', '平均年龄', '年龄差', '地域集中度', '手机比例',\n        '会话数', '无回应比例', '夜聊比例', '图片比例'],\n       dtype='object'),\n '平均年龄')\n\n\n\n\n4.1.2 经验pdf绘制\n现在我们可以绘制第七列（平均年龄）的经验概率密度函数图，这个图也叫做 直方图 histogram ，就是多个bin上面去经验地统计频数，从而来近似地描绘出数据分布的概率密度函数。\n\nfrom matplotlib import pyplot as plt\n\n\n# 设置matplotlib支持中文显示\n# 参考网上资料，说要设为 SimHei\n# plt.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体  \nplt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n# 但是SimHei这个linux上不存在，好像是微软的字体，不开源。\n# 参考另一篇博客解决这个问题 https://blog.csdn.net/MAO_TOU/article/details/93998905\nfrom matplotlib import font_manager\nfont = font_manager.FontProperties(fname=\"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\")\nplt.rcParams['font.sans-serif'] = [font.get_name()]\n\n\nplt.figure(figsize=(10, 6))\nimport seaborn as sns\n# plt.hist(df['平均年龄'], bins=10, color='skyblue', edgecolor='black')  # 使用列名绘制直方图\nsns.displot(data=df, x=df.columns[7-1] , kde=True, kind=\"hist\")\nplt.title('平均年龄的经验概率密度图')\nplt.xlabel('平均年龄')\nplt.ylabel('频数')\nplt.grid(axis='y', alpha=0.75)\nplt.show()\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n上面的图不仅画了histogram，还画了kde曲线，kde是kernel density estimation的缩写，是一种非参数统计方法，用来估计概率密度函数。由于不是重点，这里不展开介绍，暂时只需要知道它和histogram类似都能反映分布，但是是连续曲线，所以可解释性较好。\n\n\n4.1.3 正态性检验\n从图中来看，这一列的数据还是比较符合正态分布的。现在我们使用假设检验来验证这一点。 首先我们需要知道有哪些假设检验可以用来检验正态性，各自的优缺点有哪些？\n我们找到两篇较为靠谱的论文 Normality Tests Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests， 里面对各个检验都有介绍，结合其他网络资料，我整理了以下的思维导图：\n\n\n\n\n\ngraph LR\n    A[正态性检验] --&gt; B[Shapiro-Wilk 夏皮罗-威尔克 检验]\n    A --&gt; C[Kolmogorov-Smirnov检验]\n    A --&gt; D[Anderson-Darling 安德森-达令检验]\n    A --&gt; E[D'Agostino-Pearson检验]\n    A --&gt; Z[Lilliefors检验]\n\n    B --&gt; F[零假设: 数据集来自于正态分布]\n    B --&gt; G[使用条件: 小样本, 具体来说n&lt;50]\n    B --&gt; H[优点: 灵敏度高, 被认为是小样本情况下最强大的检验, 计算效率高]\n    B --&gt; I[缺点: 不适用于大样本, 过度敏感, 可能数据稍微偏离就误判不符合正态分布 ] \n\n    C --&gt; J[零假设: 样本来自的总体与指定的理论分布无显著差异]\n    C --&gt; K[使用条件: 适用于连续分布, 大样本]\n    C --&gt; L[优点: 无需分布假设, 可以两列样本直接比较, 不需要指定分布参数]\n    C --&gt; M[缺点: 小样本上不够强大]\n\n    D --&gt; N[零假设: 样本来自的总体与指定的理论分布无显著差异]\n    D --&gt; O[使用条件: 适用于各种样本大小, 特别是当需要重视分布尾部差异时]\n    D --&gt; P[优点: 更重视分布尾部, 某些情况下比KS强大]\n    D --&gt; Q[缺点: 计算复杂, 每一个分布需要计算特定的临界值]\n\n    E --&gt; R[零假设: 数据集来自于正态分布]\n    E --&gt; S[使用条件: 大多数情况都可以]\n    E --&gt; T[优点: 基于偏度和峰度系数]\n    E --&gt; U[缺点: 结果容易受到异常值的影响]\n\n    Z --&gt; V[零假设: 数据集来自于正态分布]\n    Z --&gt; W[使用条件: 适用于小样本数据]\n    Z --&gt; X[优点: 虽然是检验正态性, 但是不用假设是来自于哪一个正态分布, 就是均值方差不用指定, 因为是KS检验的改进版]\n    Z --&gt; Y[缺点: 对于非独立同分布的数据不适用]\n\n\n\n\n\n\n\n根据 https://www.lcgdbzz.org/custom/news/id/7951， 样本量大被认为是大于2000， 而根据https://blog.csdn.net/book_dw5189/article/details/133475648， 样本量&lt;50或者 &lt;200就认为小。 论文 https://www.amu.edu.my/wp-content/uploads/2024/01/V1_1_2023_Proceedings-of-Science-and-Management-2.pdf 中采用了 50 的说法。\n我们的样本量是：\n\nlen(df)\n\n2040\n\n\n不管是上面的哪个说法，都应该认为是大样本量，所以我们应当采用 KS AD 和 DP 检验，而不应该采用SW和L检验。\n\n# 提取第七列数据\n# data_column = df.iloc[:, 7-1]\ndata_column = df[df.columns[7-1]]\n\n\ndata_column\n\n0       26.681818\n1       27.500000\n2       23.415385\n3       29.409091\n4       30.319672\n          ...    \n2035    28.330000\n2036    27.928571\n2037    25.723810\n2038    27.085714\n2039    27.223301\nName: 平均年龄, Length: 2040, dtype: float64\n\n\n首先是KS检验，刚才思维导图我们有个地方说的模糊，其实KS检验有两个，一个是单样本，一个是双样本，单样本就是直接和理论分布比，双样本是两列样本去比。 这里我的疑问是， - 两列样本的样本量可以不一样大吗？ - 答，不需要，双样本测试的时候，不要求两列样本的样本量相同。 - 单样本KS检验是不是通过把理论分布采样出来得到第二个样本列，然后调用双样本KS检验去实现的？还是说另有方法？ - 参考 https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test - KS检验的统计量是两个分布的最大差值，可以是经验分布或者理论分布。 - 如果是经验分布和理论分布去算KS值，是否要采样理论分布呢？ - 这个我暂时无法找到可信答案。\n\nfrom scipy import stats\n\n\n# 进行Kolmogorov-Smirnov检验\n# ks_stat, ks_pvalue = stats.kstest(data_column, 'norm')\n# 另一种写法\nres = stats.ks_1samp(data_column, stats.norm.cdf, alternative='two-sided')\nif res.pvalue &lt; 0.05:\n    print('Reject null hypothesis! Data is not normally distributed.')\nres\n\nReject null hypothesis! Data is not normally distributed.\n\n\nKstestResult(statistic=1.0, pvalue=0.0, statistic_location=13.097826087, statistic_sign=-1)\n\n\n看来KS检验告诉我们这个数据不是高斯分布呀，看来我们人眼看图还是有一定的主观性。 继续进行下一个检验试试。\n\nstats.anderson(data_column, dist='norm')\n\nAndersonResult(statistic=9.382583309670736, critical_values=array([0.575, 0.655, 0.785, 0.916, 1.09 ]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=27.222012543150147, scale=4.986570293065674)\n success: True\n message: '`anderson` successfully fit the distribution to the data.')\n\n\n根据文档 &gt; If the returned statistic is larger than these critical values then for the corresponding significance level, the null hypothesis that the data come from the chosen distribution can be rejected. 这里统计量9.38比 1.09都要大，所以显著度为100%的情况下都可以拒绝原假设，认为数据不来自于选定的分布。\n接下来是 D’Agostino-Pearson检验\n\n# 进行D'Agostino-Pearson检验\nres = stats.normaltest(data_column)\nif res.pvalue &lt; 0.05:\n    print('Reject null hypothesis! Data is not normally distributed.')\nres\n\nReject null hypothesis! Data is not normally distributed.\n\n\nNormaltestResult(statistic=24.479341544296894, pvalue=4.8348001102946654e-06)\n\n\n根据文档 正态分布因为是 zero skewness and zero (“excess” or “Fisher”) kurtosis，所以统计量应该很低， 但是我们得到的很大，所以p值特别小，所以拒绝原假设，认为数据不服从正态分布。\n综合上面的检验，一致地得出结论，也就是col[7]并不服从正态分布。如果三个测试是独立的，那我们的type 1 error就特别低了，是1-0.05^3。不过第一个KS检验直接笃定地告诉我们是0了。\n这里我又产生了一个疑问，假如我们三个假设检验都是在检验一个事情，但是得出的结论又不一样，我应该相信谁呢？我应该怎么集成不同的结果来进行决策呢？这让我联想到课上老师说的ANOVA对应的post-hoc test，有type-1 error inflation 的问题，使用了 Bonferroni correction 进行了调整。 所以我们三个检验也应该搞个holm方法，从小到大排序p值，然后alpha值从小到大检验，防止我们错误地以为不是正态分布？\n除了假设检验外，还可以用过图示法来检验分布的正态性，比如Q-Q plot和P-P plot，由于不是重点，这里就不做过多介绍了。\n\n\n\n4.2 3.b Test the normality of each components and test the homogeneity of variances\n\nIn Col[7], there are 5 components divided by category labels. We denote the data in Col[7] with category i (where i = 1,…,5) as Col[7|categoty=i]. Test the normality of each components and test the homogeneity of variances.\n\n我们首先画图直观感受一下分开之后的分布图\n\nsns.displot(data=df, x=df.columns[7-1], hue=\"群类别\", kde=True, kind=\"hist\")\nplt.ylabel(\"频数\")\n\nText(14.854888888888896, 0.5, '频数')\n\n\n\n\n\n\n\n\n\n从图中来看，数据看起来还是有点正态的，不过我们仍然需要假设检验。 而看起来方差并不是特别一致，特别是第5组图中能感觉方差明显小。\n\n4.2.1 正态性检验\n我们使用 for 循环来对每个变量进行多种正态性检验方法。\n\ninteresting_col = df.columns[7-1]\ngrouped_data = df.groupby('群类别')\n# grouped_data\nnormality_results = {}\nfor name, group in grouped_data:\n    normality_result = {}\n    data_column = group[interesting_col]\n    res = stats.ks_1samp(data_column, stats.norm.cdf, alternative='two-sided')\n    normality_result['Kolmogorov-Smirnov'] = \"Not Normal\" if res.pvalue &lt; 0.05 else \"Normal\"\n    res = stats.anderson(data_column, dist='norm')\n    critical_value = res.critical_values[2] # 0.05 level\n    normality_result['Anderson-Darling'] = \"Not Normal\" if res.statistic &gt; critical_value else \"Normal\"\n    res = stats.normaltest(data_column)\n    normality_result[\"D'Agostino-Pearson\"] = \"Not Normal\" if res.pvalue &lt; 0.05 else \"Normal\"\n    normality_results[name] = normality_result\npd.DataFrame(normality_results)\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n\n\n\n\nKolmogorov-Smirnov\nNot Normal\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nAnderson-Darling\nNot Normal\nNot Normal\nNormal\nNot Normal\nNot Normal\n\n\nD'Agostino-Pearson\nNot Normal\nNormal\nNormal\nNot Normal\nNot Normal\n\n\n\n\n\n\n\n由此可见，Col[7|categoty=2] 和 Col[7|categoty=3] 有可能是正态的，而另外三组都不太符合正态分布。\n\n\n4.2.2 方差齐性检验\n我们首先使用 Rule of thumb 经验法则来看看数据是否满足方差齐性。\n\nstd_devs = grouped_data[interesting_col].std()\nratio_largest_to_smallest = std_devs.max() / std_devs.min() \nvariance_homogeneity = ratio_largest_to_smallest&lt;= 2\nstd_devs, ratio_largest_to_smallest, variance_homogeneity\n\n(群类别\n 1    4.923757\n 2    5.217371\n 3    2.552901\n 4    5.098256\n 5    3.018979\n Name: 平均年龄, dtype: float64,\n 2.0437025537615634,\n False)\n\n\n哎呀看来差一点点，2.04刚好比2大一些，所以拇指法则认为我们做不了ANOVA啦。\n下面我们再探索下假设检验来验证方差齐性，这样更严谨一些。\n\ngroup_values_list = [grouped_data[interesting_col].get_group(x).values for x in grouped_data.groups]\ngroup_values_list[0][:5]\n\narray([26.68181818, 27.5       , 23.41538462, 29.40909091, 30.31967213])\n\n\n\nfrom scipy import stats\n\n\n# 进行Bartlett的方差齐性检验\nbartlett_result = stats.bartlett(*group_values_list)\nif bartlett_result.pvalue &lt; 0.05:\n    print(\"Reject the null hypothesis of equal variances! \")\nbartlett_result\n\nReject the null hypothesis of equal variances! \n\n\nBartlettResult(statistic=276.31560984738496, pvalue=1.387826766589022e-58)\n\n\n可以明显看到pvalue特别低，所以很明显不同组的方差不一样，和拇指法则的结果是一致的。\n\n\n\n4.3 3.c Do the one-way ANOVA test for Col[7] with categories in Col[2].\n\nDo the one-way ANOVA test for Col[7] with categories in Col[2]. Write down your conclusion, supporting statistics, and visualize your data which inspire the process.\n\n我们首先可以画一个箱线图，直观感受一下数据的分布差异\n\n# 绘制分组分布图\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='群类别', y=df.columns[7-1], data=df)\nplt.title('群类别与平均年龄的分布图')\nplt.xlabel('群类别')\nplt.ylabel('平均年龄')\nplt.show()\n\n\n\n\n\n\n\n\n可以感觉到他们的平均值还是有点差距的，现在我们尝试做ANOVA。 不过刚才3.b 我们发现ANOVA的假设并不成立，所以我们得分析结果未必准确。\n\nfrom scipy.stats import f_oneway # ANOVA 又称 F检验，所以scipy命名为f_oneway\n\n\nres = f_oneway(*group_values_list)\nif res.pvalue &lt; 0.05:\n    print(\"Reject null hypothesis! There is a significant difference in the means between the groups.\")\nres\n\nReject null hypothesis! There is a significant difference in the means between the groups.\n\n\nF_onewayResult(statistic=171.50703270711966, pvalue=1.0820916064752822e-126)\n\n\n这里我们已经得到了结果，根据文档，scipy的statistic就是我们课上学习的F统计量，也就是 \\(F = \\frac{between}{within}\\)，这就是我们的Supporting statistic。其中记得between和within不只是方差，还要除以自由度的。\n我们的Conclusion就是不同群类别的平均年龄具有显著差异。\n我们课上学习的时候，ANOVA能得到一个较为详细的表格，包括 SS, df, MS, 不只是上面scipy输出的F和p。所以我们决定使用更加专业的统计库 statsmodels 再来进行一次 ANOVA，参考文档。\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nmodel = ols(f'{df.columns[1]} ~ C({df.columns[7-1]})', data=df).fit()\n\n\nmodel.f_pvalue\n\n0.2481580545669197\n\n\n首先ols是个缩写，全称是 ordinary least squares (OLS), 与之对应的方法是 weighted least squares (WLS), generalized least squares (GLS)。\n其中 C(x) 是 R formula style 语法。 具体来说， - ~：这是一个分隔符，用于区分因变量（响应变量）和自变量（解释变量或预测变量）。 - C(x)函数用于指定x变量应该被视为categorical variable。在R中，分类变量通常用于表示名义尺度或序数尺度的变量，比如性别、种族、国家等。 - 那么具体来说R语言是怎么处理C(x)的呢？在Python sklearn里面我们经常会用one hot编码，R也是使用one hot编码吗？ - 实际上，R语言单独有因子(Factor)类型，不是先处理为one hot再输入ols，而是直接输入ols让ols决定具体怎么处理。 - “Y ~ X1+X2” + 表示 X1 和 X2 都是自变量。 - 可以参考 http://www.sthda.com/english/articles/40-regression-analysis/163-regression-with-categorical-variables-dummy-coding-essentials-in-r/\n\nanova_table = sm.stats.anova_lm(model, test='F', typ=2)\nanova_table\n\n\n\n\n\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(平均年龄)\n4844.373039\n1922.0\n1.103449\n0.248158\n\n\nResidual\n267.250000\n117.0\nNaN\nNaN\n\n\n\n\n\n\n\n为什么使用statsmodels库的时候我们用到了线性回归呢？ 参考这本书第九讲的内容，我们了解到，ANOVA本质上检验线性回归模型的参数是否为零。这篇科普文章也可以参考一下。\n刚才调用的两个库其实都和我们课上学习的有点不一样，为了加深我们的理解，我们自己实现一下ANOVA。 根据课件上的顺序，我们逐一计算 - grand mean - between-group variation - within-group variation\n\nsource\n\n\n4.4 anova_oneway\n\n anova_oneway (*groups:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ngroups\nndarray\n\n\n\nReturns\nDataFrame\n返回ANOVA表格。包括我们课堂上学习的内容。\n\n\n\n\nres = anova_oneway(*group_values_list)\nres\n\n其中我们F为什么叫做F呢？ - 其实是因为 F Value obeys Fisher Distribution， 这个分布是 Fisher大神提出的（ANOVA也是Fisher提出的），Fisher把自己的F命名进去。\n那p为什么叫做p呢？ - p 是 probabilty的缩写，表示事件发生的概率，什么事情呢？ - 如果null hypothesis是正确的，数据出现这件事情的概率。 - 所以p也是如果拒绝 null hypothesis，我们会犯错误的概率，也就是 Type I Error。\n我们再试一下excel表格的ANOVA，看看和我们刚才编写的代码结果一不一样。\n首先默认来说Excel没有开启分析功能。需要 “文件”-&gt;“选项”-&gt;“加载项”，在“管理”下拉菜单中选择“Excel加载项”，然后勾选“分析工具库”和“分析工具库 - VBA”来完成加载。\n第二，Excel的ANOVA对输入格式有要求，必须是分组之后矩阵的形式，我们原本的数据就是两列，所以不对，需要先把数据整理成分组之后的矩阵形式。 - 然而，在尝试了数据透视表、excel公式等方式之后，我放弃了，excel分个组太麻烦了。 - 我觉得直接python导出数据到excel，然后用excel的分析功能来做ANOVA。\n\ngroup_values_df = pd.DataFrame(group_values_list)\ngroup_values_df.to_excel(\"group_values.xlsx\")\ngroup_values_df\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n\n\n\n\n0\n26.681818\n27.500000\n23.415385\n29.409091\n30.319672\n26.112500\n29.738095\n26.313433\n24.415094\n23.933333\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n37.109375\n27.147059\n28.631579\n20.212121\n26.171717\n17.106383\n30.333333\n38.266667\n26.494118\n31.022222\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n27.500000\n30.083551\n32.457746\n35.086420\n31.474576\n28.626866\n30.650206\n34.169811\n30.225000\n33.113924\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n24.254545\n26.245283\n30.533333\n26.333333\n23.964286\n27.645833\n27.718750\n33.693878\n28.571429\n20.219178\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n31.019355\n28.986667\n29.116279\n29.401430\n27.616216\n32.521053\n32.454545\n26.257143\n28.516129\n31.014634\n...\n27.377049\n27.112\n26.623632\n25.816667\n25.668712\n28.33\n27.928571\n25.72381\n27.085714\n27.223301\n\n\n\n\n5 rows × 635 columns\n\n\n\n在弹出的“数据分析”对话框中，选择“方差分析：单一因子（ANOVA：Single Factor）”，然后点击“确定”。 \n结果如下\n\n\n\nimage-2.png\n\n\n我们看到excel计算的结果和我们自己计算的结果一致，除了 p value不同。\n我们的pvalue 是按照课件上的图来的，就是 X~F(df_between, df_within)下 P(X&gt;f_value)，仔细检查还是没发现问题。\n但是确实 excel计算的结果又和 scipy的一样，说明是我们错了而不是他们错了。\n所以我们课件上的计算方法其实后来有改进版本，能得到更加准确的pvalue。\n经过检查，原来excel和scipy采用的p value 是 P(X=f_value), 直接使用了密度函数那个位置的值。\n根据网上问答 这两个方法算p value都是OK的。\n另一个问题是，OLS得到的pvalue和excel、scipy以及我们的结论不一致，OLS似乎认为变化不显著！",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#find-another-three-columns-and-test-whether-they-follow-the-anova-assumptions.",
    "href": "coding_projects/P1_ANOVA/anova.html#find-another-three-columns-and-test-whether-they-follow-the-anova-assumptions.",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "5 4. Find another three columns and test whether they follow the ANOVA assumptions.",
    "text": "5 4. Find another three columns and test whether they follow the ANOVA assumptions.\n\nChoose another 3 columns, draw the empirical pdf of each feature columns and test which column follows these assumptions in question 1? How about their corresponding log transformation?\n\n首先我们需要连续型随机变量，我们看看那些是\n\ncontinuous_vars = df.select_dtypes(include=['float'])\ncontinuous_vars.describe()\n\n\n\n\n\n\n\n\n稠密度\n性别比\n平均年龄\n年龄差\n地域集中度\n手机比例\n无回应比例\n夜聊比例\n图片比例\n\n\n\n\ncount\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n2040.000000\n\n\nmean\n0.075238\n0.653186\n27.222013\n5.274628\n0.552023\n0.261570\n0.705734\n0.145622\n0.032474\n\n\nstd\n0.114423\n0.191333\n4.986570\n2.407647\n0.294685\n0.277207\n0.236187\n0.186805\n0.080868\n\n\nmin\n0.000303\n0.000000\n13.097826\n0.335623\n0.076543\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.010693\n0.542373\n24.035470\n3.774116\n0.250000\n0.019967\n0.523719\n0.011480\n0.000000\n\n\n50%\n0.024804\n0.667256\n27.880909\n5.356491\n0.576114\n0.166667\n0.718730\n0.087869\n0.006719\n\n\n75%\n0.076384\n0.798379\n30.436108\n6.727624\n0.836538\n0.428571\n0.921559\n0.200000\n0.030185\n\n\nmax\n0.609764\n1.000000\n44.243902\n13.841550\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n\n\n\n注意 群人数 消息数 会话数 这几个变量是整数，但是不是类别型随机变量，大小是有意义的，不过我们暂时不考虑它们，也是忽略掉。\n现在我们随机选择三个\n\nimport random\n\n\n# random.seed(5)\nrandom.seed(0)\nchosen_cols = random.choices(continuous_vars.columns, k=3)\nchosen_cols\n\n['夜聊比例', '无回应比例', '年龄差']\n\n\n\n5.1 经验分布\n\nsource\n\n\n5.2 draw_hist\n\n draw_hist (df, chosen_cols, hue_col='群类别', transform=None,\n            column_name_transform=None)\n\n\ndraw_hist(df, chosen_cols, hue_col='群类别')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.3 正态性检验\n我们使用 for 循环来对每个变量进行多种正态性检验方法。 注意ANOVA的正态性是说分组的正态性。 如果每一组都是正态分布，而且零假设不成立，那合在一起其实是Gaussian Mixture Model。\n下面的代码我们引入log=False 参数，决定是对原始数据还是对log数据进行正态性检验。\n\nsource\n\n\n5.4 test_normality_group\n\n test_normality_group (df, interesting_col, hue_col='群类别', transform=None)\n\n\nfor i, col in enumerate(chosen_cols):\n    print(f\"Testing normality for column {col}\")\n    print(test_normality_group(df, col))\n\nTesting normality for column 夜聊比例\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nTesting normality for column 无回应比例\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nTesting normality for column 年龄差\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal      Normal  Not Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal      Normal  Not Normal  Not Normal  Not Normal\n\n\n可以看到除了 年龄差的第二组以外，其他的数据根本不满足正态分布。\n我们再尝试一下log后的正态性检验。\n\nlog_transform = lambda data_column: np.log(data_column+np.min(data_column)+1)  # 保证 大于0 \n# np.log(data_column) \nlog_transform([1,2,3,4,5])\n\narray([1.09861229, 1.38629436, 1.60943791, 1.79175947, 1.94591015])\n\n\n\nfor i, col in enumerate(chosen_cols):\n    print(f\"Testing normality for column log({col})\")\n    print(test_normality_group(df, col, transform=log_transform))\n\nTesting normality for column log(夜聊比例)\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nTesting normality for column log(无回应比例)\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nTesting normality for column log(年龄差)\n                             1           2           3           4           5\nKolmogorov-Smirnov  Not Normal  Not Normal  Not Normal  Not Normal  Not Normal\nAnderson-Darling    Not Normal  Not Normal      Normal  Not Normal  Not Normal\nD'Agostino-Pearson  Not Normal  Not Normal      Normal  Not Normal  Not Normal\n\n\n看来并没有什么特别效果，还是不正态的多，年龄差的第二组反而变得不正态了，第三组正态了。\n\n5.4.1 方差齐性检验\n我们首先使用 Rule of thumb 经验法则 和 bartlett 检验一起来看\n\nsource\n\n\n\n5.5 homogeneity_of_variance\n\n homogeneity_of_variance (df, interesting_col, hue_col='群类别',\n                          transform=None)\n\n\nfor i, chosen_col in enumerate(chosen_cols):\n    print(f\"Now testing variance_homogeneity of column: {chosen_col}\")\n    print(homogeneity_of_variance(df, chosen_col, transform=None))\n    print()\n\nNow testing variance_homogeneity of column: 夜聊比例\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 1.7654023254103777, 'bartlett_result': BartlettResult(statistic=184.4526258346371, pvalue=8.244412669557808e-39)}\n\nNow testing variance_homogeneity of column: 无回应比例\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 1.2996307493612391, 'bartlett_result': BartlettResult(statistic=44.64819549378769, pvalue=4.705138240554607e-09)}\n\nNow testing variance_homogeneity of column: 年龄差\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 1.5888982653697075, 'bartlett_result': BartlettResult(statistic=155.50950582298964, pvalue=1.342198169091211e-32)}\n\n\n\n\nfor i, chosen_col in enumerate(chosen_cols):\n    print(f\"Now testing variance_homogeneity of column: log({chosen_col})\")\n    print(homogeneity_of_variance(df, chosen_col, transform=log_transform))\n    print()\n\nNow testing variance_homogeneity of column: log(夜聊比例)\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 1.6365600965654272, 'bartlett_result': BartlettResult(statistic=139.12782583219428, pvalue=4.338695149250475e-29)}\n\nNow testing variance_homogeneity of column: log(无回应比例)\nThe variances may be homogeneous, according to rule of thumb.\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 1.3586915605576353, 'bartlett_result': BartlettResult(statistic=61.67293119869295, pvalue=1.2906782641394537e-12)}\n\nNow testing variance_homogeneity of column: log(年龄差)\nThe variances are not homogeneous!\nReject the null hypothesis of equal variances! \n{'ratio_largest_to_smallest': 2.282065192732663, 'bartlett_result': BartlettResult(statistic=386.6067271555664, pvalue=2.17718926130104e-82)}\n\n\n\n进行log之后反而年龄差连拇指法则都认为不满足方差齐性了，太可怕了。看来log变换对这三列数据不太有效果。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P1_ANOVA/anova.html#how-to-do-one-way-anova-with-the-non-normal-data",
    "href": "coding_projects/P1_ANOVA/anova.html#how-to-do-one-way-anova-with-the-non-normal-data",
    "title": "深入探索方差分析 (Analysis of Variance, ANOVA)",
    "section": "6 5. How to do one-way ANOVA with the non-normal data?",
    "text": "6 5. How to do one-way ANOVA with the non-normal data?\n\n6.1 5.a Find and list the possible solutions set.\n经过查找网络资料，我们采纳论文4.2.1节的总结方式，当数据不满足服从正态分布时，有三类解决思路，数据转换、非参数检验和广义线性模型。\n\n通过数据转换，把原本数据转换为服从正态分布的数据，比如log变换、Box-Cox变换等，然后我们对转换后的数据进行ANOVA分析。\n\n\n有哪些变换？log变换、Box-Cox变换、平方根转换和反正弦平方根转换等。\n缺点：论文4.2.2节指出，转换可能会改变原始数据的解释，且需要谨慎选择合适的转换方法以确保分析结果的准确性。\n\n\n换一个不需要假设正态分布的、功能类似的检验方法（一般是非参数检验方法），比如Kruskal-Wallis检验。\n\n\n优点：\n\n非参数检验不需要数据服从正态分布，因此在数据不满足正态性假设时仍能提供有效的结果。\n这个不局限于正态假设不满足，其他ANOVA假设不满足也可以用。比如文章指出，如果方差齐性假设不满足，要用Kruskal-Wallis检验。\n机器学习经典的一篇万引论文指出，多个数据集上对比不同的机器学习方法不应当使用ANOVA，因为正态性假设和方差齐性假设不一定成立，所以应当使用Friedman检验。\n\n缺点：非参数检验通常比参数检验具有较低的统计功效，这意味着在相同条件下更容易犯第二类错误（即未能拒绝错误的零假设）\n\n\n上文我们提到，ANOVA和线性回归的参数非零检验是有等价的，而线性回归的误差项被假设为是正态分布，所以才导致ANOVA需要假设正态分布，所以我们可以使用广义线性模型（误差项可以服从泊松分布、二项分布等），然后进行分析。\n\n\n可以参考这本书第十讲\n\n\n\n6.2 5.b Do the one-way ANOVA on the 3 columns you choose. Do these feature columns vary significantly? Visualize the results.\n刚才在 4. 中我们发现，简单使用log变换仍然无法让数据满足正态分布，甚至会破坏方差齐性！我们得尝试使用 5.a中的办法来改进一下！\n\n6.2.1 直接进行 ANOVA 分析\n刚才我们注意到，log变换之前其实数据已经满足拇指法则的要求，方差齐性问题不大；而正态性假设不满足我们勉强接受，开始直接进行 ANOVA 分析。\n调用我们刚才自己编写的 anova_oneway 函数，这里我们实现 auto_anova_for_df 提高API的易用性。\n\nsource\n\n\n\n6.3 auto_anova_for_df\n\n auto_anova_for_df (df, interesting_col, hue_col='群类别', transform=None)\n\n\nres_dfs = []\nfor chosen_col in chosen_cols:\n    # print(f\"Doing ANOVA for {chosen_col}\")\n    # print()\n    res = auto_anova_for_df(df, chosen_col)\n    res_dfs.append(res)\n    \n# index = pd.MultiIndex.from_tuples([(x, y) for x in chosen_cols for y in [\"Between\", \"Within\", \"Total\"]],\n#                             names=['Category', 'Source'])\n# df_combined = pd.DataFrame(index=index, columns=res_dfs[0].columns)\n# for i, source in enumerate(chosen_cols):\n#     # for s in ['Between', 'Within', 'Total']:\n#     #         df_combined.loc[(source, s)] = res_dfs[i].loc[res_dfs[i]['Source'] == s, :]\n#     df_combined.iloc[i] = res_dfs[i].values\n# df_combined\nprint(chosen_cols[0])\nres_dfs[0]\n\n夜聊比例\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares (SS)\nDegrees of Freedom (df)\nMean Square (MS)\nF\np\np_excel\n\n\n\n\n0\nBetween\n3.721528\n4\n0.930382\n28.077748\n1.110223e-16\n1.842338e-22\n\n\n1\nWithin\n67.431602\n2035\n0.033136\nNaN\nNaN\nNaN\n\n\n2\nTotal\n71.153130\n2039\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nprint(chosen_cols[1])\nres_dfs[1]\n\n无回应比例\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares (SS)\nDegrees of Freedom (df)\nMean Square (MS)\nF\np\np_excel\n\n\n\n\n0\nBetween\n6.689130\n4\n1.672283\n31.788299\n1.110223e-16\n1.859627e-25\n\n\n1\nWithin\n107.054963\n2035\n0.052607\nNaN\nNaN\nNaN\n\n\n2\nTotal\n113.744093\n2039\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nprint(chosen_cols[2])\nres_dfs[2]\n\n年龄差\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares (SS)\nDegrees of Freedom (df)\nMean Square (MS)\nF\np\np_excel\n\n\n\n\n0\nBetween\n3338.236332\n4\n834.559083\n200.242216\n1.110223e-16\n9.043259e-145\n\n\n1\nWithin\n8481.367055\n2035\n4.167748\nNaN\nNaN\nNaN\n\n\n2\nTotal\n11819.603387\n2039\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n看来这三个特征还是很明显会被群类别影响的！p值非常小！ 接下来可视化！\n\nsource\n\n\n6.4 draw_box\n\n draw_box (df, chosen_cols, hue_col='群类别', transform=None,\n           column_name_transform=None)\n\n\ndraw_box(df, chosen_cols)\n\n\n\n\n\n\n\n\n\n6.4.1 应用解决办法2——采用不对数据要求那么严格的假设检验方法\n\n6.4.1.1 Friedman检验\n机器学习经典的一篇万引论文指出，多个数据集上对比不同的机器学习方法不应当使用ANOVA，因为正态性假设和方差齐性假设不一定成立，所以应当使用Friedman检验。\n这里我们采用Friedman检验尝试一下，看看是否如这篇论文说的那么适合。\n使用 scipy实现的 friedmanchisquare\n\nsource\n\n\n\n\n6.5 auto_friedman_for_df\n\n auto_friedman_for_df (df, interesting_col, hue_col='群类别', transform=None)\n\n\nres_dfs = []\ntry:\n    for chosen_col in chosen_cols:\n        # print(f\"Doing ANOVA for {chosen_col}\")\n        # print()\n        res = auto_friedman_for_df(df, chosen_col)\n        res_dfs.append(res)\n    print(f\"Friedman for col {chosen_cols[0]}\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\nError: Unequal N in friedmanchisquare.  Aborting.\n\n\n实践出真知，原来 Friedman 测试要求每个treatment有相同的数据量！这确实适合对比机器学习方法，因为这些方法都在N个数据集上做了实验，但是确实不适合我们这里的数据。\n\n6.5.0.1 Kruskal-Wallis\n再来尝试一下 这个\n\nsource\n\n\n\n6.6 auto_kruskal_for_df\n\n auto_kruskal_for_df (df, interesting_col, hue_col='群类别', transform=None)\n\n\nres_dfs = []\nfor chosen_col in chosen_cols:\n    # print(f\"Doing ANOVA for {chosen_col}\")\n    # print()\n    res = auto_kruskal_for_df(df, chosen_col)\n    res_dfs.append(res)\nk = 0\nprint(f\"Kruskal-Wallis for col {chosen_cols[k]}\")\nres_dfs[k]\n\nKruskal-Wallis for col 夜聊比例\n\n\nKruskalResult(statistic=113.85430517053221, pvalue=1.0958066785877727e-23)\n\n\n\nk = 1\nprint(f\"Kruskal-Wallis for col {chosen_cols[k]}\")\nres_dfs[k]\n\nKruskal-Wallis for col 无回应比例\n\n\nKruskalResult(statistic=110.47802046935365, pvalue=5.754933877750579e-23)\n\n\n\nk = 2\nprint(f\"Kruskal-Wallis for col {chosen_cols[k]}\")\nres_dfs[k]\n\nKruskal-Wallis for col 年龄差\n\n\nKruskalResult(statistic=550.9540936771726, pvalue=6.360595079827829e-118)\n\n\nKruskal-Wallis H-test tests的零假设是 不同组的中位数之间没有显著差异。 看来我们对于我们选中的三列，p值都特别小，说明我们可以拒绝零假设，认为这三列都会被“群类型”影响，导致中位数不相同。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P1_ANOVA",
      "深入探索方差分析 (Analysis of Variance, ANOVA)"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/handy_crafted_linear.html",
    "href": "coding_projects/P2_SVM/handy_crafted_linear.html",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——02手动实现SGD优化的软间隔线性SVM",
    "section": "",
    "text": "本文是更高效的支持向量机算法实现及其在手写数字识别中的应用系列文章第02篇——手动实现SGD优化的软间隔线性SVM。\n\ndataset_dict_uci_digits = load_digits(as_frame=False)\nX_train, X_val, X_test, y_train, y_val, y_test, train_set, val_set, test_set, data_module, categories = process_sklearn_dataset_dict(dataset_dict_uci_digits, 'all')\ndataset_dict_full_mnist = fetch_openml(\"mnist_784\", as_frame=True)\nX_train_full, X_val_full, X_test_full, y_train_full, y_val_full, y_test_full, train_set_full, val_set_full, test_set_full, data_module_full, categories_full = process_sklearn_dataset_dict(dataset_dict_full_mnist, 'all')\n\n(1797, 64) float32 (1797,) int64 [0 1 2 3 4 5 6 7 8 9]\n1293 144 360\n(70000, 784) float32 (70000,) int64 [0 1 2 3 4 5 6 7 8 9]\n50400 5600 14000\n\n\n\n0.1 实现 Hinge Loss+SGD 版本的 Soft Margin Linear SVM\n我们现在来实现与from sklearn.linear_model import SGDClassifier等价的 SVM，但是我们基于PyTorch实现，在GPU上面运行，期望能在大型数据集上比sklearn的实现快。\n\n0.1.1 Hinge Loss 二分类实现\n首先回顾二分类情况下，李航《统计学习方法》131页的优化目标：\n\\[\n\\min_{w, b} \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) \\right]_+ + \\lambda \\lVert w \\rVert^2\n\\]\n李航随即给出了证明，证明这个无约束最优化问题等价于优化软间隔线性支持向量机的原始问题。我感觉上面的式子有点丑，莫名其妙地引入了没有物理意义的超参数\\(\\lambda\\), 让读者无法与软间隔问题中的\\(C\\)联系起来。所以我们使用李航证明中用来说明这两个问题等效性的式子:\n\\[\n\\min_{w, b}  \\frac{1}{2} \\lVert w \\rVert^2 + C \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) \\right]_+\n\\]\n其中 $i = + $ 是松弛变量，\\([]_+\\) 自动地让松弛变量满足了约束。\n我们现在就可以用 PyTorch 实现这个 二分类情况下的 Hinge Loss了。\n注意，在下面的代码中我们不会去实现\\(\\frac{1}{2} \\lVert w \\rVert^2\\)!\n因为在实际PyTorch项目中，这个是写在 Optimizer的 weight decay里面的。 1/2 其实和 C 、学习率等 只是相对比例关系。\n这是因为 PyTorch 的设计哲学中，loss 函数的输入就是 logits 和 labels，不会包括模型的参数，这样才能把逻辑解耦开来。\n所以如果我们在loss就实现 l2 regularization，是很麻烦而且没有必要的。\nOptimizer 有权限访问到 model 的参数，所以我们待会可以精确控制，只对 weight 而非 bias 做 l2 regularization，从而满足 SVM 的要求。\n\nsource\n\n\n\n0.2 BinaryHingeLoss\n\n BinaryHingeLoss (C=1.0, squared=False, margin=1.0)\n\nBinary Hinge Loss. For SVM, \\[\n\\min_{w, b}  \frac{1}{2} \\lVert w Vert^2 + C \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) ight]_+\n\\] we compute \\[\nC \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) ight]_+\n\\]\n\n\nExported source\nimport torch\nimport torch.nn as nn\nfrom fastcore.all import store_attr\n\n\n\n\nExported source\nclass BinaryHingeLoss(nn.Module):\n    \"\"\"\n    Binary Hinge Loss. \n    For SVM, \n    $$\n    \\min_{w, b}  \\frac{1}{2} \\lVert w \\rVert^2 + C \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) \\right]_+\n    $$\n    we compute \n    $$\n    C \\sum_{i=1}^N \\left[ 1 - y_i(w \\cdot x_i + b) \\right]_+\n    $$\n    \"\"\"\n    def __init__(self, C=1.0, \n                 squared = False, \n                 margin = 1.0,\n                 ):\n        super().__init__()\n        store_attr() # 保存参数到实例变量中\n\n    def forward(self, y_pred_logits:torch.Tensor, y_true:torch.Tensor)-&gt;torch.Tensor:\n        functional_margin = y_true * y_pred_logits # 函数间隔\n        how_small_than_required_margin = self.margin - functional_margin\n        xi = torch.clamp(how_small_than_required_margin, min=0) # 计算 xi 也就是 松弛变量\n        if self.squared:\n            xi = xi ** 2\n        return self.C * xi.sum()\n\n\n其中 squared 参数表示是否使用 squared hinge loss。 什么叫做 squared hinge loss 呢？我们做过理论作业，李航《统计学习方法》153页例题 7.3 提到了 (但是书上没有给出Reference) \\[\n\\min_{w, b}  \\frac{1}{2} \\lVert w \\rVert^2 + C \\sum_{i=1}^N \\xi_i^2\n\\] 来取代 \\[\n\\min_{w, b}  \\frac{1}{2} \\lVert w \\rVert^2 + C \\sum_{i=1}^N \\xi_i\n\\] 其实上面那个式子就是 squared hinge loss。\n\nfrom fastcore.test import test_eq\n\n\n# 尝试一下\ncritierion = BinaryHingeLoss(margin=1, C=1, squared=False)\ny_pred_logits = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\ny_true = torch.tensor([1.0, -1.0, 1.0])\ntest_eq(critierion(y_pred_logits, y_true).item(), 1-(-1.0)*2.0) # 第二个样本分类错误，函数间隔为 -2， 差了 3\n\n\n0.2.1 Hinge Loss 多分类实现\n现在我们已经成功实现 BinaryHingeLoss， 接下来我们要考虑 多分类情况下 要如何变化。\n参考\n\nhttps://lightning.ai/docs/torchmetrics/stable/classification/hinge_loss.html\nhttps://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html\n\n按照我们上文 理论回顾 一节说的，有两类方法。首先是直接法，具体来说 Crammer and Singer在论文中 提出， 对于每一个样本$x_i, y_i, t_i $ (y_i 是 one hot vector, t_i 是 标签，假如是第k类也就是$t_i = k \\(，\\)y_i^{t_i} = 1, y_i^{k!=t_i} = 0\\(), 使用这一个公式来作为 多分类的 Hinge Loss\\)$ L_i = _+ $$ 其中 \\(\\hat{y_i}^k = (w^k \\cdot x_i + b^k)\\) 是针对第k个类的那一个SVM(\\(w^k, b^k\\)表示)预测出来的值，不是函数间隔哦，没有乘\\(y_i^k\\)。\n而间接法则是使用 one vs all(a.k.a., rest) 来计算 hinge loss。（one vs one 比较少见）\n具体而言，首先 $t_i = k \\(，\\)y_i^{t_i} = 1, y_i^{k!=t_i} = -1$, \\(\\hat{y_i}^k = (w^k \\cdot x_i + b^k)\\) 表示 是否为 第k个类。 对于每一个样本i，对于每一个样本k都能计算出一个binary loss：\n\\[L_i^k = \\left[ 1 - y_i^k (w^k \\cdot x_i + b^k) \\right]_+ \\]\n相当于同时在训练K个分类器，所以这些loss都可以加在一起，反向传播训练对于\\(w^k, b^k\\)独立操作。\n所以推导一下，如果每一个 \\(1 - y_i^k (w^k \\cdot x_i + b^k)\\) 都 \\(\\gt 0\\) 就相当于\n\\[L_i = \\sum_{k=1}^{K} L_i^k \\approx \\left[ K - (\\hat{y_i}^{t_i} - \\sum_{k \\neq t_i} \\hat{y_i}^k)) \\right]_+ \\]\n但是并不是都&gt;0的，没法这样进去推导，所以还是得老老实实相加。\n理论清晰之后，现在我们开始实现代码：\n\nsource\n\n\n\n0.3 MultiClassHingeLoss\n\n MultiClassHingeLoss (C=1.0, squared=False, margin=1.0,\n                      strategy:Literal['crammer_singer','one_vs_all']='cra\n                      mmer_singer')\n\nMultiClassHingeLoss\n\n\nExported source\nfrom fastcore.all import patch\nfrom typing import Literal\n\n\n\n\nExported source\nStrategy = Literal['crammer_singer', 'one_vs_all']\nclass MultiClassHingeLoss(nn.Module):\n    \"\"\"MultiClassHingeLoss\"\"\"\n    def __init__(self, C=1.0, \n                 squared = False, \n                 margin = 1.0,\n                 strategy: Strategy = 'crammer_singer',\n                #  *args, **kwargs\n                 ):\n        super().__init__()\n        store_attr()\n        self.binary_critieria = None\n    def forward(self, y_pred_logits:torch.Tensor, \n                y_true:torch.Tensor # 并非 one hot 编码，而是 int/long 类型 的 label\n                )-&gt;torch.Tensor:\n        if self.strategy == 'crammer_singer':\n            return self.forward_crammer_singer(y_pred_logits, y_true)\n        elif self.strategy == 'one_vs_all':\n            return self.forward_one_vs_all(y_pred_logits, y_true)\n        else:\n            raise ValueError(f\"Invalid strategy: {self.strategy}\")\n    def forward_one_vs_all(self, y_pred_logits:torch.Tensor, y_true:torch.Tensor)-&gt;torch.Tensor:\n        num_of_classes = y_pred_logits.size(1)\n        if self.binary_critieria is None:\n            self.binary_critieria = nn.ModuleList([\n                BinaryHingeLoss(C=self.C, squared=self.squared, margin=self.margin)\n                for _ in range(num_of_classes)\n                ])\n        losses = []\n        for k, critierion in enumerate(self.binary_critieria):\n            y_true_binary = 2 * (y_true == k) - 1 # 转换为 -1/1 编码、\n            y_pred_that_class = y_pred_logits[:, k]\n            loss = critierion(y_pred_that_class, y_true_binary)\n            losses.append(loss)\n        return sum(losses)\n    def forward_crammer_singer(self, y_pred_logits:torch.Tensor, y_true:torch.Tensor)-&gt;torch.Tensor: ...\n\n\n\nsource\n\n\n0.4 get_max_values_without_true\n\n get_max_values_without_true (y_pred_logits, y_true)\n\n*获取去掉y_true对应元素后，y_pred_logits每行的最大值。\n参数: y_pred_logits: torch.Tensor, 形状为 (N, K) y_true: torch.Tensor, 形状为 (N,)\n返回: torch.Tensor, 形状为 (N,), 去掉y_true对应元素后每行的最大值*\n\n\nExported source\nimport torch\n\n\n\n\nExported source\ndef get_max_values_without_true(y_pred_logits, y_true):\n    \"\"\"\n    获取去掉y_true对应元素后，y_pred_logits每行的最大值。\n\n    参数:\n    y_pred_logits: torch.Tensor, 形状为 (N, K)\n    y_true: torch.Tensor, 形状为 (N,)\n\n    返回:\n    torch.Tensor, 形状为 (N,), 去掉y_true对应元素后每行的最大值\n    \"\"\"\n    # 将y_true转换为适当的索引格式\n    indices = y_true.unsqueeze(1).expand_as(y_pred_logits)\n\n    # 创建一个与y_pred_logits形状相同的掩码，真实标签位置为False，其余为True\n    mask = torch.ones_like(y_pred_logits, dtype=torch.bool)\n    mask.scatter_(1, indices, False)\n\n    # 使用掩码来排除y_true对应的列，并计算每一行的最大值\n    max_values = y_pred_logits[mask].view(y_pred_logits.size(0), -1).max(dim=1)[0]\n\n    return max_values\n\n\n我们调用已经实现的BinaryHingeLoss来实现forward_one_vs_all。\n为了方便实现 forward_crammer_singer 方法，首先我们实现一个辅助函数，\n注意 PyTorch中的索引有广播机制，我们刚才编程的时候遇到这个问题，实现了一阵才正确实现逻辑。\n下面的代码是说明这个问题的最小重现单元，它的运行结果可能超出你的预期，所以编程的时候我们刚才特别注意了这一点。\n\n# \ny_pred = torch.ones(2, 10)\ny_true = torch.zeros(2).to(int)\ny_pred[:, y_true] # 很多人以为会是 [1, 1], 实际输出 [[1., 1.], [1., 1.]]\n\ntensor([[1., 1.],\n        [1., 1.]])\n\n\n测试一下函数正确性\n\ny_pred_logits = torch.tensor([[1, 2, 3, 4, 5],\n                             [6, 7, 8, 9, 10],\n                             [11, 12, 13, 14, 15],\n                             [16, 17, 18, 19, 20]], dtype=torch.float)\ny_true = torch.tensor([4, 4, 4, 4])\n\n# 函数调用\nmax_values = get_max_values_without_true(y_pred_logits, y_true)\nmax_values\n\ntensor([ 4.,  9., 14., 19.])\n\n\n正确。 现在我们继续实现 MultiClassHingeLoss.forward_crammer_singer, fastcore 提供 patch 扩展了 Python 的能力，可以支持 Mixin 风格的软件编程。\n\nsource\n\n\n0.5 MultiClassHingeLoss.forward_crammer_singer\n\n MultiClassHingeLoss.forward_crammer_singer (y_pred_logits:torch.Tensor,\n                                             y_true:torch.Tensor)\n\n*L_i = _+*\n\n\nExported source\n@patch\ndef forward_crammer_singer(self:MultiClassHingeLoss, y_pred_logits:torch.Tensor, y_true:torch.Tensor)-&gt;torch.Tensor:\n    \"\"\"L_i = \\left[ 1 - (\\hat{y_i}^{t_i} - \\max_{k \\neq t_i} \\hat{y_i}^k)) \\right]_+\"\"\"\n    batch_size, num_classes = y_pred_logits.size()\n    y_true_one_hot = torch.eye(num_classes).to(y_pred_logits.device)[y_true]\n    \n    # 计算真实类别的预测值\n    y_true_logits = (y_pred_logits * y_true_one_hot).sum(dim=1)\n    # y_true_logits = y_pred_logits[:, y_true]\n\n    max_other_logits = get_max_values_without_true(y_pred_logits, y_true)\n    \n    functional_margin_differences = (y_true_logits - max_other_logits)\n    \n    # 计算hinge loss\n    xi = torch.clamp(self.margin - functional_margin_differences, min=0)\n    \n    if self.squared:\n        xi = xi ** 2\n    return self.C * xi.sum()\n\n\n现在我们简单测试一下上面实现的两个Loss是否计算正确，与理论公式一样。\n\ny_pred_logits = torch.tensor([[0.5, -0.5], [-0.5, 0.5]])\ny_true = torch.tensor([0, 1])\ncritierion = MultiClassHingeLoss(strategy=\"crammer_singer\")\nloss = critierion(y_pred_logits, y_true)\nloss\n\ntensor(0.)\n\n\n上面的结果是正确的，因为 自己这个类别的 预测值 是 0.5, 其他类别的最大预测值是 -0.5, 比它大1, 正好是margin，所以loss为0\n\ncritierion = MultiClassHingeLoss(strategy=\"one_vs_all\")\nloss = critierion(y_pred_logits, y_true)\nloss\n\ntensor(2.)\n\n\n上面的结果也是正确的，这两个数据都是 正确的那个类 自己只有0.5的值，不到1， 而错误的类不到-1，所以有正负类两个样本各有0.5的loss，一共为2。\n以上我们实现的Loss在真实情况中会使用哪个组合呢？这也是个值得探讨的问题。\n对于多类别的情况，论文 详细研究了 crammer_singer 方法 + squared hinge loss 的有效性，所以这两者是可以结合的。\n\n0.5.1 SVM 模型与优化算法实现\n在 crammer_singer 方法 和 one vs all 的情况下，SVM的参数\\(w, b\\)的大小是 (n_features, n_classes), (n_classes,)，这与多分类的感知机、Linear+Softmax是一样的。\n\nsource\n\n\n\n0.6 HingeSupportVectorClassifier\n\n HingeSupportVectorClassifier (input_dim, num_classes, learning_rate=0.01,\n                               weight_decay=0.5, optimizer_type=&lt;class\n                               'torch.optim.sgd.SGD'&gt;, C:float=1,\n                               squared:bool=False, margin:float=1, strateg\n                               y:Literal['crammer_singer','one_vs_all']='c\n                               rammer_singer', experiment_index=0)\n\nHooks to be used in LightningModule.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_dim\n\n\n\n\n\nnum_classes\n\n\nmodel related\n\n\nlearning_rate\nfloat\n0.01\n\n\n\nweight_decay\nfloat\n0.5\noptimization related\n\n\noptimizer_type\ntype\nSGD\n\n\n\nC\nfloat\n1\nloss related\n\n\nsquared\nbool\nFalse\n\n\n\nmargin\nfloat\n1\n\n\n\nstrategy\nLiteral\ncrammer_singer\n\n\n\nexperiment_index\nint\n0\nexperiment related\n\n\n\n\n\nExported source\nfrom overrides import override\nfrom lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS, STEP_OUTPUT, OptimizerLRScheduler\nimport torch.optim as optim\n# lightning imports\nimport lightning as L\n\n\n\n\nExported source\nclass HingeSupportVectorClassifier(L.LightningModule):\n    def __init__(self, \n                #  model related\n                 input_dim, num_classes,  \n                #  optimization related\n                 learning_rate=0.01, weight_decay=0.5, \n                 optimizer_type = optim.SGD, \n                #  loss related\n                 C: float = 1,\n                    squared: bool = False,\n                    margin: float = 1,\n                    strategy: Strategy = 'crammer_singer',\n                #  experiment related\n                 experiment_index=0,  \n                 ):\n        super().__init__()\n        self.save_hyperparameters()\n        L.seed_everything(experiment_index)\n        self.model = nn.Linear(input_dim, num_classes)\n        self.loss_fn = MultiClassHingeLoss()\n        \n        self.example_input_array = torch.randn(1, input_dim)\n        self.dummy_inputs = dict(input_ids=self.example_input_array) # for opendelta and huggingface\n        self.automatic_optimization = True\n        # 评价策略\n        self.evaluation_steps_outputs = dict()\n        \n    @override\n    def forward(self, image_tensor:torch.Tensor, *args, **kwargs)-&gt; torch.Tensor:\n        \"\"\"\n        Returns:\n            torch.Tensor: the predicted functional margin to each class's decision hyperplane   \n        \"\"\"\n        return self.model(image_tensor)\n    \n    def predict_geometric_margin(self, image_tensor:torch.Tensor)-&gt;torch.Tensor:\n        w_norm_each_line = torch.norm(self.model.weight, dim=1)\n        return torch.clamp(self(image_tensor) / w_norm_each_line, min=0)\n    \n    def predict_class(self, image_tensor:torch.Tensor)-&gt;torch.Tensor:\n        return torch.argmax(self(image_tensor), dim=1)\n\n    def forward_loss(self, image_tensor: torch.Tensor, label_tensor:torch.Tensor)-&gt;torch.Tensor:\n        logits = self(image_tensor)\n        return self.loss_fn(logits, label_tensor)\n        \n    @override\n    def training_step(self, batch, batch_idx=None, *args, **kwargs)-&gt; STEP_OUTPUT:\n        loss = self.forward_loss(*batch)\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n\n\nfrom namable_classify.infra import print_model_pretty\n\n\ntest_model = HingeSupportVectorClassifier(28*28, 10)\ntest_model.print_model_pretty()\ny_pred_logits =test_model(test_model.example_input_array)\ntest_model.predict_class(test_model.example_input_array)\ntest_model.predict_geometric_margin(test_model.example_input_array)\n# y_pred_logits\n# test_model.loss_fn(y_pred_logits, torch.tensor([0]))\ntest_model.forward_loss(test_model.example_input_array, torch.tensor([0]))\n\nSeed set to 0\n\n\nMon 2024-11-18 20:38:01.629617\n\n\n\nINFO     ╭─────────────────────── Model Tree for HingeSupportVectorClassifier ────────────────────────╮ torch.py:72\n         │ root                                                                                       │            \n         │ └── model (Linear) weight:[10, 784] bias:[10]                                              │            \n         ╰────────────────────────────────────────────────────────────────────────────────────────────╯            \n\n\n\n\n\n\n\ntensor(1.4472, grad_fn=&lt;MulBackward0&gt;)\n\n\n\n我们定义好了 loss 和 model（w与b的参数，以及决策超平面如何用于决策）。 现在我们要定义训练算法。\n首先我们来首先一下 上文我们提到的sklearn使用的 Leon Bottou optimal learning rate。从现代深度学习的角度来看，Leon Bottou 本质上是提出了一个 learning rate scheduler。\n参照 Leon Bottou 的SVM网站, 他对学习率的规划如下\nSGD\n\\[\n\\eta_t = \\frac{\\eta_0}{(1 + \\lambda \\eta_0 t)}\n\\]\nASGD\n\\[\n\\eta_t = \\frac{\\eta_0}{(1 + \\lambda \\eta_0 t)^{0.75}}\n\\]\n其中对于第一个形式，是否是一个特殊的[指数/gamma 衰减的学习率]？(https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html)。 \\[\n{\\eta}_{t+1} = \\frac{\\eta_0}{(1 + \\lambda \\eta_0 (t+1) )}\n\\]\n\\[\n\\gamma = \\frac{{\\eta}_{t+1}}{\\eta_t} = \\frac{1}{1+\\frac{1}{t + \\frac{1}{\\lambda \\eta_0}}}\n\\] 答案是否定的，因为 \\(\\gamma\\) 推导出来不是和t无关的常数。 所以Leon Bottou不是 gamma衰减的特殊情况。\n\n\nExported source\nscheduler_lmd_leon_bottou_sgd = lambda epoch, init_lr=0.1, lmd=0.001: init_lr / (1+ lmd*init_lr*epoch)\nscheduler_lmd_leon_bottou_asgd = lambda epoch, init_lr=0.1, lmd=0.001: init_lr / (1+ lmd*init_lr*epoch)**0.75\n\n\n不要忘了刚才还有 \\(\\frac{1}{2} ||w||^2\\) 项， 需要特别注意 bias \\(b\\) 没有被decay。博客提到，尽管很多论文都指出了分开这两者的weight decay的重要性，但是在torch中实现这一点还是有一定的难度的。\n\nsource\n\n\n0.7 separate_weight_decay\n\n separate_weight_decay (model:torch.nn.modules.module.Module,\n                        weight_decay:float, otherwise_set_to:float=0.0,\n                        verbose:bool=False)\n\n\n\nExported source\ndef separate_weight_decay(model:nn.Module, weight_decay: float, otherwise_set_to:float=0.0, verbose:bool=False):\n    decay = list() # 不能使用 set，由于Pytorch优化器需要顺序\n    no_decay = list()\n    for name, param in model.named_parameters():\n        do_weight_decay = 'weight' in name\n        if verbose:\n            print(f'{name} should do weight decay? {do_weight_decay}')\n        if do_weight_decay:\n            decay.append(param)\n        else:\n            no_decay.append(param)\n    # return decay, no_decay\n    return [\n                dict(params=decay, weight_decay=weight_decay), \n                dict(params=no_decay, weight_decay=otherwise_set_to)\n            ]\n\n\n\ntest_model = HingeSupportVectorClassifier(10, 10)\nweight_decay = 0.001\nseparate_weight_decay(test_model, weight_decay)\npass\n\nSeed set to 0\n\n\n\nsource\n\n\n0.8 HingeSupportVectorClassifier.configure_optimizers\n\n HingeSupportVectorClassifier.configure_optimizers ()\n\n*Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you’d need one. But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in the manual optimization mode.\nReturn: Any of these 6 options.\n- **Single optimizer**.\n- **List or Tuple** of optimizers.\n- **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\n  (or multiple ``lr_scheduler_config``).\n- **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\n  key whose value is a single LR scheduler or ``lr_scheduler_config``.\n- **None** - Fit will run without any optimizer.\nThe lr_scheduler_config is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below.\n.. code-block:: python\nlr_scheduler_config = {\n    # REQUIRED: The scheduler instance\n    \"scheduler\": lr_scheduler,\n    # The unit of the scheduler's step size, could also be 'step'.\n    # 'epoch' updates the scheduler on epoch end whereas 'step'\n    # updates it after a optimizer update.\n    \"interval\": \"epoch\",\n    # How many epochs/steps should pass between calls to\n    # `scheduler.step()`. 1 corresponds to updating the learning\n    # rate after every epoch/step.\n    \"frequency\": 1,\n    # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n    \"monitor\": \"val_loss\",\n    # If set to `True`, will enforce that the value specified 'monitor'\n    # is available when the scheduler is updated, thus stopping\n    # training if not found. If set to `False`, it will only produce a warning\n    \"strict\": True,\n    # If using the `LearningRateMonitor` callback to monitor the\n    # learning rate progress, this keyword can be used to specify\n    # a custom logged name\n    \"name\": None,\n}\nWhen there are schedulers in which the .step() method is conditioned on a value, such as the :class:torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the lr_scheduler_config contains the keyword \"monitor\" set to the metric name that the scheduler should be conditioned on.\n.. testcode::\n# The ReduceLROnPlateau scheduler requires a monitor\ndef configure_optimizers(self):\n    optimizer = Adam(...)\n    return {\n        \"optimizer\": optimizer,\n        \"lr_scheduler\": {\n            \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n            \"monitor\": \"metric_to_track\",\n            \"frequency\": \"indicates how often the metric is updated\",\n            # If \"monitor\" references validation metrics, then \"frequency\" should be set to a\n            # multiple of \"trainer.check_val_every_n_epoch\".\n        },\n    }\n\n# In the case of two optimizers, only one using the ReduceLROnPlateau scheduler\ndef configure_optimizers(self):\n    optimizer1 = Adam(...)\n    optimizer2 = SGD(...)\n    scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n    scheduler2 = LambdaLR(optimizer2, ...)\n    return (\n        {\n            \"optimizer\": optimizer1,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler1,\n                \"monitor\": \"metric_to_track\",\n            },\n        },\n        {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n    )\nMetrics can be made available to monitor by simply logging it using self.log('metric_to_track', metric_val) in your :class:~lightning.pytorch.core.LightningModule.\nNote: Some things to know:\n- Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\n- If a learning rate scheduler is specified in ``configure_optimizers()`` with key\n  ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\n  the scheduler's ``.step()`` method automatically in case of automatic optimization.\n- If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\n- If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\n- If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\n  yourself.\n- If you need to control how often the optimizer steps, override the :meth:`optimizer_step` hook.*\n\n\nExported source\n@override    \n@patch\ndef configure_optimizers(self:HingeSupportVectorClassifier) -&gt; OptimizerLRScheduler:\n    init_lr = self.hparams.learning_rate\n    # lmd = self.hparams.weight_decay / self.hparams.C \n    lmd = self.hparams.weight_decay # 需要考证，Leon Bottou的lamda 是什么情况下推导的。\n\n    weight_decay = self.hparams.weight_decay\n    \n    if self.hparams.optimizer_type == torch.optim.ASGD:\n        optimizer = torch.optim.ASGD(\n            # self.parameters(), \n            separate_weight_decay(self, weight_decay), \n                                    lr=init_lr,  # 刚才 save_hyperparameters() 保存了，这是为了方便是使用 Lightning 调学习率\n                                    # weight_decay = self.hparams.weight_decay, # 李航书上的 hinge loss的第一项\n                                    ) \n        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,\n                lr_lambda=lambda epoch: scheduler_lmd_leon_bottou_asgd(epoch, init_lr, lmd))\n    elif self.hparams.optimizer_type == torch.optim.SGD:\n        optimizer = torch.optim.SGD(\n            # self.parameters(), \n            separate_weight_decay(self, weight_decay), \n                                    lr=init_lr,\n                                    # weight_decay=self.hparams.weight_decay\n                                    )\n        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,\n                lr_lambda=lambda epoch: scheduler_lmd_leon_bottou_sgd(epoch, init_lr, lmd))\n    else:\n        return self.hparams.optimizer_type(self.parameters(), lr=init_lr, weight_decay=self.hparams.weight_decay) # 只 return optimizer\n        \n    return ([optimizer], [scheduler])\n\n\n最后我们补上评价指标\n\nsource\n\n\n0.9 HingeSupportVectorClassifier.test_step\n\n HingeSupportVectorClassifier.test_step (batch, batch_idx=None, *args,\n                                         **kwargs)\n\n*Operates on a single batch of data from the test set. In this step you’d normally generate examples or calculate anything of interest such as accuracy.\nArgs: batch: The output of your data iterable, normally a :class:~torch.utils.data.DataLoader. batch_idx: The index of this batch. dataloader_idx: The index of the dataloader that produced this batch. (only if multiple dataloaders used)\nReturn: - :class:~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss'. - None - Skip to the next batch.\n.. code-block:: python\n# if you have one test dataloader:\ndef test_step(self, batch, batch_idx): ...\n\n# if you have multiple test dataloaders:\ndef test_step(self, batch, batch_idx, dataloader_idx=0): ...\nExamples::\n# CASE 1: A single test dataset\ndef test_step(self, batch, batch_idx):\n    x, y = batch\n\n    # implement your own\n    out = self(x)\n    loss = self.loss(out, y)\n\n    # log 6 example images\n    # or generated text... or whatever\n    sample_imgs = x[:6]\n    grid = torchvision.utils.make_grid(sample_imgs)\n    self.logger.experiment.add_image('example_images', grid, 0)\n\n    # calculate acc\n    labels_hat = torch.argmax(out, dim=1)\n    test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n\n    # log the outputs!\n    self.log_dict({'test_loss': loss, 'test_acc': test_acc})\nIf you pass in multiple test dataloaders, :meth:test_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\n.. code-block:: python\n# CASE 2: multiple test dataloaders\ndef test_step(self, batch, batch_idx, dataloader_idx=0):\n    # dataloader_idx tells you which dataset this is.\n    ...\nNote: If you don’t need to test you don’t need to implement this method.\nNote: When the :meth:test_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of the test epoch, the model goes back to training mode and gradients are enabled.*\n\n\nExported source\nfrom namable_classify.infra import append_dict_list, ensure_array\nfrom typing import Any\nimport numpy as np\n\n\n\n\nExported source\n@patch\ndef on_evaluation_epoch_start(self:HingeSupportVectorClassifier, stage:str=\"\"):\n    self.evaluation_steps_outputs = dict()\n    self.evaluation_steps_outputs[f'{stage}_batch_probs'] = []\n    self.evaluation_steps_outputs[f'{stage}_label_tensor'] = []\n    # self.evaluation_steps_outputs[f'{stage}_batch_preds'] = []\n        \n@patch\ndef evaluation_step(self:HingeSupportVectorClassifier, batch, batch_idx=None, stage:str=\"\", *args: Any, **kwargs: Any) -&gt; STEP_OUTPUT:\n    image_tensor, label_tensor = batch\n    batch_probs = self(image_tensor)\n    # batch_preds = self.predict_class(image_tensor)\n    append_dict_list(self.evaluation_steps_outputs, f'{stage}_batch_probs', ensure_array(batch_probs))\n    append_dict_list(self.evaluation_steps_outputs, f'{stage}_label_tensor', ensure_array(label_tensor))\n    # append_dict_list(self.evaluation_steps_outputs, f'{stage}_batch_preds', ensure_array(batch_preds))\n    batch_loss = self.loss_fn(batch_probs, label_tensor)\n    self.log(f\"{stage}_loss\", batch_loss, prog_bar=True)\n    return batch_loss\n        \n@patch\ndef on_evaluation_epoch_end(self:HingeSupportVectorClassifier, stage:str=\"\"):\n    # https://github.com/Lightning-AI/pytorch-lightning/discussions/9845\n    # labels = self.lit_data.classes\n    # labels = list(range(self.lit_data.num_of_classes))\n    labels = list(range(self.hparams.num_classes))\n    # labels = None\n    # print(labels)\n    # stack 是 new axis， concat是existing axis\n    all_pred_probs = np.concatenate(self.evaluation_steps_outputs[f'{stage}_batch_probs'])\n    all_label_tensor = np.concatenate(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n    # all_preds = np.concatenate(self.evaluation_steps_outputs[f'{stage}_batch_preds'])\n    # logger.debug(self.evaluation_steps_outputs[f'{stage}_label_tensor'])\n    # logger.debug(all_label_tensor)\n    eval_dict = compute_classification_metrics(all_label_tensor, all_pred_probs, \n                                            #    logits_to_prob=False, \n                                                logits_to_prob=True, \n                                            labels=labels)\n    eval_dict = {f\"{stage}_{k}\": v for k,v in eval_dict.items()}\n    self.log_dict(eval_dict)\n    self.evaluation_steps_outputs.clear()\n\n@override\n@patch\ndef on_validation_epoch_start(self:HingeSupportVectorClassifier):\n    return self.on_evaluation_epoch_start(stage=\"val\")\n\n@override\n@patch\ndef on_test_epoch_start(self:HingeSupportVectorClassifier):\n    return self.on_evaluation_epoch_start(stage=\"test\")\n\n@override\n@patch\ndef on_validation_epoch_end(self:HingeSupportVectorClassifier):\n    return self.on_evaluation_epoch_end(stage=\"val\")\n\n@override\n@patch\ndef on_test_epoch_end(self:HingeSupportVectorClassifier):\n    return self.on_evaluation_epoch_end(stage=\"test\")\n\n@override\n@patch\ndef validation_step(self:HingeSupportVectorClassifier, batch, batch_idx=None, *args, **kwargs):\n    return self.evaluation_step(batch, batch_idx, stage=\"val\")\n\n@override\n@patch\ndef test_step(self:HingeSupportVectorClassifier, batch, batch_idx=None, *args, **kwargs):\n    return self.evaluation_step(batch, batch_idx, stage=\"test\")\n\n\n\nsource\n\n\n0.10 HingeSupportVectorClassifier.validation_step\n\n HingeSupportVectorClassifier.validation_step (batch, batch_idx=None,\n                                               *args, **kwargs)\n\n*Operates on a single batch of data from the validation set. In this step you’d might generate examples or calculate anything of interest like accuracy.\nArgs: batch: The output of your data iterable, normally a :class:~torch.utils.data.DataLoader. batch_idx: The index of this batch. dataloader_idx: The index of the dataloader that produced this batch. (only if multiple dataloaders used)\nReturn: - :class:~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss'. - None - Skip to the next batch.\n.. code-block:: python\n# if you have one val dataloader:\ndef validation_step(self, batch, batch_idx): ...\n\n# if you have multiple val dataloaders:\ndef validation_step(self, batch, batch_idx, dataloader_idx=0): ...\nExamples::\n# CASE 1: A single validation dataset\ndef validation_step(self, batch, batch_idx):\n    x, y = batch\n\n    # implement your own\n    out = self(x)\n    loss = self.loss(out, y)\n\n    # log 6 example images\n    # or generated text... or whatever\n    sample_imgs = x[:6]\n    grid = torchvision.utils.make_grid(sample_imgs)\n    self.logger.experiment.add_image('example_images', grid, 0)\n\n    # calculate acc\n    labels_hat = torch.argmax(out, dim=1)\n    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n\n    # log the outputs!\n    self.log_dict({'val_loss': loss, 'val_acc': val_acc})\nIf you pass in multiple val dataloaders, :meth:validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\n.. code-block:: python\n# CASE 2: multiple validation dataloaders\ndef validation_step(self, batch, batch_idx, dataloader_idx=0):\n    # dataloader_idx tells you which dataset this is.\n    ...\nNote: If you don’t need to validate you don’t need to implement this method.\nNote: When the :meth:validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.*\n\nsource\n\n\n0.11 HingeSupportVectorClassifier.on_test_epoch_end\n\n HingeSupportVectorClassifier.on_test_epoch_end ()\n\nCalled in the test loop at the very end of the epoch.\n\nsource\n\n\n0.12 HingeSupportVectorClassifier.on_validation_epoch_end\n\n HingeSupportVectorClassifier.on_validation_epoch_end ()\n\nCalled in the validation loop at the very end of the epoch.\n\nsource\n\n\n0.13 HingeSupportVectorClassifier.on_test_epoch_start\n\n HingeSupportVectorClassifier.on_test_epoch_start ()\n\nCalled in the test loop at the very beginning of the epoch.\n\nsource\n\n\n0.14 HingeSupportVectorClassifier.on_validation_epoch_start\n\n HingeSupportVectorClassifier.on_validation_epoch_start ()\n\nCalled in the validation loop at the very beginning of the epoch.\n\nsource\n\n\n0.15 HingeSupportVectorClassifier.on_evaluation_epoch_end\n\n HingeSupportVectorClassifier.on_evaluation_epoch_end (stage:str='')\n\n\nsource\n\n\n0.16 HingeSupportVectorClassifier.evaluation_step\n\n HingeSupportVectorClassifier.evaluation_step (batch, batch_idx=None,\n                                               stage:str='', *args:Any,\n                                               **kwargs:Any)\n\n\nsource\n\n\n0.17 HingeSupportVectorClassifier.on_evaluation_epoch_start\n\n HingeSupportVectorClassifier.on_evaluation_epoch_start (stage:str='')\n\n\ninput_dim = X_val.shape[1]\nnum_of_classes = len(categories)\ninput_dim, num_of_classes\n\n\n\n\n\n(64, 10)\n\n\n\n\nget_cls_task = lambda: HingeSupportVectorClassifier(input_dim, num_of_classes, \n                                        learning_rate=1,\n                                        weight_decay=0.5, \n                                        optimizer_type=torch.optim.ASGD, C=1, squared=True, margin=1, \n                                        strategy=\"crammer_singer\", experiment_index=0)\ncls_task = get_cls_task()\ncls_data = data_module\n# cls_data = data_module_full\n\nSeed set to 0\n\n\n\n0.17.1 SVM 训练与评价\n\nfrom thu_big_data_ml.help import runs_path\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom lightning.pytorch.callbacks import ModelSummary, LearningRateMonitor, LearningRateFinder, BatchSizeFinder\n\n\ntrainer = L.Trainer(default_root_dir=runs_path, \n                    enable_checkpointing=True, \n                    enable_model_summary=True, \n                    # num_sanity_val_steps=2, # 防止 val 在训了好久train才发现崩溃\n                    callbacks=[\n                        EarlyStopping(monitor=\"val_acc1\", mode=\"max\", check_finite=True, \n                                      patience=5, \n                                      check_on_train_epoch_end=False,  # check on validation end\n                                      verbose=True),\n                        ModelSummary(max_depth=3),\n                        # LearningRateFinder(), \n                        # BatchSizeFinder(), \n                        LearningRateMonitor(logging_interval=\"epoch\")\n                               ]\n                    # , fast_dev_run=True\n                    # , limit_train_batches=10, \n                    # limit_val_batches=5\n                    , accelerator=\"gpu\", devices=1, strategy=\"auto\"\n                    )\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\nTrainer already configured with model summary callbacks: [&lt;class 'lightning.pytorch.callbacks.model_summary.ModelSummary'&gt;]. Skipping setting a default `ModelSummary` callback.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n\n\ntrainer.fit(cls_task, datamodule=cls_data)\nval_res = trainer.validate(cls_task, datamodule=cls_data)\ntest_res = trainer.test(cls_task, datamodule=cls_data)\npass\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:58:49.020341\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\nINFO: \n  | Name    | Type                | Params | Mode  | In sizes | Out sizes\n-------------------------------------------------------------------------------\n0 | model   | Linear              | 650    | train | [1, 64]  | [1, 10]  \n1 | loss_fn | MultiClassHingeLoss | 0      | train | ?        | ?        \n-------------------------------------------------------------------------------\n650       Trainable params\n0         Non-trainable params\n650       Total params\n0.003     Total estimated model params size (MB)\n2         Modules in train mode\n0         Modules in eval mode\n\n\nSat 2024-11-16 00:58:49.057947\n\n\n\nINFO                                                                                           model_summary.py:104\n           | Name    | Type                | Params | Mode  | In sizes | Out sizes                                 \n         -------------------------------------------------------------------------------                           \n         0 | model   | Linear              | 650    | train | [1, 64]  | [1, 10]                                   \n         1 | loss_fn | MultiClassHingeLoss | 0      | train | ?        | ?                                         \n         -------------------------------------------------------------------------------                           \n         650       Trainable params                                                                                \n         0         Non-trainable params                                                                            \n         650       Total params                                                                                    \n         0.003     Total estimated model params size (MB)                                                          \n         2         Modules in train mode                                                                           \n         0         Modules in eval mode                                                                            \n\n\n\n\n\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n\n\n\n\n\n\n\n\nINFO: Metric val_acc1 improved. New best score: 0.514\n\n\nSat 2024-11-16 00:58:52.534348\n\n\n\nINFO     Metric val_acc1 improved. New best score: 0.514                                      early_stopping.py:273\n\n\n\n\n\n\nINFO: Metric val_acc1 improved by 0.229 &gt;= min_delta = 0.0. New best score: 0.743\n\n\nSat 2024-11-16 00:58:55.733727\n\n\n\nINFO     Metric val_acc1 improved by 0.229 &gt;= min_delta = 0.0. New best score: 0.743          early_stopping.py:273\n\n\n\n\n\n\n\n\n\nINFO: Metric val_acc1 improved by 0.007 &gt;= min_delta = 0.0. New best score: 0.750\n\n\nSat 2024-11-16 00:59:01.783794\n\n\n\nINFO     Metric val_acc1 improved by 0.007 &gt;= min_delta = 0.0. New best score: 0.750          early_stopping.py:273\n\n\n\n\n\n\n\n\n\n\n\n\nINFO: Metric val_acc1 improved by 0.111 &gt;= min_delta = 0.0. New best score: 0.861\n\n\nSat 2024-11-16 00:59:09.920693\n\n\n\nINFO     Metric val_acc1 improved by 0.111 &gt;= min_delta = 0.0. New best score: 0.861          early_stopping.py:273\n\n\n\n\n\n\n\n\n\nINFO: Metric val_acc1 improved by 0.042 &gt;= min_delta = 0.0. New best score: 0.903\n\n\nSat 2024-11-16 00:59:14.194501\n\n\n\nINFO     Metric val_acc1 improved by 0.042 &gt;= min_delta = 0.0. New best score: 0.903          early_stopping.py:273\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nINFO: Monitored metric val_acc1 did not improve in the last 5 records. Best score: 0.903. Signaling Trainer to stop.\n\n\nSat 2024-11-16 00:59:26.505406\n\n\n\nINFO     Monitored metric val_acc1 did not improve in the last 5 records. Best score: 0.903.  early_stopping.py:273\n         Signaling Trainer to stop.                                                                                \n\n\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:59:27.127571\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         val_acc1          │    0.8541666865348816     │\n│         val_acc10         │            1.0            │\n│         val_acc2          │    0.9513888955116272     │\n│         val_acc20         │            1.0            │\n│         val_acc3          │    0.9652777910232544     │\n│         val_acc5          │    0.9791666865348816     │\n│   val_balanced_accuracy   │    0.8519047498703003     │\n│      val_cohen_kappa      │    0.8378465175628662     │\n│          val_f1           │    0.8545861840248108     │\n│      val_hinge_loss       │    0.29842936992645264    │\n│       val_log_loss        │    0.9072062373161316     │\n│         val_loss          │     263.0315856933594     │\n│   val_matthews_corrcoef   │    0.8427900671958923     │\n│       val_precision       │    0.8835164904594421     │\n│        val_recall         │    0.8519047498703003     │\n│        val_roc_auc        │    0.9750232100486755     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:59:28.313136\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         test_acc1         │     0.855555534362793     │\n│        test_acc10         │            1.0            │\n│         test_acc2         │    0.9027777910232544     │\n│        test_acc20         │            1.0            │\n│         test_acc3         │    0.9444444179534912     │\n│         test_acc5         │    0.9694444537162781     │\n│  test_balanced_accuracy   │    0.8538845777511597     │\n│     test_cohen_kappa      │    0.8394717574119568     │\n│          test_f1          │    0.8514753580093384     │\n│      test_hinge_loss      │    0.30003729462623596    │\n│       test_log_loss       │     1.314468264579773     │\n│         test_loss         │     328.9302062988281     │\n│  test_matthews_corrcoef   │    0.8407779932022095     │\n│      test_precision       │    0.8590342998504639     │\n│        test_recall        │    0.8538845777511597     │\n│       test_roc_auc        │    0.9722300171852112     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n\n\n\n0.18 对手动实现的SVM进行调参\n要想进行调参，我们需要首先思考一下，实际上有哪些元参数是必要的。\n首先optimizer_type选择ASGD还是SGD，squared是hinge loss还是squared hinge loss，strategy使用crammer_singer还是one vs all, 这三个参数的选择自然是会影响到最终的结果，是重要的目标元参数或者冗余元参数。然而，剩下的learning_rate,weight_decay和C, margin我们可以发现，本质上只有前两个。C和learning_rate是一样的效果，而margin是一个函数间隔，也是可以任意选取的，不影响优化问题的最优解（当然会一定程度影响landscape）。\n因此，对于软间隔的Linear SVM的原始问题，我们只需要在给定优化器、损失函数、多分类策略的情况下，只需要调整现代深度学习中也很重要的learning_rate,weight_decay参数。\n我在上次Project作业KD树中详细描述了谷歌AI团队《深度学习调优指南》的思想，涉及到的概念包括目标元参数、冗余元参数和固定元参数，贝叶斯优化、演化计算、近似随机搜索，科学实验的控制变量法与调参实验设计中的探索与利用、调参结果的假设检验分析等。这里我们不再赘述，需要的话可以阅读上次作业的文档。\n与上次作业不同，今天我们调的参数（学习率）具有一定的特殊性，因为我们今天的模型是个可以SGD优化的模型，所以我们可以用到深度学习论文中提出的一些调参方法来进行调参。具体而言，我们今天学习的是这篇经典论文Cyclical Learning Rates for Training Neural Networks 的调参方法，具体的实现已经集成到 lightning 库中，我们可以直接使用。\n\nfrom lightning.pytorch.tuner import Tuner\n\n\ncls_task = get_cls_task()\ntuner_trainer = L.Trainer()\ntuner = Tuner(tuner_trainer)\nlr_finder = tuner.lr_find(cls_task, datamodule=cls_data, max_lr=10, min_lr=1e-6, num_training=100, mode = \"exponential\")\n# print(lr_finder.results)\nfig = lr_finder.plot(suggest=True)\nfig.show()\nnew_lr = lr_finder.suggestion()\nnew_lr, cls_task.hparams.learning_rate\n\nINFO: Seed set to 0\n\n\nSat 2024-11-16 00:52:49.912254\n\n\n\nINFO     Seed set to 0                                                                                   seed.py:57\n\n\n\nINFO: Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n\n\nSat 2024-11-16 00:52:49.928983\n\n\n\nINFO     Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook   rank_zero.py:63\n         environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside                \n         interactive / notebook environments is considered experimental and unstable. Your mileage                 \n         may vary.                                                                                                 \n\n\n\nINFO: GPU available: True (cuda), used: True\n\n\nSat 2024-11-16 00:52:49.953772\n\n\n\nINFO     GPU available: True (cuda), used: True                                                     rank_zero.py:63\n\n\n\nINFO: TPU available: False, using: 0 TPU cores\n\n\nSat 2024-11-16 00:52:49.958918\n\n\n\nINFO     TPU available: False, using: 0 TPU cores                                                   rank_zero.py:63\n\n\n\nINFO: HPU available: False, using: 0 HPUs\n\n\nSat 2024-11-16 00:52:49.962648\n\n\n\nINFO     HPU available: False, using: 0 HPUs                                                        rank_zero.py:63\n\n\n\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:52:49.972189\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\nINFO: LR finder stopped early after 85 steps due to diverging loss.\n\n\nSat 2024-11-16 00:53:03.916698\n\n\n\nINFO     LR finder stopped early after 85 steps due to diverging loss.                             lr_finder.py:282\n\n\n\nINFO: Learning rate set to 3.467368504525316e-05\n\n\nSat 2024-11-16 00:53:03.941939\n\n\n\nINFO     Learning rate set to 3.467368504525316e-05                                                lr_finder.py:301\n\n\n\nINFO: Restoring states from the checkpoint path at /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/coding_projects/P2_SVM/.lr_find_eeb25b7b-6568-46de-b7da-ccdf5af0b22b.ckpt\n\n\nSat 2024-11-16 00:53:03.946531\n\n\n\nINFO     Restoring states from the checkpoint path at                                               rank_zero.py:63\n         /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/                \n         coding_projects/P2_SVM/.lr_find_eeb25b7b-6568-46de-b7da-ccdf5af0b22b.ckpt                                 \n\n\n\nINFO: Restored all states from the checkpoint at /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/coding_projects/P2_SVM/.lr_find_eeb25b7b-6568-46de-b7da-ccdf5af0b22b.ckpt\n\n\nSat 2024-11-16 00:53:03.962106\n\n\n\nINFO     Restored all states from the checkpoint at                                                 rank_zero.py:63\n         /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/                \n         coding_projects/P2_SVM/.lr_find_eeb25b7b-6568-46de-b7da-ccdf5af0b22b.ckpt                                 \n\n\n\n\n\n\n\n(3.467368504525316e-05, 3.467368504525316e-05)\n\n\n\n\n\n\n\n\n\n\n\n\n\n这个方法我认为也可以用于调整weight decay。\n\ncls_task = get_cls_task()\ncls_task.hparams.learning_rate = new_lr\ntuner_trainer = L.Trainer()\ntuner = Tuner(tuner_trainer)\nweight_decay_finder = tuner.lr_find(cls_task, datamodule=cls_data, max_lr=1e-3, min_lr=1e-5, num_training=50, attr_name='weight_decay')\n\nINFO: Seed set to 0\n\n\nSat 2024-11-16 00:54:03.777345\n\n\n\nINFO     Seed set to 0                                                                                   seed.py:57\n\n\n\nINFO: Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n\n\nSat 2024-11-16 00:54:03.800328\n\n\n\nINFO     Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook   rank_zero.py:63\n         environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside                \n         interactive / notebook environments is considered experimental and unstable. Your mileage                 \n         may vary.                                                                                                 \n\n\n\nINFO: GPU available: True (cuda), used: True\n\n\nSat 2024-11-16 00:54:03.836096\n\n\n\nINFO     GPU available: True (cuda), used: True                                                     rank_zero.py:63\n\n\n\nINFO: TPU available: False, using: 0 TPU cores\n\n\nSat 2024-11-16 00:54:03.852469\n\n\n\nINFO     TPU available: False, using: 0 TPU cores                                                   rank_zero.py:63\n\n\n\nINFO: HPU available: False, using: 0 HPUs\n\n\nSat 2024-11-16 00:54:03.868754\n\n\n\nINFO     HPU available: False, using: 0 HPUs                                                        rank_zero.py:63\n\n\n\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:54:03.892937\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\nINFO: `Trainer.fit` stopped: `max_steps=50` reached.\n\n\nSat 2024-11-16 00:54:11.843827\n\n\n\nINFO     `Trainer.fit` stopped: `max_steps=50` reached.                                             rank_zero.py:63\n\n\n\nINFO: Learning rate set to 7.585775750291839e-05\n\n\nSat 2024-11-16 00:54:11.865877\n\n\n\nINFO     Learning rate set to 7.585775750291839e-05                                                lr_finder.py:301\n\n\n\nINFO: Restoring states from the checkpoint path at /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/coding_projects/P2_SVM/.lr_find_c0a44246-c85b-407a-8dae-440075c5ae1a.ckpt\n\n\nSat 2024-11-16 00:54:11.877609\n\n\n\nINFO     Restoring states from the checkpoint path at                                               rank_zero.py:63\n         /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/                \n         coding_projects/P2_SVM/.lr_find_c0a44246-c85b-407a-8dae-440075c5ae1a.ckpt                                 \n\n\n\nINFO: Restored all states from the checkpoint at /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/coding_projects/P2_SVM/.lr_find_c0a44246-c85b-407a-8dae-440075c5ae1a.ckpt\n\n\nSat 2024-11-16 00:54:11.900391\n\n\n\nINFO     Restored all states from the checkpoint at                                                 rank_zero.py:63\n         /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/notebooks/                \n         coding_projects/P2_SVM/.lr_find_c0a44246-c85b-407a-8dae-440075c5ae1a.ckpt                                 \n\n\n\n\nfig = weight_decay_finder.plot(suggest=True)\nfig.show()\nnew_weight_decay = weight_decay_finder.suggestion()\nnew_weight_decay, cls_task.hparams.weight_decay\n\n\n\n\n\n(7.585775750291839e-05, 7.585775750291839e-05)\n\n\n\n\n\n\n\n\n\n\n\n\n\n由于代码限制，第二张图中显示的learning rate其实是weight decay。\n现在我们对调整后的参数进行重新训练\n\ncls_task = get_cls_task()\ncls_task.hparams.learning_rate = new_lr\ncls_task.hparams.weight_decay = new_weight_decay\n\nINFO: Seed set to 0\n\n\nSat 2024-11-16 00:54:57.243884\n\n\n\nINFO     Seed set to 0                                                                                   seed.py:57\n\n\n\n\ntrainer.fit(cls_task, datamodule=cls_data)\nval_res_tuned = trainer.validate(cls_task, datamodule=cls_data)\ntest_res_tuned = trainer.test(cls_task, datamodule=cls_data)\npass\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/runs/lightning_logs/version_16/checkpoints exists and is not empty.\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:58:01.204967\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\nINFO: \n  | Name    | Type                | Params | Mode  | In sizes | Out sizes\n-------------------------------------------------------------------------------\n0 | model   | Linear              | 650    | train | [1, 64]  | [1, 10]  \n1 | loss_fn | MultiClassHingeLoss | 0      | train | ?        | ?        \n-------------------------------------------------------------------------------\n650       Trainable params\n0         Non-trainable params\n650       Total params\n0.003     Total estimated model params size (MB)\n2         Modules in train mode\n0         Modules in eval mode\n\n\nSat 2024-11-16 00:58:01.224387\n\n\n\nINFO                                                                                           model_summary.py:104\n           | Name    | Type                | Params | Mode  | In sizes | Out sizes                                 \n         -------------------------------------------------------------------------------                           \n         0 | model   | Linear              | 650    | train | [1, 64]  | [1, 10]                                   \n         1 | loss_fn | MultiClassHingeLoss | 0      | train | ?        | ?                                         \n         -------------------------------------------------------------------------------                           \n         650       Trainable params                                                                                \n         0         Non-trainable params                                                                            \n         650       Total params                                                                                    \n         0.003     Total estimated model params size (MB)                                                          \n         2         Modules in train mode                                                                           \n         0         Modules in eval mode                                                                            \n\n\n\n\n\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:58:03.645924\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         val_acc1          │    0.1319444477558136     │\n│         val_acc10         │            1.0            │\n│         val_acc2          │    0.2361111044883728     │\n│         val_acc20         │            1.0            │\n│         val_acc3          │    0.3541666567325592     │\n│         val_acc5          │    0.5347222089767456     │\n│   val_balanced_accuracy   │    0.13571429252624512    │\n│      val_cohen_kappa      │    0.03511122986674309    │\n│          val_f1           │    0.1358683854341507     │\n│      val_hinge_loss       │    1.1006195545196533     │\n│       val_log_loss        │    2.3971312046051025     │\n│         val_loss          │    204.75518798828125     │\n│   val_matthews_corrcoef   │    0.03540673106908798    │\n│       val_precision       │    0.13904762268066406    │\n│        val_recall         │    0.13571429252624512    │\n│        val_roc_auc        │     0.544339656829834     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n/home/ye_canming/program_files/managers/conda/envs/yuequ/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ye_canming/program_files/managers/conda/envs/y ...\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n\n\nSat 2024-11-16 00:58:04.947243\n\n\n\nINFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]                                         cuda.py:61\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         test_acc1         │    0.11666666716337204    │\n│        test_acc10         │            1.0            │\n│         test_acc2         │    0.25555557012557983    │\n│        test_acc20         │            1.0            │\n│         test_acc3         │    0.3444444537162781     │\n│         test_acc5         │    0.5166666507720947     │\n│  test_balanced_accuracy   │    0.11671385914087296    │\n│     test_cohen_kappa      │   0.018240757286548615    │\n│          test_f1          │    0.1174597293138504     │\n│      test_hinge_loss      │    1.1020585298538208     │\n│       test_log_loss       │     2.420191526412964     │\n│         test_loss         │     219.2089385986328     │\n│  test_matthews_corrcoef   │   0.018393170088529587    │\n│      test_precision       │    0.12187045812606812    │\n│        test_recall        │    0.11671385914087296    │\n│       test_roc_auc        │    0.5245167016983032     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n\nval_res = val_res[0]\ntest_res = test_res[0]\nval_res_tuned = val_res_tuned[0]\ntest_res_tuned = test_res_tuned[0]\n\n\nresults = []\nfor key in val_res.keys():\n    delta = val_res_tuned[key] - val_res[key]\n    is_better = delta&gt;0 \n    if 'loss' in key:\n        is_better = not is_better\n    results.append(dict(metric=key, value=val_res[key], tuned_value=val_res_tuned[key], delta=delta, is_better=is_better))\nfor key in test_res.keys():\n    delta = test_res_tuned[key] - test_res[key]\n    is_better = delta&gt;0 \n    if 'loss' in key:\n        is_better = not is_better\n    results.append(dict(metric=key, value=test_res[key], tuned_value=test_res_tuned[key], delta=delta, is_better=is_better))\n\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\n\n\n\nmetric\nvalue\ntuned_value\ndelta\nis_better\n\n\n\n\n0\nval_loss\n263.031586\n204.755188\n-58.276398\nTrue\n\n\n1\nval_acc1\n0.854167\n0.131944\n-0.722222\nFalse\n\n\n2\nval_acc2\n0.951389\n0.236111\n-0.715278\nFalse\n\n\n3\nval_acc3\n0.965278\n0.354167\n-0.611111\nFalse\n\n\n4\nval_acc5\n0.979167\n0.534722\n-0.444444\nFalse\n\n\n5\nval_acc10\n1.000000\n1.000000\n0.000000\nFalse\n\n\n6\nval_acc20\n1.000000\n1.000000\n0.000000\nFalse\n\n\n7\nval_matthews_corrcoef\n0.842790\n0.035407\n-0.807383\nFalse\n\n\n8\nval_f1\n0.854586\n0.135868\n-0.718718\nFalse\n\n\n9\nval_precision\n0.883516\n0.139048\n-0.744469\nFalse\n\n\n10\nval_recall\n0.851905\n0.135714\n-0.716190\nFalse\n\n\n11\nval_balanced_accuracy\n0.851905\n0.135714\n-0.716190\nFalse\n\n\n12\nval_cohen_kappa\n0.837847\n0.035111\n-0.802735\nFalse\n\n\n13\nval_roc_auc\n0.975023\n0.544340\n-0.430684\nFalse\n\n\n14\nval_hinge_loss\n0.298429\n1.100620\n0.802190\nFalse\n\n\n15\nval_log_loss\n0.907206\n2.397131\n1.489925\nFalse\n\n\n16\ntest_loss\n328.930206\n219.208939\n-109.721268\nTrue\n\n\n17\ntest_acc1\n0.855556\n0.116667\n-0.738889\nFalse\n\n\n18\ntest_acc2\n0.902778\n0.255556\n-0.647222\nFalse\n\n\n19\ntest_acc3\n0.944444\n0.344444\n-0.600000\nFalse\n\n\n20\ntest_acc5\n0.969444\n0.516667\n-0.452778\nFalse\n\n\n21\ntest_acc10\n1.000000\n1.000000\n0.000000\nFalse\n\n\n22\ntest_acc20\n1.000000\n1.000000\n0.000000\nFalse\n\n\n23\ntest_matthews_corrcoef\n0.840778\n0.018393\n-0.822385\nFalse\n\n\n24\ntest_f1\n0.851475\n0.117460\n-0.734016\nFalse\n\n\n25\ntest_precision\n0.859034\n0.121870\n-0.737164\nFalse\n\n\n26\ntest_recall\n0.853885\n0.116714\n-0.737171\nFalse\n\n\n27\ntest_balanced_accuracy\n0.853885\n0.116714\n-0.737171\nFalse\n\n\n28\ntest_cohen_kappa\n0.839472\n0.018241\n-0.821231\nFalse\n\n\n29\ntest_roc_auc\n0.972230\n0.524517\n-0.447713\nFalse\n\n\n30\ntest_hinge_loss\n0.300037\n1.102059\n0.802021\nFalse\n\n\n31\ntest_log_loss\n1.314468\n2.420192\n1.105723\nFalse\n\n\n\n\n\n\n\n我们发现其实 test_loss 与 val_loss 其实我们调参之后的模型确实变小了，说明了调参的有效性。\n但是其他所有指标，包括sklearn里面的hinge_loss (one vs all, 不是 crammer_singer，并且有对样本平均) 都变差了。这说明 crammer_singer 方法，或者”sum”而非”mean“的损失函数，是带有一定局限性的。\n\n\n0.19 附加题: 对比不同 kernel 方法下的 SVM 分类器 （对完整SVM进行调参）\n现在我们手动实现了线性SVM，接下来我们对比不同 kernel 方法下的 SVM 分类器。\n接下来的内容请见文件 03svm_kernel_hpo。\n本次Project的目录请见绪论 00svm。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——02手动实现SGD优化的软间隔线性SVM"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/use_lib.html",
    "href": "coding_projects/P2_SVM/use_lib.html",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别",
    "section": "",
    "text": "本文是更高效的支持向量机算法实现及其在手写数字识别中的应用系列文章第01篇——调库实现SVM手写数字识别。\n上文我们已经了解了数据的加载与预处理，并且理解了理论上的一些问题。\ndataset_dict_uci_digits = load_digits(as_frame=False)\nX_train, X_val, X_test, y_train, y_val, y_test, train_set, val_set, test_set, data_module, categories = process_sklearn_dataset_dict(dataset_dict_uci_digits, 'all')\ndataset_dict_full_mnist = fetch_openml(\"mnist_784\", as_frame=True)\nX_train_full, X_val_full, X_test_full, y_train_full, y_val_full, y_test_full, train_set_full, val_set_full, test_set_full, data_module_full, categories_full = process_sklearn_dataset_dict(dataset_dict_full_mnist, 'all')\n\n(1797, 64) float32 (1797,) int64 [0 1 2 3 4 5 6 7 8 9]\n1293 144 360\n(70000, 784) float32 (70000,) int64 [0 1 2 3 4 5 6 7 8 9]\n50400 5600 14000",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/use_lib.html#实验内容",
    "href": "coding_projects/P2_SVM/use_lib.html#实验内容",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别",
    "section": "1 实验内容",
    "text": "1 实验内容\n\n1.1 调库实现SVM\n为了给我们后面的实验一个参照，我们调用现有代码库的SVM，关注其精度与速度的情况。 当然如果我们Project在此收尾，只能酌情被扣除分数。 在本节之后，我们将使用 PyTorch 和 numpy 这样的基础科学计算库，来在GPU和CPU上实现SVM及其优化。\n\n\n\n\n\n\n重要\n\n\n\n本次Project首先展示了几个常用的SVM库的精度与速度，并且对其进行调参；随后本次Project基于基础科学计算库手写实现了SVM及其优化，和前面的库的精度与速度进行了对比。\n\n\n\n1.1.1 sklearn实现的 SMO 形式的 RBF kernel SVM\n\nfrom sklearn.svm import SVC\n\n\nsvc = SVC(kernel='rbf', probability=True)\nsvc.fit(X_train, y_train)\n\nSVC(probability=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC(probability=True) \n\n\n\ny_pred = svc.predict(X_test)\ny_pred_proba = svc.predict_proba(X_test)\nsvc_res = compute_classification_metrics(y_test, y_pred_proba, logits_to_prob=False, y_pred=y_pred, labels=list(range(10)))\nsvc_res\n\n\n\n\n\n{\n    'acc1': 0.9722222222222222,\n    'acc2': 0.9833333333333333,\n    'acc3': 0.9916666666666667,\n    'acc5': 0.9916666666666667,\n    'acc10': 1.0,\n    'acc20': 1.0,\n    'matthews_corrcoef': 0.9692503039897137,\n    'f1': 0.972029880729665,\n    'precision': 0.973182392919235,\n    'recall': 0.971984126984127,\n    'balanced_accuracy': 0.971984126984127,\n    'cohen_kappa': 0.9691339500827382,\n    'roc_auc': 0.9993403631348077,\n    'hinge_loss': 0.11966705184959518,\n    'log_loss': 0.1287164515187897,\n    'acc1_pred': 0.9722222222222222\n}\n\n\n\n需要注意的是，SVM的概率计算的机制较为特殊，所以用SVM的概率预测值进行决策的话，与SVM本身的预测是有所不同的。 因此我们上面看到的结果中，根据y_pred_proba计算的acc1(top k 准确率) 与 根据 y_pred计算的acc1并不相同，SVM本身的预测比SVM的概率预测更加准确。\n我写的代码库 namable_classify 就充分考虑了这种情况的发生，允许用户传入 y_pred。\n为了更好理解，我们代码可以看到具体的区别在哪里：\n\nimport numpy as np\n\n\ninterested = np.where(np.argmax(y_pred_proba, axis=1)!=y_pred)\ny_pred_proba[interested], np.argmax(y_pred_proba, axis=1)[interested], y_pred[interested]\n\n\n\n\n\n(\n    array([[0.04655995, 0.06806033, 0.01481866, 0.01379496, 0.04681734,\n        0.08531872, 0.31274431, 0.02019028, 0.37692727, 0.01476818],\n       [0.00642917, 0.04689452, 0.01313312, 0.04944728, 0.01523242,\n        0.03770956, 0.00456987, 0.3768156 , 0.01336737, 0.43640109],\n       [0.13989772, 0.01654543, 0.16119182, 0.17785276, 0.05271123,\n        0.13162163, 0.13944642, 0.02354677, 0.03741341, 0.1197728 ]]),\n    array([8, 9, 3]),\n    array([6, 7, 2])\n)\n\n\n\n\n\n1.1.2 sklearn 实现的 SMO形式 的 linear SVM\n\nsvc_linear = SVC(kernel='linear', probability=True)\nsvc_linear.fit(X_train, y_train)\n\nSVC(kernel='linear', probability=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC(kernel='linear', probability=True) \n\n\n\ny_pred = svc_linear.predict(X_test)\ny_pred_proba = svc_linear.predict_proba(X_test)\ncompute_classification_metrics(y_test, y_pred_proba, logits_to_prob=False, y_pred=y_pred, labels=list(range(10)))\n\n\n\n\n\n{\n    'acc1': 0.9777777777777777,\n    'acc2': 1.0,\n    'acc3': 1.0,\n    'acc5': 1.0,\n    'acc10': 1.0,\n    'acc20': 1.0,\n    'matthews_corrcoef': 0.9723041620958817,\n    'f1': 0.9748756231876998,\n    'precision': 0.9756801209103841,\n    'recall': 0.9748326898326898,\n    'balanced_accuracy': 0.9748326898326898,\n    'cohen_kappa': 0.9722207932506817,\n    'roc_auc': 0.9995142149923252,\n    'hinge_loss': 0.13536783910745212,\n    'log_loss': 0.1218441979874856,\n    'acc1_pred': 0.975\n}\n\n\n\n\n\n1.1.3 sklearn 实现的 基于 liblinear 库 的 Linear SVM\nThe main differences between LinearSVC and SVC lie in the loss function used by default, and in the handling of intercept regularization between those two implementations.\n\nn_samples, n_features = X_train.shape\nsklearn_will_use_dual_problem = n_samples &lt; n_features\nn_samples, n_features, sklearn_will_use_dual_problem\n\n\n\n\n\n(1293, 64, False)\n\n\n\n\nfrom sklearn.svm import LinearSVC\n\n\nlinear_svc = LinearSVC(penalty='l2', loss='squared_hinge', dual=sklearn_will_use_dual_problem, \n                       tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1)\nlinear_svc.fit(X_train, y_train)\n\nLinearSVC(dual=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearSVC?Documentation for LinearSVCiFittedLinearSVC(dual=False) \n\n\n\ny_pred = linear_svc.predict(X_test)\ncompute_classification_metrics(y_test, y_pred=y_pred, labels=list(range(10)), y_pred_metrics_only=True)\n\n\n\n\n\n{\n    'matthews_corrcoef': 0.9507782171913305,\n    'f1': 0.9551493507947526,\n    'precision': 0.9564648995608748,\n    'recall': 0.9553131703131704,\n    'balanced_accuracy': 0.9553131703131704,\n    'cohen_kappa': 0.9506151669738929,\n    'acc1_pred': 0.9555555555555556\n}\n\n\n\n\n\n1.1.4 sklearn 实现的 SGD优化Hinge Loss形式 的 linear SVM\nhttps://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html\nsklearn实现的 soft-margin linear Support Vector Machine 在 from sklearn.linear_model import SGDClassifier类中给出。 sklearn使用的是 one versus all (OVA) scheme，文档摘录如下\n\nFor each of the classes, a binary classifier is learned that discriminates between that and all other classes. At testing time, we compute the confidence score (i.e. the signed distances to the hyperplane) for each classifier and choose the class with the highest confidence.\n\nsklearn文档指出这种形式的SVM的潜在优化，包括以下几点\n\nmodified_huber，这是一个平滑版本的hinge loss，有研究表明效果更好。\nASGD，这个似乎类似于深度学习中的 Stochastic Weight Averaging (SWA)、Model Exponential moving average (Model EMA)和Sharpness-Aware Minimization (SAM)，我们有空深入研究一下这里面的区别与联系。\nElastic Net, 结合了L1和L2的正则项，来控制模型复杂度。\noptimal learning rate, 具体来说是 Leon Bottou 提出的一种方法，公式在此处可见。\n\n\nfrom sklearn.linear_model import SGDClassifier\n\n\nsgd_svm = SGDClassifier(\n    # loss=\"hinge\", \n# penalty=\"l2\", \n    loss=\"modified_huber\", \n                    penalty=\"elasticnet\", \n                    max_iter=1000, fit_intercept=True, \n                    learning_rate='optimal', \n                    early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, warm_start=True, average=True)\nsgd_svm.fit(X_train, y_train)\n\nSGDClassifier(average=True, early_stopping=True, loss='modified_huber',\n              penalty='elasticnet', warm_start=True)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SGDClassifier?Documentation for SGDClassifieriFittedSGDClassifier(average=True, early_stopping=True, loss='modified_huber',\n              penalty='elasticnet', warm_start=True) \n\n\n\ny_pred = sgd_svm.predict(X_test)\ncompute_classification_metrics(y_test, y_pred=y_pred, labels=list(range(10)), y_pred_metrics_only=True)\n\n\n\n\n\n{\n    'matthews_corrcoef': 0.9538068512149889,\n    'f1': 0.9581518233244193,\n    'precision': 0.9591395565079776,\n    'recall': 0.958086658086658,\n    'balanced_accuracy': 0.958086658086658,\n    'cohen_kappa': 0.9537005281569381,\n    'acc1_pred': 0.9583333333333334\n}\n\n\n\n\n\n1.1.5 使用更加高性能的SVM库来加速训练\n\n1.1.5.1 CPU上对SVM训练的加速\n我们首先尝试CPU上的加速。针对英特尔CPU，Intel对sklearn库进行了加速，我们通过下面的方式启用\npip install scikit-learn-intelex\n参考 博客 进行测速。\n\n# 加速之前\noriginal_sklearn = [0]*4\noriginal_sklearn[0] = %timeit -o svc.fit(X_train, y_train)\noriginal_sklearn[1] = %timeit -o  svc_linear.fit(X_train, y_train)\noriginal_sklearn[2] = %timeit -o linear_svc.fit(X_train, y_train)\noriginal_sklearn[3] = %timeit -o sgd_svm.fit(X_train, y_train)\n\n235 ms ± 39.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n94.6 ms ± 6.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n232 ms ± 16.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n79.5 ms ± 7.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\nfrom sklearnex import patch_sklearn\nimport logging\n\n\npatch_sklearn(verbose=False)\nlogging.disable(logging.INFO)\n# 因为存在JIT影响，先跑一遍\nsvc.fit(X_train, y_train)\nsvc_linear.fit(X_train, y_train)\nlinear_svc.fit(X_train, y_train)\nsgd_svm.fit(X_train, y_train)\npass\n\n\n# 加速之后\nintel_sklearn = [0]*4\nintel_sklearn[0] = %timeit -o svc.fit(X_train, y_train)\nintel_sklearn[1] = %timeit -o  svc_linear.fit(X_train, y_train)\nintel_sklearn[2] = %timeit -o linear_svc.fit(X_train, y_train)\nintel_sklearn[3] = %timeit -o sgd_svm.fit(X_train, y_train)\n\n284 ms ± 38.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n99.1 ms ± 7.91 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n274 ms ± 34.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n58 ms ± 4.13 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n英特尔宣称 对SVC的加速可以达到203.7%，然而我们并没有看到这样的结果。 我们使用假设检验来看看英特尔的sklearn是不是显著地块？这里由于结果是相关的，而且不能假设是正态分布，所以使用 wilcoxon signed rank 检验。\n\nfrom scipy.stats import wilcoxon\n\n\noriginal_sklearn_time = [t.best for t in original_sklearn]\nintel_sklearn_time = [t.best for t in intel_sklearn]\nres_less = wilcoxon(intel_sklearn_time, original_sklearn_time, zero_method='zsplit',alternative='less' # 实验备则假设， intel_sklearn 用时更短\n                    )\nif res_less.pvalue &gt; 0.05:\n    print(\"Null hypothesis cannot be rejected, so I have to accept that intel_sklearn is not faster than original_sklearn. \")\nres_less\nres_greater = wilcoxon(intel_sklearn_time, original_sklearn_time, zero_method='zsplit', alternative='greater' # 实验备则假设，intel_sklearn 用时更长\n                    )\nres_less, res_greater\n\nSun 2024-11-17 01:36:45.594639\n\n\n\nINFO     Null hypothesis cannot be rejected, so I have to accept that intel_sklearn is not faster     nucleus.py:53\n         than original_sklearn.                                                                                    \n\n\n\n\n\n\n\n(WilcoxonResult(statistic=7.0, pvalue=0.8125), WilcoxonResult(statistic=7.0, pvalue=0.3125))\n\n\n\n可以看出，不能显著地说哪个更快，都是在随机误差范围之内。可以认为这两个方法一样快。\n\n\n1.1.5.2 GPU上对SVM的加速\npip install thundersvm\n\nfrom thundersvm import SVC\n\n\n# thunder_svc = SVC(kernel='rbf', probability=True)\nthunder_svc = SVC(gpu_id=2)\nthunder_svc.fit(X_train, y_train)\n\n\n在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n\n请查看单元格中的代码，以确定故障的可能原因。\n\n单击&lt;a href='https://aka.ms/vscodeJupyterKernelCrash'&gt;此处&lt;/a&gt;了解详细信息。\n\n有关更多详细信息，请查看 Jupyter &lt;a href='command:jupyter.viewOutput'&gt;log&lt;/a&gt;。\n\n\n\n\nimport pandas as pd\n\n\ny_pred = thunder_svc.predict(X_test)\ny_pred_proba = thunder_svc.predict_proba(X_test)\nthunder_svc_res = compute_classification_metrics(y_test, y_pred_proba, logits_to_prob=False, y_pred=y_pred, labels=list(range(10)))\n# thunder_svc_res, svc_res\nres = []\nfor k, v in thunder_svc_res.items():\n    delta = v - svc_res[k]\n    # print(f\"{k}: {v:.4f} ({delta:+.4f})\")\n    res.append(dict(metric=k, value=v, delta=delta))\npd.DataFrame(res)\n\n\n\n\n\n\n\n\n\n\n\nmetric\nvalue\ndelta\n\n\n\n\n0\nacc1\n0.972222\n0.000000\n\n\n1\nacc2\n0.988889\n0.005556\n\n\n2\nacc3\n0.991667\n0.002778\n\n\n3\nacc5\n0.994444\n0.002778\n\n\n4\nacc10\n1.000000\n0.000000\n\n\n5\nacc20\n1.000000\n0.000000\n\n\n6\nmatthews_corrcoef\n0.969250\n0.000000\n\n\n7\nf1\n0.972030\n0.000000\n\n\n8\nprecision\n0.973182\n0.000000\n\n\n9\nrecall\n0.971984\n0.000000\n\n\n10\nbalanced_accuracy\n0.971984\n0.000000\n\n\n11\ncohen_kappa\n0.969134\n0.000000\n\n\n12\nroc_auc\n0.992732\n-0.006617\n\n\n13\nhinge_loss\n0.124893\n0.005310\n\n\n14\nlog_loss\n0.370853\n0.242670\n\n\n15\nacc1_pred\n0.972222\n0.000000\n\n\n\n\n\n\n\n看来精度上和sklearn的SVC基本一致，基本没有差别，除了log_loss多一点。\n\nthunder_svc_time = %timeit -o thunder_svc.fit(X_train, y_train)\n\n164 ms ± 59.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nsvc_time = %timeit -o svc.fit(X_train, y_train)\n\n186 ms ± 4.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n这里时间是不相关的，所以使用 mannwhitneyu 检验。\n\nfrom scipy.stats import mannwhitneyu\n\n\nres_less = mannwhitneyu(thunder_svc_time.all_runs, svc_time.all_runs, alternative='less' # 实验备则假设， intel_sklearn mannwhitneyu\n                    )\nif res_less.pvalue &gt; 0.05:\n    print(\"We cannot reject the null hypothesis! \")\nelse:\n    print(\"Null hypothesis rejected! ThunderSVC is significantly faster than SVC.\")\nres_less\n\nFri 2024-11-15 23:22:46.455835\n\n\n\nINFO     Null hypothesis rejected! ThunderSVC is significantly faster than SVC.                         utils.py:77\n\n\n\n\n\n\n\nMannwhitneyuResult(statistic=0.0, pvalue=0.0002913752913752914)\n\n\n\n看来thundersvm在GPU上加速还是显著地更快一些。\n\n\n\n\n1.2 实现 Hinge Loss+SGD 版本的 Soft Margin Linear SVM 并对其进行调参优化\n现在我们已经调研并且运行了已有SVM库的代码，了解了他们的用法以及在MNIST数据集上的表现。接下来我们将手写实现SVM，以及对其进行优化。\n接下来的内容请见文件 02svm_handy_crafted_linear。\n本次Project的目录请见绪论 00svm。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别"
    ]
  },
  {
    "objectID": "coding_projects/P2_SVM/handy_crafted_kernel.html",
    "href": "coding_projects/P2_SVM/handy_crafted_kernel.html",
    "title": "更高效的支持向量机算法实现及其在手写数字识别中的应用——04手动实现使用SMO的Kernel SVM",
    "section": "",
    "text": "本文是更高效的支持向量机算法实现及其在手写数字识别中的应用系列文章第04篇——手动实现使用SMO的Kernel SVM。\n\nsource\n\n0.1 KernelSupportVectorClassifier\n\n KernelSupportVectorClassifier\n                                (config:thu_big_data_ml.svm.kernel_hpo.Sup\n                                portVectorClassifierConfig)\n\n自己实现的支持向量机分类器。需要支持多分类。\n\n\nExported source\nfrom thu_big_data_ml.svm.kernel_hpo import SupportVectorClassifierConfig\nfrom fastcore.all import patch, store_attr\n\n\n/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/thu_big_data_ml/svm/kernel_hpo.py:225: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n  sampler=QMCSampler(seed=42), # 谷歌建议\n/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/thu_big_data_ml/svm/kernel_hpo.py:226: ExperimentalWarning: WilcoxonPruner is experimental (supported from v3.6.0). The interface can change in the future.\n  pruner=WilcoxonPruner(), # 对重复实验进行假设检验剪枝\n[I 2024-11-24 19:44:23,455] Using an existing study with name 'svm kernel hpo 11.17 3.0' instead of creating a new one.\n\n\n\n\nExported source\nclass KernelSupportVectorClassifier:\n    \"\"\"自己实现的支持向量机分类器。需要支持多分类。\n    \"\"\"\n    def __init__(self, config:SupportVectorClassifierConfig):\n        store_attr()\n\n\n由于本次这次Project时间不足，而我们已经完美完成了项目的前4个要求，所以我们暂时没有时间探索这里如何实现。等我有时间了我将继续更新这里的KernelSupportVectorClassifier 敬请关注后续的实现，我将把完整代码开源到 Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data 下的 svm_handy_crafted_kernel 笔记本中。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "P2_SVM",
      "更高效的支持向量机算法实现及其在手写数字识别中的应用——04手动实现使用SMO的Kernel SVM"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#绪论",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#绪论",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "1 绪论",
    "text": "1 绪论",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#代码与文档格式说明",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#代码与文档格式说明",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "2 代码与文档格式说明",
    "text": "2 代码与文档格式说明\n本文档使用Jupyter Notebook编写，所以同时包括了实验文档和实验代码。\n本次实验项目采用了 Quarto + nbdev 的系统来发布Jupyter Notebook, 因而我们的实验文档导出为pdf和html格式可以进行阅读，而我们的代码也导出为python模块形式，可以作为代码库被其他项目使用。\n我们这样做的好处是，避免单独管理一堆 .py 文件，防止代码冗余和同步混乱，py文件和pdf文件都是从.ipynb文件导出的，可以保证实验文档和代码的一致性。\n\n\n\n\n\n\n重要\n\n\n\n可以通过以下命令安装我们实验的代码：\npip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git\n我们的代码导出为了python模块形式，通过以下命令导入：\nfrom thu_big_data_ml.big_data_analytics.matrix_decomposition import *\n\n\nhttps://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git 是我们本次大数据机器学习课程实验的代码仓库地址。\n而这次作业中，我开发的我们课题组的基础依赖库ScholarlyInfrastructure也相应地进行了代码更新。这个库对标fastcore库，对AI科研经常会用到的一些基础性地、和Python语言的表达力有关的代码进行了整理，比如PyTorch模型检查、清晰的日志、实验参数管理、异常处理、argmax自动函数优化等。接下来我们也会用到这个项目中的一些代码来完成本次作业。 \npip install git+https://github.com/THU-CVML/ScholarlyInfrastructure.git\nfrom scholarly_infrastructure import *\n以上代码库开源在github，欢迎各位同学、老师们提出宝贵意见，或者加入我们的开发一起完善，构建更加优质的科研工具。\n\n\n\n\n\n\n重要\n\n\n\n本文档具有一定的交互性，建议使用浏览器打开html文件，这样比pdf文件阅读体验更佳。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#实验目的与项目要求",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#实验目的与项目要求",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "3 实验目的与项目要求",
    "text": "3 实验目的与项目要求\n\n老师给我们的要求是\n\n实现基于用户的协同过滤算法，并在测试集上计算RMSE。\n使用梯度下降法实现矩阵分解，优化目标函数，并在测试集上评估效果，尝试不同的参数组合。\n比较协同过滤和矩阵分解的优缺点。\n\n\n作为Top1大学的学生，我们不仅需要完成以上内容，还需要进行一些深入的思考和探索。\n\n算法优化：针对协同过滤的稀疏性问题，我们计划实现基于近邻选择的优化策略，如KNN-based CF，并尝试利用GPU加速相似度计算。\n超参数调优：在矩阵分解中，我们将系统地搜索隐空间维度k和正则化参数λ的最佳组合，使用网格搜索结合交叉验证来确定最优参数。\n自定义改进：尝试在矩阵分解中引入非线性变换或自定义正则化项，探索是否能进一步提高推荐精度。\n全面对比分析：除了RMSE，我们还将从时间复杂度、可解释性、冷启动问题等方面全面比较协同过滤和矩阵分解的优缺点，并通过可视化手段展示实验结果。\n\n事不宜迟，我们开始动手吧！",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#实验数据整理",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#实验数据整理",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "4 1. 实验数据整理",
    "text": "4 1. 实验数据整理\n\nNetflix 在2006年举办了奖金高达100万美元的Netflix Prize竞赛，旨在改进其电影推荐算法。这一竞赛吸引了大量AI开发者投身于推荐系统相关研究，并开辟了推荐算法商业化的先河。 Netflix电影评价数据集包含来自48万用户对1.7万部电影的评价数据，评价数超过100万条。\n\n我们选择了老师提供的Netflix数据集版本（一个子集），并使用里面的全部一万多个用户和一万多个电影的全量矩阵进行实验。\n\n4.1 数据集的自动下载\n我们在linux服务器中运行代码，因此优雅的方式是直接在服务器上下载数据集，加快速度。首先我们需要确认数据文件夹在哪里，这个是gitignore的一个文件夹。\n\nfrom thu_big_data_ml.help import data_path\n\n\ndownload_path = data_path / \"netflix\"\ndownload_path.mkdir(exist_ok=True, parents=True)\ndownload_path\n\n\n\n\n\nPath('/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/data/netflix')\n\n\n\n根据老师分享的清华网盘链接，我们写出如下代码：\n\nurls = [\n    \"https://cloud.tsinghua.edu.cn/seafhttp/files/5f936b33-0b44-4878-8c3c-320ad1863c3b/movie_titles.txt\", \n    \"https://cloud.tsinghua.edu.cn/seafhttp/files/54d448d0-88c1-4a6d-b0bc-80f1992deeca/netflix_test.txt\",\n    \"https://cloud.tsinghua.edu.cn/seafhttp/files/bfafbb0a-30fc-4215-aee2-4b73cc2d6855/netflix_train.txt\",\n    \"https://cloud.tsinghua.edu.cn/seafhttp/files/a228e885-c624-4cde-8c28-b88b3846e405/users.txt\",\n]\n# 自动提取文件名，得到 movie_titles.txt\n# filenames = [url[(url.rfind(\"F\")+1):url.rfind(\"&dl=1\")] for url in urls]\nfilenames = [url.split(\"/\")[-1] for url in urls]\nfilenames\n\n\n\n\n\n['movie_titles.txt', 'netflix_test.txt', 'netflix_train.txt', 'users.txt']\n\n\n\npip install py3-wget\nimport py3_wget\nfor url, file in zip(urls, filenames):\n    \n    py3_wget.download_file(\n        url=url,\n        output_path=(download_path/file).as_posix(),\n    )\n\n\n4.2 数据读取\n\nimport pandas as pd\nimport numpy as np\n\n由于我们有很多耗时操作，所以我们需要使用joblib库来将已经进行过的操作缓存到硬盘上，以便下次直接从硬盘中读取。\n\nfrom thu_big_data_ml.help import joblib_memory\n\n\npd.read_csv = joblib_memory.cache(pd.read_csv) # 尽管都是从磁盘读取，cache之前需要11s来读取 训练集， cache之后不需要解析csv的格式，所以快很多，0s左右就可以读取。\n\n现在我们来读取四个csv表格\n\n# 读取用户列表, 根据老师给的文档的信息，文件有 10000 行，每行一个整数，表示用户的 id，文件对应本次作业的所有用户。\nusers = pd.read_csv(download_path/'users.txt', header=None, names=['user_id'])\nprint(users.shape)\nusers.head()\n\nWed 2024-11-27 18:37:23.135476\n\n\n\nINFO     (10000, 1)                                                                                   nucleus.py:53\n\n\n\n\n\n\n\n\n\n\n\n\n\nuser_id\n\n\n\n\n0\n305344\n\n\n1\n387418\n\n\n2\n2439493\n\n\n3\n1664010\n\n\n4\n2118461\n\n\n\n\n\n\n\n\n# 读取训练集，文件包含 689 万条用户打分，每行为一条打分，对应的格式为：用户 id 电影 id 分数 打分日期\n# 我们用英文来标注列的名字。\ntrain_data = pd.read_csv(download_path/'netflix_train.txt', sep=' ', header=None, names=['user_id', 'movie_id', 'rating', 'date'])\nprint(train_data.shape)\ntrain_data.head()\n\nWed 2024-11-27 18:37:24.479991\n\n\n\nINFO     (6897746, 4)                                                                                 nucleus.py:53\n\n\n\n\n\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ndate\n\n\n\n\n0\n305344\n1\n1\n2004-02-08\n\n\n1\n305344\n3\n2\n2003-03-23\n\n\n2\n305344\n4\n1\n2003-12-13\n\n\n3\n305344\n5\n1\n2004-12-15\n\n\n4\n305344\n6\n1\n2003-09-23\n\n\n\n\n\n\n\n\n# 读取测试集, 文件包含约 172 万条用户打分，格式与训练集相同。\ntest_data = pd.read_csv(download_path/'netflix_test.txt', sep=' ', header=None, names=['user_id', 'movie_id', 'rating', 'date'])\nprint(test_data.shape)\ntest_data.head()\n\nWed 2024-11-27 18:37:25.914513\n\n\n\nINFO     (1719466, 4)                                                                                 nucleus.py:53\n\n\n\n\n\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ndate\n\n\n\n\n0\n2123534\n6134\n4\n2005-05-31\n\n\n1\n2123534\n677\n1\n2005-06-06\n\n\n2\n2123534\n3182\n4\n2005-06-06\n\n\n3\n2123534\n7882\n4\n2005-06-27\n\n\n4\n2123534\n6099\n1\n2005-05-31\n\n\n\n\n\n\n\n\n# 读取电影名称,文件对应每部电影的年份和名称，格式为：电影 id, 年份, 名称, 各项之间用逗号分隔。\ntry:\n    movies = pd.read_csv(download_path/'movie_titles.txt', sep=',', header=None, encoding='utf-8')\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\n________________________________________________________________________________\n[Memory] Calling pandas.io.parsers.readers.read_csv...\nread_csv(Path('/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/data/netflix/movie_titles.txt'), sep=',', header=None, encoding='utf-8')\n\n\nWed 2024-11-27 18:37:26.328949\n\n\n\nINFO     Error: Error tokenizing data. C error: Expected 3 fields in line 72, saw 4                   nucleus.py:53\n                                                                                                                   \n\n\n\n可以看到我们遇到了一个报错，72行的数据是这样的“72,1974,At Home Among Strangers, A Stranger Among His Own” 一个电影名自己包括分隔符”,“在里面，导致了pandas读取出错， 怎么解决这个问题呢？\n我们可以指定 names ，或者改变 sep使用正则表达式，强制要求有三个字段。\n\ntry:\n    movies = pd.read_csv(download_path / 'movie_titles.txt', sep=r'\\s*,\\s*', header=None, encoding='utf-8',\n                        names=['movie_id', 'year', 'title'], engine='python')\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\n________________________________________________________________________________\n[Memory] Calling pandas.io.parsers.readers.read_csv...\nread_csv(Path('/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/data/netflix/movie_titles.txt'), sep='\\\\s*,\\\\s*', header=None, encoding='utf-8', names=['movie_id', 'year', 'title'], engine='python')\n\n\nWed 2024-11-27 18:37:26.669584\n\n\n\nINFO     Error: 'utf-8' codec can't decode byte 0xe9 in position 2872: invalid continuation byte      nucleus.py:53\n\n\n\n为了解决编码问题，我们使用 chardet 自动检测数据的 编码格式。\npip install chardet\n\nimport chardet\n\n\nwith open(download_path / 'movie_titles.txt', 'rb') as f:\n    rawdata = f.read()\nencoding = chardet.detect(rawdata)['encoding']\nencoding\n\n\n\n\n\n'ISO-8859-1'\n\n\n\n\ntry:\n    movies = pd.read_csv(download_path / 'movie_titles.txt', sep=r'\\s*,\\s*', header=None, encoding=encoding, \n                        names=['movie_id', 'year', 'title'], engine='python')\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\n________________________________________________________________________________\n[Memory] Calling pandas.io.parsers.readers.read_csv...\nread_csv(Path('/home/ye_canming/repos/assignments/THU-Coursework-Machine-Learning-for-Big-Data/data/netflix/movie_titles.txt'), sep='\\\\s*,\\\\s*', header=None, encoding='ISO-8859-1', names=['movie_id', 'year', 'title'], engine='python')\n\n\nWed 2024-11-27 18:37:32.244361\n\n\n\nINFO     Error: Expected 3 fields in line 72, saw 4. Error could possibly be due to quotes being      nucleus.py:53\n         ignored when a multi-char delimiter is used.                                                              \n\n\n\n看来就算指定了 names， pandas无法知道我们面对多个逗号的时候处理的逻辑，而sep使用了正则表达式加上两边空白符对于本例无效，因为我们的分隔符实际上是没有空格的逗号。实际上，我们的规则是第一次遇到的两个逗号算数，后面的逗号无效。\n我们现在手动使用Python代码来处理这个复杂的逻辑，最后再转换为dataframe。\n\nwith open(download_path / 'movie_titles.txt', 'r', encoding=encoding) as file:\n    lines = file.readlines()\nlines[:3]\n\n\n\n\n\n['1,2003,Dinosaur Planet\\n', '2,2004,Isle of Man TT 2004 Review\\n', '3,1997,Character\\n']\n\n\n\n\nmovies = []\nfor i, line in enumerate(lines):\n    # 去除最后一个 \\n\n    line = line.strip()\n    if line==\"\": # 最后一行空行\n        continue\n    # 前两个逗号算数，第三个逗号无效\n    splits = line.split(',', 2)\n    # print(splits)\n    try:\n        row_data = [int(splits[0]), int(splits[1]), splits[2]]\n    except Exception as e:\n        print(e)\n        print(line, splits)\n        break\n        # logger.exception(e)\n    movies.append(row_data)\n\nWed 2024-11-27 18:37:34.815688\n\n\n\nINFO     invalid literal for int() with base 10: 'NULL'                                               nucleus.py:53\n\n\n\nWed 2024-11-27 18:37:34.839353\n\n\n\nINFO     ('4388,NULL,Ancient Civilizations: Rome and Pompeii', ['4388', 'NULL', 'Ancient              nucleus.py:55\n         Civilizations: Rome and Pompeii'])                                                                        \n\n\n\n我们可以看到再次出现报错，有的电影缺失了year这个字段，并且是用”NULL”字符串表示的。我们可以把它当做None，让Pandas处理为NaN。\n\nfrom scholarly_infrastructure import default_on_exception\n\n\ndefault_on_exception?\n\nSignature: default_on_exception(func, default_value=None, verbose=False)\nDocstring: &lt;no docstring&gt;\nFile:      ~/repos/novelties/cv/ScholarlyInfrastructure/scholarly_infrastructure/nucleus.py\nType:      function\n\n\n\nint_or_none = default_on_exception(lambda x: int(x), default_value=None)\nmovies = []\nfor i, line in enumerate(lines):\n    # 去除最后一个 \\n\n    line = line.strip()\n    if line==\"\": # 最后一行空行\n        continue\n    # 前两个逗号算数，第三个逗号无效\n    splits = line.split(',', 2)\n    row_data = [int_or_none(splits[0]), int_or_none(splits[1]), splits[2]]\n    movies.append(row_data)\n\n\n# 将列表转换为 DataFrame\nmovies = pd.DataFrame(movies, columns=['movie_id', 'year', 'title'])\nprint(movies.shape)\nmovies.head()\n\nWed 2024-11-27 18:37:37.539546\n\n\n\nINFO     (17770, 3)                                                                                   nucleus.py:53\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovie_id\nyear\ntitle\n\n\n\n\n0\n1\n2003.0\nDinosaur Planet\n\n\n1\n2\n2004.0\nIsle of Man TT 2004 Review\n\n\n2\n3\n1997.0\nCharacter\n\n\n3\n4\n1994.0\nPaula Abdul's Get Up & Dance\n\n\n4\n5\n2004.0\nThe Rise and Fall of ECW\n\n\n\n\n\n\n\n\n\n4.3 数据预处理为评分矩阵X\n\nfrom scipy.sparse import csr_matrix\n\ncsr_matrix是Compressed Sparse Row matrix，适合用于行操作比较多的场景。在这个推荐系统的问题中，用户是行，电影是列，每个元素是用户的评分。由于用户和电影的数量都很大，而且每个用户只评过很少的电影，所以这个矩阵会非常稀疏。用稀疏矩阵来表示可以节省内存和计算时间。\n那么怎么从刚才的原始数据得到评分矩阵呢？首先，我先对用户ID和电影ID分别建立一个字典，这个字典把行的索引（比如0-9999这些用户）和”user_id”实际的值去做映射。我们必须做这一步，不然索引是不安全的。我们使用行列的索引而非原始的user_id来做后续的操作。\n\n# 对用户ID进行排序，并映射到行索引\nsorted_users = users.sort_values('user_id')\nuser_to_row = {user_id: idx for idx, user_id in enumerate(sorted_users['user_id'])}\n# 对电影ID进行排序，并映射到列索引\nsorted_movies = movies.sort_values('movie_id')\nmovie_to_col = {movie_id: idx for idx, movie_id in enumerate(sorted_movies['movie_id'])}\n\n但是需要注意的是，data不一定用到了所有的user_id 和 movie_id, 所以实际上movie用到的只有老师说的”10000”多个，而不是 17770个。 \n\ntrain_data['user_id'].nunique(), train_data['movie_id'].nunique(), test_data['user_id'].nunique(), test_data['movie_id'].nunique()\n\n\n\n\n\n(10000, 10000, 10000, 9983)\n\n\n\n首先我们还需要搞明白训练集和测试集的关系是什么，他们的用户和电影是否重叠呢？\n\n# 集合取交集\nlen(set(train_data['user_id'].unique()) & set(test_data['user_id'].unique())), len(set(train_data['movie_id'].unique()) & set(test_data['movie_id'].unique()))\n\n\n\n\n\n(10000, 9983)\n\n\n\n\n\n\n\n\n\n注记\n\n\n\n一开始我以为，测试集和训练集的划分是根据不同的用户来操作的，我们需要用已知用户的评分去预测未知用户的评分，现在看来并不是这样的，一个用户实际上在训练集和测试集上都有出现，但是是不同的评分数据。我们接下来推荐系统中实际上是通过其他用户在训练集的评分来补全我们用户的评分，然后再用测试集已知的我们这个用户的评分来计算损失。\n\n\n我们再取并集来看，可以看出不管是训练集还是测试集，一共出现的都只有10000个电影和10000个用户。\n\n# 集合取并集\nlen(set(train_data['user_id'].unique()) | set(test_data['user_id'].unique())), len(set(train_data['movie_id'].unique()) | set(test_data['movie_id'].unique()))\n\n\n\n\n\n(10000, 10000)\n\n\n\n为了让矩阵是\\(10000\\times 10000\\)，而不是\\(10000\\times 17770\\)，我们的索引需要压缩一下。\n\nmovies_set = set(train_data['movie_id'].unique()) | set(test_data['movie_id'].unique())\nmovie_to_col = {movie_id: idx for idx, movie_id in enumerate(movies_set)}\n\n现在我们可以安全地从 train_data 和 tets_data 得到 \\(X_{train}, X_{test}\\) 了，这个矩阵在《深度学习推荐系统》一书中又称作“共现矩阵”。\n在scipy里，csr_matrix的构造函数可以接受三个参数： values, (rows, cols)，以及形状。 比如 values可以是 [10, 8], rows=[0, 1], cols=[3, 2], 这就表示在 (0, 3)和 (1, 2)两个坐标上矩阵的值是 10 和 8， 其他位置都是0（表示评分未知）。\n这样我们就成功规避了老师提到的“计算机计算能力”不足无法处理矩阵的问题。 当然这里只是解决了存储问题，后续这个矩阵怎么去做进一步运算是值得思考的。\n\nsource\n\n\n4.4 get_rating_matrix\n\n get_rating_matrix (data:pandas.core.frame.DataFrame)\n\n\n\nExported source\n# @joblib_memory.cache # data 哈希本身需要很大的开销，不宜 cache\ndef get_rating_matrix(data:pd.DataFrame)-&gt; csr_matrix:\n    rows = data['user_id'].map(user_to_row)\n    cols = data['movie_id'].map(movie_to_col)\n    values = data['rating']\n    \n    return csr_matrix((values, (rows, cols)), shape=(len(user_to_row), len(movie_to_col)))\n\n\n\nX_train = get_rating_matrix(train_data)\nX_test = get_rating_matrix(test_data)\nX_train.shape, X_test.shape, type(X_train), X_train.dtype\n\n\n\n\n\n((10000, 10000), (10000, 10000), &lt;class 'scipy.sparse._csr.csr_matrix'&gt;, dtype('int64'))\n\n\n\n如果有些操作不被稀疏矩阵支持，我们可能还是需要稠密矩阵，我们把稠密矩阵也给出。\n\nX_train_dense:np.array = X_train.toarray() # todense也可以\nX_test_dense:np.array = X_test.toarray() # todense也可以\nX_train_dense.shape, X_test_dense.shape, type(X_train_dense), X_train_dense.dtype\n\n\n\n\n\n((10000, 10000), (10000, 10000), &lt;class 'numpy.ndarray'&gt;, dtype('int64'))\n\n\n\n\n## 2. 基于用户的协同过滤实现\n\n协同过滤思路很简单，“当需要判断用户 i 是否喜欢电影 j，只要看与 i 相似的用户，看他们是否喜欢电影 j，并根据相似度对他们的打分进行加权平均”，这里需要注意几个关键的点：\n1. 判断用户i和用户j的相似性，是通过训练集i和j的相似性，而不是通过测试集用户i和用户j的相似性，也不是通过测试集i和训练集j的相似性，因为测试集本质上不是矩阵，而是单个评分，每次测试的时候我们知道的只有 user_id和movie_id，不能利用测试集的其他信息来判断相似性。\n2. 判断用户i是否喜欢电影j，用户i自身和自己很相似，但是因为缺失了数据所以填写了0，万万不可以用矩阵中缺省值“0”加入评分的平均计算，所以寻找“与i相似的用户”时，需要排除用户i自己。\n\n\n由于协同过滤有很多个不同的版本，而项目文档给出的公式缺乏对我上面说到的几个问题的严格定义，因此我们参考[《深度学习推荐系统》一书中的定义](https://yd.qq.com/web/reader/b7732f20813ab7c33g015deakaab325601eaab3238922e53)来实现代码。\n提出协同过滤方法的论文是 《Amazon.com Recommenders Item-to-Item Collaborative Filtering》。\n\n此外，协同过滤和机器学习方法有一定的关联，\n- 协同过滤和使用cos相似度的weighted的K近邻（sklearn中的`KNeighborsRegressor(weights='distance', metric='cosine')`）比较相似，区别KNN一般预测一个值或者类别，这里预测整个一行。以及刚才我们提到的第2点，协同过滤不能使用用户自己。\n- 计算一个矩阵每一行之间的相似度，把相似度矩阵存下来，也叫做Kernel Method，存下来的矩阵叫做Gram矩阵。\n\n由于K近邻代码上和协同过滤还是有所区别，我们这里不使用K近邻实现推荐系统。\n\n\n\n4.5 用户相似度计算\n我们首先计算每个用户互相之间的相似度。\n\n# 尝试在GPU上面算，期待会快一些\nimport torch\n\n\nX_train_torch = torch.from_numpy(X_train_dense).float()\nX_train_torch = X_train_torch.to(\"cuda\")\ntry:\n    cosine_sim = torch.nn.functional.cosine_similarity(X_train_torch[:, None], X_train_torch[None, :], dim=2)\nexcept Exception as e:\n    print(e)\n\nWed 2024-11-27 18:37:57.300306\n\n\n\nINFO     CUDA out of memory. Tried to allocate 3725.29 GiB. GPU 0 has a total capacity of 23.69 GiB   nucleus.py:53\n         of which 18.69 GiB is free. Process 1612869 has 1.91 GiB memory in use. Process 1631877 has               \n         1.66 GiB memory in use. Including non-PyTorch memory, this process has 1.41 GiB memory in                 \n         use. Of the allocated memory 1.12 GiB is allocated by PyTorch, and 0 bytes is reserved by                 \n         PyTorch but unallocated. If reserved but unallocated memory is large try setting                          \n         PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation               \n         for Memory Management                                                                                     \n         (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)                                   \n\n\n\n可惜PyTorch似乎不支持稀疏矩阵，我们暂时无法通过PyTorch在CUDA上面完成余弦相似度的计算。\n我们还是使用CPU来做。根据sklearn的文档\n\nX : {array-like, sparse matrix} of shape (n_samples_X, n_features) Input data.\n\nsklearn支持通过稀疏的方式，针对稀疏矩阵进行优化的前提下，来计算相似度，速度应该是合理的。\n\nsource\n\n\n4.6 get_similarities\n\n get_similarities ()\n\n\n\nExported source\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\n\n\nExported source\n@joblib_memory.cache\ndef get_similarities():\n    simularities = cosine_similarity(X_train)\n    return simularities\n\n\n\ncosine_sim = get_similarities()\n\n我们经过 352.9s, 5.9min 的时间，成功计算出 10000 x 10000 的余弦相似度矩阵。 \n由于我们使用了 joblib缓存结果, 第二次加载这个矩阵只需要 3.3s 。\n\ncosine_sim.shape, type(cosine_sim), cosine_sim.dtype\n\n\n\n\n\n((10000, 10000), &lt;class 'numpy.ndarray'&gt;, dtype('float64'))\n\n\n\n\ncosine_sim[:5, :5]\n\n\n\n\n\narray([[1.        , 0.29042362, 0.27409518, 0.29692921, 0.34769348],\n       [0.29042362, 1.        , 0.29676954, 0.2805517 , 0.23722667],\n       [0.27409518, 0.29676954, 1.        , 0.39591191, 0.32875298],\n       [0.29692921, 0.2805517 , 0.39591191, 1.        , 0.30646964],\n       [0.34769348, 0.23722667, 0.32875298, 0.30646964, 1.        ]])\n\n\n\n值得注意的是，cosine_similarity和cosine_distances有所不同，这两个加在一起是1，不要搞混了。\n\n\n4.7 “推理”协同过滤模型\n按照协同过滤算法本身来说，现在我们本来只需要对测试集的每一个评分开始预测就行了，对测试集有评分的每一个用户和每一个电影，按照公式去计算训练集中相似的用户的评分的加权平均数就可以了。\n但是我们可以把思路理地更清晰一些，实际上训练集确定的情况下，整个训练集的矩阵每一行是什么情况都是可以计算的，未来测试集只需要查询对应的结果即可，我们按照机器学习的术语，把这个过程称为“推理”（而刚才计算相似度矩阵的过程可以称为“训练”），得到的结果是新的 10000 x 10000的矩阵，每一行的评分是通过原始矩阵其他行的打分加权平均计算得到的。\n如此一来，我们的操作是向量化的。\n首先，根据我上面提到的“第二点”，我们需要排除用户自身和自身的相似度，不能用用户自身的评分来预测。实际上，更加合理的做法是计算平均数的时候排除评分为0的情况。\n我们可以使用 np.nanmean() 来在忽略缺失值的情况下计算平均值。\n\nexample_array = np.array([np.nan, np.nan, 1])\nnp.nanmean(example_array) # 正确的结果是 1.0，错误的结果是 1/3\n\n\n\n\n\n1.0\n\n\n\n\n# 如果是加权平均数，也是同理\nexample_weights = [1, 2, 3]\nmask = np.isnan(example_array)\nweights = np.where(mask, np.nan, example_weights)\nweighted_sum = np.nansum(example_array * weights)\nweight_sum = np.nansum(weights)\nweighted_mean = weighted_sum / weight_sum\nweighted_mean # 应当仍是1 , 而不是 0.5\n\n\n\n\n\n1.0\n\n\n\n理论清晰了，刚才我们已经知道怎么对向量做操作，现在我们可以编写代码来排除没有评分的列的情况下求加权平均数，对整个矩阵去做操作。\n\nX_train_dense = X_train_dense.astype(np.float64)\n\n\n\nExported source\nfrom copy import deepcopy\nfrom tqdm import tqdm\n\n\n\n# 评分范围是 1-5, 所以0就是缺失值，刚才稀疏矩阵的默认设为了0，我们需要nan\nX_train_dense_nan = deepcopy(X_train_dense)\nX_train_dense_nan[X_train_dense_nan==0] = np.nan\nX_train_dense_nan[0]\n\n\n\n\n\narray([nan, nan, nan, ..., nan, nan, nan])\n\n\n\n\nnp.ones((2, 3)).sum(axis=0)\n\n\n\n\n\narray([2., 2., 2.])\n\n\n\n\nsource\n\n\n4.8 get_X_train_weighted\n\n get_X_train_weighted ()\n\n\n\nExported source\ndef compute_weighted_sum_on_matrix(cosine_sim, X_train_dense_nan):\n# 创建一个与 X_train_dense 相同大小的矩阵，用于存储加权平均数\n    X_train_weighted = np.zeros_like(X_train_dense_nan)\n\n    # 遍历 X_train_dense 的每一行\n    for i in tqdm(range(X_train_dense_nan.shape[0])):\n        # 获取第 i 行的权重\n        weights = cosine_sim[i, :]\n        \n        # 复制这个权重到整个矩阵的维度，方便后面掩码操作\n        weights = np.repeat(weights, X_train_dense_nan.shape[1]).reshape(X_train_dense_nan.shape[0], X_train_dense_nan.shape[1])\n        \n        \n        # 创建一个掩码，是 nan的就是True\n        mask = np.isnan(X_train_dense_nan)\n        \n        \n        # 将权重中的对应位置设置为 np.nan\n        weights = np.where(mask, np.nan, weights)\n        \n        # 计算加权平均数，忽略 np.nan 值\n        X_train_weighted[i, :] = np.nansum(X_train_dense_nan * weights, axis=0) / np.nansum(weights, axis=0)\n\n    # X_train_weighted 现在是一个 mxn 的矩阵，其中每一行是忽略 np.nan 的加权平均数\n    return X_train_weighted\n\n@joblib_memory.cache\ndef get_X_train_weighted():\n    return compute_weighted_sum_on_matrix(cosine_sim, X_train_dense_nan)\n\n\n\nsource\n\n\n4.9 compute_weighted_sum_on_matrix\n\n compute_weighted_sum_on_matrix (cosine_sim, X_train_dense_nan)\n\n\n# X_train_weighted = get_X_train_weighted()\n\n可以看到速度非常慢，不可接受（4分钟连第一个计算也没有完成），我们需要进行一些优化。 \n\n4.9.1 速度优化——矩阵乘法\n如果我们不考虑加权平均数需要忽略没有评分的其他用户这一问题，直接把0当做是有效的评分，并且基于相似度直接计算加权平均数，那么我们马上就发现其实矩阵乘法 cosine_sim @ X_train_dense 是有意义的，这就等价于每一行的 cosine_sim 线性组合 X_train_densede 所有行向量。这个离加权平均数只差了一个归一化的步骤，新的矩阵的每一行需要 除以 cosine_sim 那一行的和。\n\nweight_sum = cosine_sim.sum(axis=1) # 每一行的和\nweight_sum.shape\n\n\n\n\n\n(10000,)\n\n\n\n\nX_train_pred_wrong = (cosine_sim @ X_train_dense) / weight_sum[:, np.newaxis] # 升维变成一列向量，这样才能每一行去除这个值而不是每一列去除。\nX_train_pred_wrong.shape\n\n\n\n\n\n(10000, 10000)\n\n\n\n\nX_train_pred_wrong[0]\n\n\n\n\n\narray([0.0410934 , 0.00174947, 0.10677668, ..., 0.00775722, 0.01182744,\n       0.02292204])\n\n\n\n当然上面得到的结果是错误的，我们看到里面的值都是“0.0410934”之类的，明显小于1，不可能是实际的评分取值，这就是因为没有考虑到刚才我们说的排除没有和商品交互的用户提供的0评分的问题。\n我们仔细观察上面的公式，可以发现 cosine_sim @ X_train_dense 其实计算的是正确的，因为评分为0的时候自然不会算进去，问题出在/ weight_sum[:, np.newaxis] 这一步把评分为0的用户也算了进去。\n因此，正确的解决办法是，对每一个用户和每一个物品，都有不同的 weight_sum。 给定一个用户的时候，确定了和其他用户的相似性，但是不同物品有不同的nan mask，从而weight的加和有所不同。\n我们经过一段时间的思考，可以注意到，这其实也是可以通过一个矩阵乘法来解决的。首先我们定义mask矩阵，如果是0（缺失评分）mask就是1，否则就是0。我们注意到(1-mask)矩阵，如果当做是一行列向量，那么每一个列向量就表示了物品对用户的选择，也就是这个物品有哪些用户是有评分的。使用这个列向量去对cosine_sim进行线性组合，其含义就是在进行一个选择性求和，只有非nan的地方才会相加。\n\nmask = np.isnan(X_train_dense_nan)\nweight_sum_correct = cosine_sim@(1-mask)\nweight_sum_correct.shape\n\n\n\n\n\n(10000, 10000)\n\n\n\n\nX_train_pred = (cosine_sim @ X_train_dense) / weight_sum_correct\nX_train_pred.shape\n\n\n\n\n\n(10000, 10000)\n\n\n\n最终我们的公式非常的简洁 (cosine_sim @ X_train_dense) / (cosine_sim @ (X_train_dense!=0)), 其中 @ 表示矩阵乘法， / 表示逐元素相除。\n\nX_train_pred[0]\n\n\n\n\n\narray([3.57833886, 1.76862034, 3.38810491, ..., 2.66767709, 1.94945024,\n       2.63015681])\n\n\n\n可以看到这一次我们得到的数值是正确的，是1-5的评分能得到的平均数。 网络上很多协同过滤的博客参差不齐，都没有提到这个公式，都是用for去写的，而《深度学习推荐系统》一书也没有涉及到这个细节。这里我们自己通过数学推导，终于得到了正确而高效的计算公式。\n刚才我们是用稠密矩阵来实现对应的公式的，由于矩阵乘法已经被numpy库深度优化，所以我们的计算很高效。下面我们尝试稀疏矩阵实现同样的计算。\ncosine_sim_sparse = csr_matrix(cosine_sim)\nnot_zero_rating = csr_matrix(1-mask) # 实际上这个很稀疏，很多元素都是0\nX_train_pred_sparse = (cosine_sim_sparse @ X_train) / (cosine_sim_sparse @ not_zero_rating)\nX_train_pred_sparse.shape\nnp.allclose(X_train_pred, X_train_pred_sparse.toarray())\n可以发现稀疏矩阵的速度在这个数据规模上和这个问题上，比稠密矩阵的还要慢不少，无法在合理的时间内完成。 \n这可能是因为我们得到的最终结果是稠密的，经过矩阵乘法之后稀疏矩阵就不再稀疏，因而算法并不高效，需要算出10000*10000个点，还不如稠密矩阵表示。\n\n\n\n4.10 评价协同过滤模型\n现在我们有了 X_train_pred, 包括了对所有用户在所有物品上的评分，接下来只需要与 X_test 对比就可以了。\n但是需要注意的是，X_test 并没有包含所有用户在所有物品上的评分，如果直接对这两个矩阵展开为向量去做RMSE，得到的结果当然是错误的。因为这样错误地把0评分和预测评分去做比较。\n我们可以for遍历所有的测试数据，然后去查询 X_train_pred 中对应的评分，然后再去计算指标。我们也可以对矩阵去进行操作。\n\ntest_mask = (X_test_dense!=0)  # 获得一个 mask，在老师给的文档中也称为“指示矩阵”\nmasked_X_train_pred = test_mask * X_train_pred # 把 X_test_dense 没有评分的地方的 X_train_pred 也变成0 （这里通过乘法，乘1乘0实现，也可以通过赋值实现）\nn = test_mask.sum() # 计算有评分的数量\nrmse = np.sqrt(((X_test_dense-masked_X_train_pred)**2).sum() / n) # 计算 RMSE，因为没有评分的地方大家都是0，所以计算出来是对的。\nrmse, n\n\n\n\n\n\n(1.0183690394072489, 1719466)\n\n\n\n我们也可以使用 PyTorch 来计算 RMSE，做出一个loss function。\n\nsource\n\n\n4.11 masked_rmse_loss\n\n masked_rmse_loss (reconstructed:torch.Tensor, matrix:torch.Tensor,\n                   verbose:bool=False, do_ensure_tensor:bool=True)\n\n\n\nExported source\nimport torch\n\n\n\n\nExported source\ndef ensure_tensor(x:np.ndarray|list, device:str=\"cuda:2\"):\n    # 确保输入loss函数的数据是张量\n    return torch.tensor(x).to(device)\ndef masked_rmse_loss(reconstructed:torch.Tensor, matrix:torch.Tensor, verbose:bool=False, do_ensure_tensor:bool=True)-&gt;torch.Tensor:\n    # 首先确保类型是tensor，而且device想同，这样才能在GPU上算Loss\n    if do_ensure_tensor:\n        reconstructed = ensure_tensor(reconstructed)\n        matrix = ensure_tensor(matrix)\n    # 获得一个 mask，在老师给的文档中也称为“指示矩阵”\n    test_mask = (matrix!= 0)\n    n = test_mask.sum()\n    if verbose:\n        print(f\"Number of non-zero elements in the matrix: {n}\")\n    # 只对mask后的元素做Loss计算\n    masked_matrix = matrix[test_mask]\n    masked_reconstructed = reconstructed[test_mask]\n    return torch.sqrt(torch.mean((masked_reconstructed - masked_matrix)**2))\n\n\n\nsource\n\n\n4.12 ensure_tensor\n\n ensure_tensor (x:numpy.ndarray|list, device:str='cuda:2')\n\n\nmasked_rmse_loss(ensure_tensor(X_train_pred), ensure_tensor(X_test_dense), verbose=True)\n\n/tmp/ipykernel_1705708/3678547022.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(x).to(device)\n\n\nWed 2024-11-27 18:38:57.454612\n\n\n\nINFO     Number of non-zero elements in the matrix: 1719466                                           nucleus.py:53\n\n\n\n\n\n\n\ntensor(1.0184, device='cuda:2', dtype=torch.float64)\n\n\n\n刚才我们算出了在测试集上的RMSE，同理，其实我们也可以计算在训练集上的RMSE，这应该并不是0，因为协同过滤算法不仅考虑了原本用户自己的评分，还把相似用户的评分考虑进来了。\n\nmasked_rmse_loss(ensure_tensor(X_train_pred), ensure_tensor(X_train_dense), verbose=True)\n\n/tmp/ipykernel_1705708/3678547022.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(x).to(device)\n\n\nWed 2024-11-27 18:39:01.089009\n\n\n\nINFO     Number of non-zero elements in the matrix: 6897746                                           nucleus.py:53\n\n\n\n\n\n\n\ntensor(1.0127, device='cuda:2', dtype=torch.float64)\n\n\n\n可以看出对于UserCF算法，训练集和测试集的RMSE误差差不多，训练集稍微低一些。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#基于梯度下降的矩阵分解算法实现",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#基于梯度下降的矩阵分解算法实现",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "5 3. 基于梯度下降的矩阵分解算法实现",
    "text": "5 3. 基于梯度下降的矩阵分解算法实现\n我们首先复习一下吴老师课程讲解的内容。\n老师课上强调，矩阵分解可以把PCA、SVD、LDA三个重要的方法统一起来。\n我们可以使用 PyTorch 来实现梯度下降矩阵分解，但是这里我们同时也尝试一下 jax 来实现。因为 jax 是 谷歌提出的新一代框架，结合了 NumPy 的接口和自动微分功能，以及强大的编译优化，据一些研究指出具有较好的性能。\npip install -U \"jax[cuda12]\"\npip install flax\npip install treescope\n\n5.1 模型定义\n首先我们需要定义我们的模型，具体来说需要定义模型的参数 U和V。U和V建模了评分矩阵。\n\n# 定义分解矩阵的大小\nk = 50  # 隐向量维度\nm, n = X_train_torch.shape\n\n\n\nExported source\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\n为了让代码规范一些，我们把参数写为 module 形式。\n\nsource\n\n\n5.2 MatrixFactorization\n\n MatrixFactorization (n_users:int, n_items:int, k)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n\nivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\n\n\nType\nDetails\n\n\n\n\nn_users\nint\n\n\n\nn_items\nint\n定义分解矩阵的大小\n\n\nk\n\n隐向量维度\n\n\n\n\n\nExported source\nclass MatrixFactorization(nn.Module):\n    def __init__(self, n_users:int, n_items:int, # 定义分解矩阵的大小\n                 k # 隐向量维度\n                 ):\n        super().__init__()\n        self.U = nn.Parameter(torch.randn(n_users, k))\n        self.V = nn.Parameter(torch.randn(n_items, k))\n    \n    def forward(self):\n        return torch.matmul(self.U, self.V.t())\n\n\n\nmodel = MatrixFactorization(m, n, k)\nmodel().shape\n\n\n\n\n\ntorch.Size([10000, 10000])\n\n\n\n我们再用 jax/flax 框架来尝试一下。\n\n\nExported source\n# 再尝试一下jax\nimport jax\nimport jax.numpy as jnp\nfrom jax import grad, jit, vmap # 这三个函数在 jax 中叫做 \"transformations\", 意思是对函数进行操作的函数（也可以说是泛函、算子），这三个函数分别作用是  求导，即时编译，向量化。\nimport jax.random as jrandom # 为了和 torch.random 做区分，我们导入叫做 jrandom\n\n\n\n# jax不需要 requires_grad 因为求导的逻辑不一样，jax待会会直接定义导函数。\n# 在 jax 当中随机数非常重要。 jax的函数是纯函数，不能有副作用，而且输入相同时输出必须相同。所以随机数必须通过显式地传入随机种子，来让随机函数是纯函数。\nkey = jrandom.PRNGKey(42)\njU = jrandom.normal(key, (m, k))\njV = jrandom.normal(key, (n, k))\n\n2024-11-27 18:39:11.782934: W external/xla/xla/service/platform_util.cc:206] unable to create StreamExecutor for CUDA:3: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n\n\nWed 2024-11-27 18:39:12.592821\n\n\n\nINFO     Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute      xla_bridge.py:906\n         'GpuAllocatorConfig'                                                                                      \n\n\n\nWed 2024-11-27 18:39:12.620062\n\n\n\nINFO     Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so:       xla_bridge.py:906\n         cannot open shared object file: No such file or directory                                                 \n\n\n\n我们可以直接使用jax对 jU 和 jV 去做梯度下降，但是我们写得更加规范一些，现在我们使用flax框架把矩阵分解也写为一个Module。\n注意，根据 https://github.com/google/flax , flax 有两套不同的API，一套是 from flax import linen, 一套是 from flax import nnx。 &gt; Released in 2024, Flax NNX is a new simplified Flax API that is designed to make it easier to create, inspect, debug, and analyze neural networks in JAX. Flax NNX evolved from the Flax Linen API, which was released in 2020 by engineers and researchers at Google Brain in close collaboration with the JAX team.\n后者与PyTorch更加接近，是flax的最新设计，我们决定使用后者。\n\n\nExported source\nfrom flax import linen as jnn # 为了和 torch.nn 做区分，我们导入叫做 jnn，和flax官方的写法不同\nfrom flax import nnx # 导入 nnx 库，里面包含了一些常用的网络层\nfrom fastcore.all import store_attr # 导入 fastcore 基础库的 store_attr 函数，用来方便地存储类的属性，这样Python面向对象写起来不那么冗长。 请 pip install fastcore。\nimport treescope # flax 的 可视化\n\n\n\n# 定义 MatrixFactorization 模型\n# 注意 flax 使用了 Python标准库 `dataclasses`， 因为面向对象的定义风格更加简洁，使用类变量specify了init的参数。\nclass JaxMatrixFactorization(nnx.Module):\n    def __init__(self, n_users:int, n_items:int, # 定义分解矩阵的大小\n                 k:int, # 隐向量维度\n                 *, rngs: nnx.Rngs # 在 jax 中随机种子非常重要。\n                 ):\n        super().__init__()\n        # store_attr()\n        key = rngs.params()\n        self.U = nnx.Param(jrandom.normal(key, (n_users, k)))\n        self.V = nnx.Param(jrandom.normal(key, (n_items, k)))\n        # 如果我们还有子模块，flax要求把 rngs 传递下去。\n    def __call__(self):\n        # return jnp.dot(self.U, self.V.T) # 不能使用这个，因为 nnx.Param 和 jnp.array 不一样，会导致 jax 编译错误，这个是jax的bug。\n        return self.U @ self.V.T\n\n\n# 现在我们可以构建这个模型\nrngs=nnx.Rngs(params=42)\njmodel = JaxMatrixFactorization(m, n, k, rngs=rngs)\nprint(jmodel().shape)\nnnx.display(jmodel)\n\nWed 2024-11-27 18:39:18.599747\n\n\n\nINFO     (10000, 10000)                                                                               nucleus.py:53\n\n\n\n\n\n\n     \n\n\n\n\n\n   \n\n\n可见目前来看新版的 nnx 接口与PyTorch基本一样，只不过强调随机数种子的传递。旧版的linen则是有较大的不同，它并不能在类中储存状态，需要递归地从模型中调用初始化函数整合出一个大的参数向量出来。\n\n\n5.3 损失函数定义\n\n\n\nimage.png\n\n\n注意在 PyTorch 的设计哲学中，正则化项是通过优化器weight_decay选项来实现的，而不是在损失函数中计算。 这是因为损失函数通常输入是 (y_pred, y_true) 的形式，不包含模型参数，这样才能把逻辑解耦开来。所以如果我们在loss就实现 l2 regularization，是很麻烦而且没有必要的。而优化器对模型的参数有完全的访问权，可以精确控制哪些部分的参数使用什么学习率和什么正则化。\n所以我们下面损失函数暂时忽略 \\(\\lambda\\) ，稍后会加入回来。\n\nsource\n\n\n5.4 jax_masked_mse_loss\n\n jax_masked_mse_loss (reconstructed:jax.Array, matrix:jax.Array)\n\n\n\nExported source\n# 定义PyTorch的损失函数\ndef masked_mse_loss(reconstructed:torch.Tensor, matrix:torch.Tensor)-&gt;torch.Tensor:\n    observed_indices = torch.where(matrix != 0) # A 矩阵，表示哪里是有评分的，只在有评分的地方算loss。\n    return 0.5*torch.mean((reconstructed[observed_indices] - matrix[observed_indices])**2)\n\n# 同理，定义 jax 损失函数\ndef jax_masked_mse_loss(reconstructed:jnp.ndarray, matrix:jnp.ndarray)-&gt;jnp.ndarray:\n    observed_indices = jnp.where(matrix != 0) # A 矩阵，表示哪里是有评分的，只在有评分的地方算loss。\n    return 0.5*jnp.mean((reconstructed[observed_indices] - matrix[observed_indices])**2)\n\n\n\nsource\n\n\n5.5 masked_mse_loss\n\n masked_mse_loss (reconstructed:torch.Tensor, matrix:torch.Tensor)\n\n\n# 测试一下我们刚写的函数\nmasked_mse_loss(model(), model()) # 应当是0\n\n\n\n\n\ntensor(0., grad_fn=&lt;MulBackward0&gt;)\n\n\n\n\njax_masked_mse_loss(jmodel(), jmodel()) # 应当是0\n\n\n\n\n\nArray(0., dtype=float32)\n\n\n\n可以看到 jax 和 torch 基本都是遵循numpy接口的，所以写法基本一样。由于PyTorch的求导方式是动态构建计算图，所以我们在上面的输出可以看到 tensor 带有一个 grad_fn 属性，用来记录计算图，而 jax 的输出则没有。\n\n\n5.6 3.a 梯度下降训练分解矩阵U和V (k=50, λ=0.01)\n\n# 参考推荐系统库 https://surprise.readthedocs.io/en/stable/matrix_factorization.html 的默认参数设置，\n# lmd = 2e-2\nlr = 5e-3\n\n# 参考老师给的设置\nlmd = 0.01\nk = 50\n\n# 收敛条件\nmax_epochs = 100000\n# required_rmse = 1.0\n# required_delta_loss = 1e-4\nrequired_delta_loss = 1e-6\n\n\n5.6.1 PyTorch 实现训练矩阵分解模型\n\nsource\n\n\n\n5.7 train_matrix_factorization\n\n train_matrix_factorization (X_train_dense:&lt;built-infunctionarray&gt;,\n                             X_test_dense:&lt;built-infunctionarray&gt;,\n                             k:int=50, lmd:float=0.02, lr:float=0.005,\n                             max_epochs:int=100000,\n                             required_delta_loss:float=0.01,\n                             random_state=42, device='cuda:4')\n\n\n\nExported source\nimport lightning as L # PyTorch Lightning库，这里我们只是用它来固定随机数种子\n\n\n\n\nExported source\ndef train_matrix_factorization(X_train_dense:np.array, X_test_dense:np.array, k:int = 50, \n                    lmd:float = 2e-2, lr:float = 5e-3, max_epochs:int = 100000, \n                    required_delta_loss:float = 1e-2,\n                    random_state=42, device = 'cuda:4'):\n    # 设置 PyTorch 随机种子，防止结果不一致。\n    L.seed_everything(random_state) \n    # 输入数据转为 PyTorch 张量\n    X_train_torch = torch.from_numpy(X_train_dense).to(device)\n    X_test_torch = torch.from_numpy(X_test_dense).to(device)\n    # 模型定义\n    m, n = X_train_torch.shape\n    model = MatrixFactorization(m, n, k).to(device)\n    model = torch.compile(model)\n    # 优化器定义\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=lmd)\n    # 指标\n    metrics = []\n    # 优化循环\n    bar = tqdm(range(max_epochs))\n    previous_loss = 0\n    for epoch in bar:\n        optimizer.zero_grad()\n        pred_matrix = model()\n        loss = masked_mse_loss(pred_matrix, X_train_torch)\n        loss.backward()\n        optimizer.step()\n        # 计算指标\n        with torch.no_grad():\n            # RMSE\n            train_rmse = masked_rmse_loss(pred_matrix, X_train_torch, do_ensure_tensor=False)\n            test_rmse = masked_rmse_loss(pred_matrix, X_test_torch, do_ensure_tensor=False)\n            # loss 变化\n            loss_item = loss.item()\n            delta_loss = abs(loss_item - previous_loss)\n            previous_loss = loss_item\n            \n            metric = dict(\n                loss=loss_item,\n                train_rmse = train_rmse.item(),\n                test_rmse = test_rmse.item(), \n                delta_loss = delta_loss\n            )\n            # 指标记录\n            metrics.append(metric)\n            bar.set_postfix(**metric)\n            # 中止条件\n            if delta_loss&lt;required_delta_loss:\n                break\n            \n    return model, metrics\n\n\n\nmodel, metrics = train_matrix_factorization(X_train_dense, X_test_dense, k=k, lmd=lmd, lr=lr, max_epochs=max_epochs, required_delta_loss=required_delta_loss)\n\nINFO: Seed set to 42\n\n\nWed 2024-11-27 19:00:35.276313\n\n\n\nINFO     Seed set to 42                                                                                  seed.py:57\n\n\n\n  9%|▉         | 8898/100000 [05:29&lt;56:16, 26.98it/s, delta_loss=9.99e-7, loss=0.229, test_rmse=0.944, train_rmse=0.676]  \n\n\n\nmetrics_df = pd.DataFrame(metrics)\nmetrics_df\n\n\n\n\n\n\n\n\n\n\n\nloss\ntrain_rmse\ntest_rmse\ndelta_loss\n\n\n\n\n0\n31.268773\n7.908068\n7.916553\n3.126877e+01\n\n\n1\n30.852997\n7.855316\n7.867649\n4.157756e-01\n\n\n2\n30.443528\n7.803016\n7.819154\n4.094697e-01\n\n\n3\n30.040385\n7.751179\n7.771080\n4.031427e-01\n\n\n4\n29.643580\n7.699816\n7.723437\n3.968044e-01\n\n\n...\n...\n...\n...\n...\n\n\n8894\n0.228510\n0.676033\n0.944070\n1.001718e-06\n\n\n8895\n0.228509\n0.676031\n0.944089\n1.001671e-06\n\n\n8896\n0.228508\n0.676030\n0.944108\n1.000704e-06\n\n\n8897\n0.228507\n0.676028\n0.944127\n1.000480e-06\n\n\n8898\n0.228506\n0.676027\n0.944146\n9.992896e-07\n\n\n\n\n8899 rows × 4 columns\n\n\n\n\n5.7.1 Jax/Flax 实现训练矩阵分解模型\n\nfrom functools import partial\nimport optax\n\n\n# 训练函数\n# @nnx.jit  # nnx 提供的 算子，进行自动状态管理\n@partial(nnx.jit, static_argnums=(3, ))  # 静态参数，用于固定模型和优化器参数, 这个是为了解决一些不能被 jit 但是可以hash的参数，这里不能这样解决。参考 https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\ndef train_step(jmodel:JaxMatrixFactorization, joptimizer:nnx.Optimizer, X_train_jnp:jnp.ndarray, criterion=jax_masked_mse_loss):\n    def loss_fn(jmodel:JaxMatrixFactorization):\n        pred_matrix = jmodel()\n        return criterion(pred_matrix, X_train_jnp)\n    loss, grads = nnx.value_and_grad(loss_fn)(jmodel) # 这是另一个nnx算子，自动求导函数、\n    joptimizer.update(grads)  # In place 的更新操作，更新优化器参数和模型参数。\n    return loss\n\n\n# 构建jax的优化器\njoptimizer = nnx.Optimizer(jmodel, optax.adamw(lr))\nX_train_jnp = jnp.array(X_train_dense) # 从numpy array 转换为 jax array\ntry:\n    loss = train_step(jmodel, joptimizer, X_train_jnp)  \nexcept Exception as e:\n    print(e)\n\nWed 2024-11-27 19:06:14.722929\n\n\n\nINFO     Abstract tracer value encountered where concrete value is expected: traced array with shape  nucleus.py:53\n         int32[]                                                                                                   \n         The size argument of jnp.nonzero must be statically specified to use jnp.nonzero within JAX               \n         transformations.                                                                                          \n         The error occurred while tracing the function train_step at                                               \n         /tmp/ipykernel_1705708/2484339058.py:5 for jit. This concrete value was not available in                  \n         Python because it depends on the value of the argument X_train_jnp.                                       \n                                                                                                                   \n         See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError                   \n\n\n\n这是 jax jit编译时会遇到的典型问题，问题的根源在于我们刚才定义 jax_masked_mse_loss 函数的时候，使用到了 jnp.where 函数（使用到 jnp.nonzero函数），这个函数如果输入并不知道 size，就无法进行编译。\n我们现在来改进一下这个函数。刚才 where 是选择了 indices 出来，所以导致了计算具有动态性，不利于jax的静态编译，我们可以使用另一种计算方式。\n\nsource\n\n\n\n5.8 compilable_jax_masked_mse_loss\n\n compilable_jax_masked_mse_loss (reconstructed:jax.Array,\n                                 matrix:jax.Array)\n\n\n\nExported source\n@jit\ndef compilable_jax_masked_mse_loss(reconstructed:jnp.ndarray, matrix:jnp.ndarray)-&gt;jnp.ndarray:\n    mask = (matrix!=0)  # 获得一个 mask，在老师给的文档中也称为“指示矩阵”\n    masked_reconstructed = mask * reconstructed # 把 matrix 没有评分的地方的 reconstructed 也变成0 （这里通过乘法，乘1乘0实现，也可以通过赋值实现）\n    n = mask.sum() # 计算有评分的数量\n    rmse = jnp.sqrt(((matrix-masked_reconstructed)**2).sum() / n) # 计算 RMSE，因为没有评分的地方大家都是0，所以计算出来是对的。\n    return rmse\n\n\n\n\n\n\n(Array(0., dtype=float32), 0.0)\n\n\n\n\nloss = compilable_jax_masked_mse_loss(jmodel(), jmodel())\nloss, float(loss) # 单个scalar转化为float\n\n使用 jit 算子对 compilable_jax_masked_mse_loss 操作，然后计算一次，可以看到计算成功了，这个函数是可以被jax编译的。\n现在我们可以来优化了。\n\nsource\n\n\n5.9 train_matrix_factorization_jax\n\n train_matrix_factorization_jax (X_train_dense:&lt;built-infunctionarray&gt;,\n                                 X_test_dense:&lt;built-infunctionarray&gt;,\n                                 k:int=50, lmd:float=0.02, lr:float=0.005,\n                                 max_epochs:int=100000,\n                                 required_delta_loss:float=0.001,\n                                 random_state=42,\n                                 trial:optuna.trial._trial.Trial=None,\n                                 critical_metric='test_rmse')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX_train_dense\narray\n\n\n\n\nX_test_dense\narray\n\n\n\n\nk\nint\n50\n\n\n\nlmd\nfloat\n0.02\n\n\n\nlr\nfloat\n0.005\n\n\n\nmax_epochs\nint\n100000\n\n\n\nrequired_delta_loss\nfloat\n0.001\n\n\n\nrandom_state\nint\n42\n\n\n\ntrial\nTrial\nNone\n\n\n\ncritical_metric\nstr\ntest_rmse\n用于下一章节的调优的 Pruning\n\n\n\n\n\nExported source\nimport optuna\n\n\n\n\nExported source\n# @jit\ndef train_matrix_factorization_jax(X_train_dense:np.array, X_test_dense:np.array, k:int = 50, \n                    lmd:float = 2e-2, lr:float = 5e-3, max_epochs:int = 100000, required_delta_loss:float = 1e-3,\n                    random_state=42,\n                    trial:optuna.Trial=None, critical_metric=\"test_rmse\" # 用于下一章节的调优的 Pruning \n                    ):\n    X_train_jnp = jnp.array(X_train_dense) # 从numpy array 转换为 jax array\n    X_test_jnp = jnp.array(X_test_dense) # 从numpy array 转换为 jax array\n    # 模型定义\n    m, n = X_train_jnp.shape\n    rngs=nnx.Rngs(params=random_state)\n    jmodel = JaxMatrixFactorization(m, n, k, rngs=rngs)\n    # 优化器\n    joptimizer = nnx.Optimizer(jmodel, optax.adamw(learning_rate=lr, weight_decay=lmd))\n    jmetrics = [] # 指标\n    bar = tqdm(range(max_epochs))\n    previous_loss:float = 0.0\n    for epoch in bar:\n        pred_matrix = jmodel()\n        loss = train_step(jmodel, joptimizer, X_train_jnp, criterion=compilable_jax_masked_mse_loss)\n        \n        # 指标记录\n        train_rmse = jnp.sqrt(loss)\n        test_rmse = jnp.sqrt(compilable_jax_masked_mse_loss(pred_matrix, X_test_jnp))\n        # 有关收敛\n        loss_item = float(loss) # 把单个 scalar 转化为 float， 但是需要注意这个会让jit无法在外层编译\n        delta_loss:float = abs(loss_item - previous_loss)\n        previous_loss = loss_item\n        \n        metric = dict(\n            loss = loss_item,  \n            train_rmse = float(train_rmse),\n            test_rmse = float(test_rmse), \n            delta_loss = delta_loss\n        )\n        # 指标的记录\n        jmetrics.append(metric)\n        bar.set_postfix(**metric)\n        # optuna调参记录\n        if trial is not None:\n            for k, v in metric.items():\n                trial.set_user_attr(k, v)\n            trial.report(metric[critical_metric], step=epoch)\n            if trial.should_prune():\n                raise optuna.TrialPruned()\n\n        # 收敛条件\n        if delta_loss&lt;required_delta_loss:\n            break\n    return jmodel, jmetrics\n\n\n\n# 设置 jax 计算的设备\njax.default_device = jax.devices(\"gpu\")[1]\njax.default_device\n\n\n\n\n\nCudaDevice(id=1)\n\n\n\n\njmodel, jmetrics = train_matrix_factorization_jax(X_train_dense, X_test_dense, k=k, lmd=lmd, lr=lr, max_epochs=max_epochs, required_delta_loss=required_delta_loss)\n\n  6%|▌         | 5503/100000 [01:27&lt;25:04, 62.82it/s, delta_loss=8.34e-7, loss=0.676, test_rmse=0.978, train_rmse=0.822]  \n\n\n\njmetrics_df = pd.DataFrame(jmetrics)\njmetrics_df\n\n\n\n\n\n\n\n\n\n\n\nloss\ntrain_rmse\ntest_rmse\ndelta_loss\n\n\n\n\n0\n7.955531\n2.820555\n2.821863\n7.955531e+00\n\n\n1\n7.902468\n2.811133\n2.813115\n5.306339e-02\n\n\n2\n7.849845\n2.801758\n2.804412\n5.262232e-02\n\n\n3\n7.797671\n2.792431\n2.795755\n5.217409e-02\n\n\n4\n7.745949\n2.783154\n2.787145\n5.172205e-02\n\n\n...\n...\n...\n...\n...\n\n\n5499\n0.675748\n0.822039\n0.978253\n1.251698e-06\n\n\n5500\n0.675747\n0.822038\n0.978269\n1.370907e-06\n\n\n5501\n0.675746\n0.822038\n0.978279\n1.192093e-06\n\n\n5502\n0.675745\n0.822037\n0.978296\n1.072884e-06\n\n\n5503\n0.675744\n0.822036\n0.978304\n8.344650e-07\n\n\n\n\n5504 rows × 4 columns\n\n\n\n我们很明显看到 jax 的矩阵分解优化速度比PyTorch要快很多。不仅收敛的epochs数少了一半，而且每一个epoch需要的训练时间也更少。\n\n为什么收敛的epochs数少了呢？可以看到是因为 jax 的初始值就更好一些。尽管 jax.random.normal 与 torch.randn 确实是等价的，而且 随机种子都是42，但是jax得到的初始UV确实更好。\n为什么 jax 比 PyTorch 快呢？我们的 PyTorch 已经是使用了良好的代码实践，使用了 PyTorch 2.0 的 torch.compile功能，并且在不需要求导的情况下使用了 torch.no_grad()，然而仍然是打不过 jax。有人说这是因为 jax 支持 JIT，这确实没错，XLA技术具有强大的性能，但是 PyTorch 的 torch.compile 也未尝不利。参考文章，实际上问题的关键在于 JAX 强调 函数式编程和无状态设计，所有的函数都是纯函数，没有副作用，因此编译优化更简单，而 PyTorch 则是面向对象编程，有状态的设计，因而需要更多的编译优化。\n\n为了确定文档中说的 jax.random.normal 与 torch.randn 等价，这里我们可以使用 KS 拟合优度假设检验，验证这两个方法得到的随机数是否来自于同一个分布。\n\nfrom scipy.stats import kstest, norm\n\n\n# 生成 PyTorch 随机数\nL.seed_everything(42)\ntorch_samples = torch.randn(1000)\n# 生成 JAX 随机数\njax_samples = jax.random.normal(jrandom.PRNGKey(42), (1000,))\nres_torch = kstest(torch_samples, norm.cdf, alternative='two-sided')\nres_jax = kstest(jax_samples, norm.cdf, alternative='two-sided')\nres_mutual = kstest(jax_samples, torch_samples, alternative='two-sided')\nif res_torch.pvalue &gt; 0.05:\n    print(f\"无法拒绝零假设，所以我们得接受torch就是服从标准正态分布\")\nif res_jax.pvalue &gt; 0.05:\n    print(f\"无法拒绝零假设，所以我们得接受jax就是服从标准正态分布\")\nif res_jax.pvalue &gt; 0.05:\n    print(f\"无法拒绝零假设，所以我们得接受这两个分布是一样的。\")\nres_torch, res_jax, res_mutual\n\nINFO: Seed set to 42\n\n\nWed 2024-11-27 19:42:05.180708\n\n\n\nINFO     Seed set to 42                                                                                  seed.py:57\n\n\n\nWed 2024-11-27 19:42:05.233134\n\n\n\nINFO     无法拒绝零假设，所以我们得接受torch就是服从标准正态分布                                      nucleus.py:53\n\n\n\nWed 2024-11-27 19:42:05.248983\n\n\n\nINFO     无法拒绝零假设，所以我们得接受jax就是服从标准正态分布                                        nucleus.py:53\n\n\n\nWed 2024-11-27 19:42:05.257456\n\n\n\nINFO     无法拒绝零假设，所以我们得接受这两个分布是一样的。                                           nucleus.py:53\n\n\n\n\n\n\n\n(\n    KstestResult(statistic=0.019189070906030226, pvalue=0.848033539038892, statistic_location=-0.38583097, statistic_sign=1),\n    KstestResult(statistic=0.034437055011013185, pvalue=0.18222928193437893, statistic_location=-0.63853437, statistic_sign=1),\n    KstestResult(statistic=0.041, pvalue=0.37012017606173, statistic_location=-0.81669724, statistic_sign=1)\n)\n\n\n\n我们可以看到统计上来说确实是等价的，但是得到的结果在相同随机数种子下确实是不同的数值。而且由于 res_torch 的 p值比 res_jax 的更高，我们可以认为 torch 的随机结果反而更加接近标准正态分布。\n从 jax random模块的文档来看，jax采用的随机数生成算法是”threefry2x32”，设计的目的是为了更好的并行化和向量化。\n根据这篇学术论文, NumPy, TensorFlow, 和 PyTorch 三个框架使用的随机数生成算法分别是 Mersenne Twister, PCG, and Philox。因此，PyTorch生成随机数的算法与Jax有所不同，这也就导致了我们刚才都选择了42作为随机种子，但是得到的UV矩阵初值有所不同，jax的随机矩阵在矩阵分解这个问题上似乎更好。\n\n5.9.1 画出迭代过程中目标函数值和测试集上 RMSE 的变化\n我们这里尝试使用 plotly 而非 matplotlib 库来绘制图片，因为使用html或者jupyter notebook查看本文档的时候，plotly 能展示交互性的图表。\npip install plotly\n\n\nExported source\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\n由于 目标函数值 （MSE）的量纲和 RMSE不同，我们可以使用高级的绘图技巧，在同一张图上使用不同的纵轴来绘制不同的曲线，以方便比较。参考官方文档 和 中文翻译版本。\n\nsource\n\n\n\n5.10 draw_metrics_df\n\n draw_metrics_df (df:pandas.core.frame.DataFrame, title:str='Metrics')\n\n\n\nExported source\ndef draw_metrics_df(df:pd.DataFrame, title:str='Metrics'):\n    # 使用 plotly 创建图表\n    fig = go.Figure()\n    # 需要支持第二纵轴\n    fig = make_subplots(specs=[[{\"secondary_y\": True}]], figure=fig)\n\n    # 绘制 loss 曲线\n    fig.add_trace(go.Scatter(x=df.index, y=df['loss'], name='Loss', mode='lines'), secondary_y=False)\n    fig.add_trace(go.Scatter(x=df.index[1:], y=df['delta_loss'][1:], name='Delta Loss', mode='lines'), secondary_y=False)\n\n    # 绘制 train_rmse 和 test_rmse 曲线\n    fig.add_trace(go.Scatter(x=df.index, y=df['train_rmse'], name='Train RMSE', mode='lines'), secondary_y=True)\n    fig.add_trace(go.Scatter(x=df.index, y=df['test_rmse'], name='Test RMSE', mode='lines'), secondary_y=True)\n    \n    # 更新坐标轴\n    fig.update_yaxes(title_text=\"Loss\", titlefont_color=\"red\", tickfont_color=\"red\", secondary_y=False)\n    fig.update_yaxes(title_text=\"RMSE\", titlefont_color=\"blue\", tickfont_color=\"blue\", secondary_y=True)\n    \n    # 标题\n    fig.update_layout(title=dict(\n        text=title\n    ),)\n    return fig\n\n\n\nfig = draw_metrics_df(metrics_df, title=\"Metrics of PyTorch Based Matrix Factorization Training\")\nfig\n\n                                                \n\n\n\nfig = draw_metrics_df(jmetrics_df, title=\"Metrics of Jax Based Matrix Factorization Training\")\nfig\n\n                                                \n\n\n如图所示，Loss 和 Delta Loss 使用的是左侧的坐标轴，单位为评分的平方，而Train RMSE 和 Test RMSE 使用的是右侧的坐标轴，单位为评分。Delta Loss是用来决定收敛条件的，是Loss的差分的绝对值。\n最终的PyTorch和Jax分别的测试集RMSE为\n\nmetrics[-1]['test_rmse'], jmetrics[-1]['test_rmse']\n\n\n\n\n\n(0.9441459774971008, 0.9783037304878235)\n\n\n\n我们对上面的图进行一些分析：\n\nLoss和Train RMSE 的趋势是一致的，因为他们之间是平方关系；他们随着训练时间的增加而减小，一开始减小的速度比较快，后面变化趋于平缓。\nDelta Loss 也随着时间逐渐减小。\nTest RMSE 一开始先是快速降低，随后缓慢降低，最后反而开始上升。这就说明到了后期出现了过拟合现象，测试损失反而在上升。可以使用 Early Stop等方法缓解此问题。\nJax 和 PyTorch 的曲线趋势相似，但是初值不相同，这个问题我们已经在上文中详细讨论，这里不再赘述。\n\n\n\n5.11 3.b 矩阵分解参数调优\n\n5.11.1 科学调参的原则与方法\n我在以前的作业当中详细描述了谷歌AI团队《深度学习调优指南》的思想，涉及到的概念包括目标元参数、冗余元参数和固定元参数，贝叶斯优化、演化计算、近似随机搜索，科学实验的控制变量法与调参实验设计中的探索与利用等。这里我们不再赘述，需要的话可以阅读这次作业的文档 以及 谷歌Deep Learning Tuning Playbook原文。\n简单总结来说，调参的本质是进行科学实验，通过控制变量法，探究在冗余和固定元参数（a.k.a. 无关变量）搜索到最优或者保持固定时，目标元参数（a.k.a. 目标超参数、自变量）对因变量（a.k.a. 评价指标）的影响。\n而对于调参实验的结果，我们可以使用我们这门课当中学习的假设检验方法，来探究目标元参数的取值（比如选择自己提出的方法还是其他人的方法）之间导致因变量的差异是否具有统计显著性，以及哪一个元参数的取值最好。这个可以参考我们上一次作业ANOVA的文档，这里我们同样不再赘述。\n\n\n5.11.2 搜索空间定义\n本次作业中，我们可以认为 k 的取值是 目标元参数，我们实验的目的就是探究 不同k的取值对于矩阵分解的效果有何影响。直观地来说，k越大，我们矩阵可以容纳的秩就越大，表达能力就更强，应当具有更好的分解效果，这是我们的实验假设。具体而言，k决定了模型参数的大小，而李航《统计学习方法》中介绍的泛化误差上界定理，Open AI 对 LLM 探究的 Scaling Law 都指出模型参数和模型的泛化误差具有重要的关系。我们通过本次调参实验可以尝试看看有无类似的规律。\n而 \\(\\lambda\\) 以及 学习率 lr 的取值则是 冗余元参数 或者 固定超参数。由于作业要求我们搜索 \\(\\lambda\\)，所以它是 冗余元参数，我们需要为每一个 k 的取值搜素它的值调到最优，而为了节省计算资源，lr则可以当做固定超参数。为了提高实验速度，我们把required_delta_loss设的比上一节要大一些，并且使用 jax 来做分解。\n为了定义搜索空间，我们使用dataclass，要求传入函数的参数是强类型，而且有一个随机概率分布，这样方便定义调参。这里用到我自己写的scholarly_infrastructure库的一个核心功能experiment_setting，对Python标准的dataclass进行了改进。\n\nsource\n\n\n\n5.12 MatrixFactorizationSetting\n\n MatrixFactorizationSetting (k:int=20, lmd:float=0.001, lr:float=0.005,\n                             required_delta_loss:float=0.001)\n\n\n\nExported source\nfrom scholarly_infrastructure.rv_args.nucleus import RandomVariable, experiment_setting\nfrom optuna.distributions import IntDistribution, FloatDistribution, CategoricalDistribution\nfrom typing import Optional, Union\nfrom dataclasses import asdict\nimport optuna\n\n\n\n\nExported source\n@experiment_setting\nclass MatrixFactorizationSetting:\n    # 隐因子数量 k\n    k: int = ~RandomVariable( # ~ 表示 服从 这个分布，这是我写的库实现的语法糖\n        default=20,\n        description=\"Number of latent factors.\",\n        # distribution=IntDistribution(low=1, high=128, log=True) # 我们假设 k 和 RMSE满足某种“scaling law”，所以使用 log 分布。\n        distribution=CategoricalDistribution([1, 4, 16, 64]) \n        )\n    \n    # 正则化参数 λ\n    lmd: float = ~RandomVariable(\n        default=0.001,\n        description=\"Regularization parameter.\",\n        distribution=FloatDistribution(0.001, 0.1, log=True)\n    )\n    \n    # 学习率\n    lr: float = ~RandomVariable(\n        default = 5e-3, \n        description=\"Learning rate.\",\n        distribution=FloatDistribution(1e-4, 1e-1, log=True) # 虽然本次我们实验不调，但是其固有分布也是要写清楚的，下次实验或许要调。\n    )\n    \n    # 精度要求\n    required_delta_loss: float = ~RandomVariable(\n        default = 1e-3, \n        description=\"Required Delta Loss, a.k.a. tolerance\",\n        distribution=FloatDistribution(1e-8, 1e-1, log=True)\n    )\n\n\n\n# 可以展示文档， MatrixFactorizationSetting 是一个 dataclass，也是一个 experiment_setting\nMatrixFactorizationSetting.show_dataframe_doc()[:1]\n\n\n\n\n\n\n\n\n\n\n\nname\ntype\ndefault\ndefault_factory\ninit\nrepr\nhash\ncompare\nmetadata\nkw_only\ndescription\ndistribution\n\n\n\n\n0\nk\n&lt;class 'int'&gt;\n20.0\n&lt;dataclasses._MISSING_TYPE object at 0x7ef6e43...\nTrue\nTrue\nNone\nTrue\nNone\n&lt;dataclasses._MISSING_TYPE object at 0x7ef6e43...\nNumber of latent factors.\nCategoricalDistribution(choices=(1, 4, 16, 64))\n\n\n\n\n\n\n\n固定元参数定义\n\n\nExported source\nfixed_meta_params = MatrixFactorizationSetting(lr=5e-3, # surprise库的值\n                                               required_delta_loss=1e-4)\nfrozen_rvs = {\"lr\", \"required_delta_loss\"}\n\n\n\n5.12.1 定义目标函数\n由于我们数据不是很多，我们直接就使用 测试集作为验证集，允许使用验证集来进行模型选择（包括调参、Early Stopping等）。\n\nsource\n\n\n\n5.13 objective\n\n objective (trial:optuna.trial._trial.Trial, critical_metric='test_rmse')\n\n\n\nExported source\ndef objective(trial:optuna.Trial, critical_metric=\"test_rmse\"):\n    # experiment_setting 类具有 optuna_suggest 方法，可以自动推荐一个设置出来。\n    config:MatrixFactorizationSetting = MatrixFactorizationSetting.optuna_suggest(\n        trial, fixed_meta_params, frozen_rvs=frozen_rvs)\n    # 调用上面写好的 train_matrix_factorization_jax 函数\n    jmodel, jmetrics = train_matrix_factorization_jax(X_train_dense, X_test_dense, \n                                              trial=trial, critical_metric=critical_metric, # 为了进行搜索剪枝，传入这两个参数\n                                              **asdict(config))\n    # 假如采取最后的\n    # best_metric = jmetrics[-1][critical_metric]\n    # 假如允许 Early Stop\n    best_metric = min(map(lambda m: m[critical_metric], jmetrics))\n    return best_metric\n\n\n\n5.13.1 执行调参搜索\n\n\nExported source\nfrom thu_big_data_ml.help import runs_path\nfrom optuna.samplers import *\nfrom optuna.pruners import *\nimport json\n\n\n\n\nExported source\nstudy_path = runs_path / \"optuna_studies.db\"\nsqlite_url = f\"sqlite:///{study_path}\"\n\n\n\n\nExported source\nstudy = optuna.create_study(\n    study_name=\"matrix factorization hpo 11.27 4.0\", # 3.0 使用 1e-3\n    storage=sqlite_url, \n    load_if_exists=True, \n    # sampler=QMCSampler(seed=42), # 谷歌建议\n    sampler=TPESampler(seed=42), # 谷歌建议\n    pruner=HyperbandPruner(), # 通过中间结果来决定是否停止搜索\n    direction=\"minimize\")\nstudy.set_user_attr(\"contributors\", [\"Ye Canming\"])\nstudy.set_user_attr(\"fixed_meta_parameters\", json.dumps(asdict(fixed_meta_params)))\n\n\n[I 2024-11-27 21:57:31,990] A new study created in RDB with name: matrix factorization hpo 11.27 4.0\n\n\n接下来运行\n\nstudy.optimize(objective, n_trials=10)\n\n\nstudy.optimize(objective, n_trials=30)\n\n\nstudy.optimize(objective, n_trials=20)\n\n\n\n5.13.2 分析实验结果\n首先加载调参实验的结果，实验分析的时候，不用重新再跑一次实验，这两个是分开的\n\nstudy = optuna.load_study(\n    study_name=\"matrix factorization hpo 11.27 4.0\", \n    storage=sqlite_url)\n\n\n5.13.2.1 最好的参数组合是哪个？\n\nstudy.best_value, study.best_params\n\n\n\n\n\n(0.9159189462661743, {'k': 16, 'lmd': 0.07791470666172784})\n\n\n\n\n\n5.13.2.2 Optuna 可视化分析结果\n可以通过下面的命令对我们刚才保存调参结果的数据库文件进行可视化展示：\noptuna-dashboard sqlite:///optuna_studies.db --port 18081\n\n\nfrom optuna.visualization import plot_intermediate_values\nfrom optuna.visualization import plot_param_importances\nfrom optuna.visualization import plot_optimization_history\n\n\nplot_optimization_history(study)\n\n                                                \n\n\n我们进行了60次实验，随着实验的进行，目标函数越来越好。注意有很多实验因为被提前剪枝了所以没有在图中显示出来，这些实验的目标函数值太大了，不会优于显示在图中的实验。\n\nplot_intermediate_values(study)\n\n                                                \n\n\n图中我们可以看出，不同的实验的loss下降曲线是有所不同，有的曲线是向上凸的。\n\nplot_param_importances(study)\n\n                                                \n\n\n从这个图我们可以发现，相比于正则化项 lambda的取值，k的取值明显对泛化性能更加重要。\n\n\n5.13.2.3 以 k 为目标元参数进行假设检验分析——期望改进分析\n期望改进分析是说如果有多个方法可以选择的时候，我提出的方法随机地应用于某一个人使用的元参数组合时，我的方法的期望性能相比于采纳其他方法，是否显著地更好。\n\n# 首先我们拿到实验的所有数据\ndf = study.trials_dataframe()\ndf.head()\n\n\n\n\n\n\n\n\n\n\n\nnumber\nvalue\ndatetime_start\ndatetime_complete\nduration\nparams_k\nparams_lmd\nuser_attrs_delta_loss\nuser_attrs_loss\nuser_attrs_test_rmse\nuser_attrs_train_rmse\nsystem_attrs_completed_rung_0\nsystem_attrs_completed_rung_1\nsystem_attrs_completed_rung_2\nsystem_attrs_completed_rung_3\nsystem_attrs_completed_rung_4\nsystem_attrs_completed_rung_5\nsystem_attrs_completed_rung_6\nstate\n\n\n\n\n0\n0\n0.961816\n2024-11-27 21:57:37.217204\n2024-11-27 21:58:54.987898\n0 days 00:01:17.770694\n4\n0.002051\n0.000100\n0.916142\n0.961816\n0.957153\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nCOMPLETE\n\n\n1\n1\n0.919173\n2024-11-27 21:58:55.112755\n2024-11-27 22:01:19.734468\n0 days 00:02:24.621713\n16\n0.026070\n0.000100\n0.805639\n0.919173\n0.897574\n2.309793\n2.299495\n2.269680\n2.190724\n2.011784\n1.097557\n0.927841\nCOMPLETE\n\n\n2\n2\n1.117243\n2024-11-27 22:01:20.259350\n2024-11-27 22:01:49.182465\n0 days 00:00:28.923115\n4\n0.002310\n0.007060\n1.239060\n1.117243\n1.113131\n2.021852\n2.018061\n2.007246\n1.979886\n1.928901\n1.117243\nNaN\nPRUNED\n\n\n3\n3\n0.920926\n2024-11-27 22:01:49.277027\n2024-11-27 22:04:11.261289\n0 days 00:02:21.984262\n16\n0.003823\n0.000100\n0.809304\n0.920926\n0.899613\n2.299917\n2.270888\n2.193796\n2.017946\n1.108612\n0.929011\nNaN\nCOMPLETE\n\n\n4\n4\n1.533228\n2024-11-27 22:04:17.347049\n2024-11-27 22:04:40.633025\n0 days 00:00:23.285976\n1\n0.008168\n0.013748\n2.349351\n1.533228\n1.532759\n1.921702\n1.920640\n1.917642\n1.910277\n1.898259\n1.533228\nNaN\nPRUNED\n\n\n\n\n\n\n\n\n# 用于后续指定列进行分析\ntarget = \"value\" # 实际上是 test_rmse\ntreatment = \"params_k\"\n\n\n# 只需要分析表格中我们感兴趣的列\nintersted_cols = [c for c in df.columns if c.startswith(\"params\") or \"user_attrs\" in c or c==\"value\"]\ndfi = df[intersted_cols].dropna(subset=[target])\ndfi[treatment] = dfi[treatment].astype(\"int\")\ndfi.head()\n\n\n\n\n\n\n\n\n\n\n\nvalue\nparams_k\nparams_lmd\nuser_attrs_delta_loss\nuser_attrs_loss\nuser_attrs_test_rmse\nuser_attrs_train_rmse\n\n\n\n\n0\n0.961816\n4\n0.002051\n0.000100\n0.916142\n0.961816\n0.957153\n\n\n1\n0.919173\n16\n0.026070\n0.000100\n0.805639\n0.919173\n0.897574\n\n\n2\n1.117243\n4\n0.002310\n0.007060\n1.239060\n1.117243\n1.113131\n\n\n3\n0.920926\n16\n0.003823\n0.000100\n0.809304\n0.920926\n0.899613\n\n\n4\n1.533228\n1\n0.008168\n0.013748\n2.349351\n1.533228\n1.532759\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\n\nfig, ax = plt.subplots()\nax.set_xscale('log')\n# sns.boxplot(data=dfi, x=treatment, y=target, ax=ax)\ndfi.plot(x=treatment, y=target, ax=ax, kind='scatter', c='red')\n\n\n不同k的RMSE箱线图对比\n\n\n\n&lt;Axes: xlabel='params_k', ylabel='value'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndfi.boxplot(by=treatment, column=target)\n\n\n\n\n\n&lt;Axes: title={'center': 'value'}, xlabel='params_k'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们首先画出了散点图和箱线图，可以直观感觉到，k小的时候，test_rmse的上界反而更小，而平均值则是在k=4时取最好。\n现在我们来画经验分布图，包括没有分组前和分组之后的数据的分布图。\n\nsns.displot(data=dfi, x=target, kde=True, kind=\"hist\")\nplt.ylabel(\"频数\")\nplt.xlabel(\"test_rmse\")\nsns.displot(data=dfi, x=target, hue=treatment, kde=True, kind=\"hist\")\nplt.ylabel(\"频数\")\nplt.xlabel(\"test_rmse\")\n\n\n\n\n\nText(0.5, 9.444444444444438, 'test_rmse')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n刚才进行了可视化分析，现在进行严格的假设检验。\n我们在同时比较多个方法，可以用上一次作业的ANOVA检验吗？ 由于我们使用了nbdev系统，我上次写作业的代码已经变成了成熟的python模块，我们可以直接调用我之前写的代码，看看ANOVA的条件是否满足。 由于上次写的test_normality_group需要大量数据才有效，我们需要换别的假设检验。\n\nsource\n\n\n\n\n5.14 test_normality_small_sample\n\n test_normality_small_sample (df, interesting_col, hue_col='群类别',\n                              transform=None)\n\n\n\nExported source\nfrom thu_big_data_ml.big_data_analytics.anova import test_normality_group, homogeneity_of_variance\nfrom scipy import stats\nfrom statsmodels.stats.diagnostic import lilliefors\nfrom thu_big_data_ml.big_data_analytics.anova import auto_anova_for_df, auto_kruskal_for_df\n\n\n\n\nExported source\n# 根据上次我们ANOVA作业调研的结果， Shapiro-Wilk 和 Lilliefors 是适合小样本情况下的正态检验方法。\ndef test_normality_small_sample(df, interesting_col, hue_col='群类别', transform=None):\n    if transform is None:\n        transform = lambda x: x\n    grouped_data = df.groupby(hue_col)\n    normality_results = {}\n    for name, group in grouped_data:\n        normality_result = {}\n        data_column = group[interesting_col].to_numpy()\n        data_column = transform(data_column)\n        \n        # Shapiro-Wilk test\n        res = stats.shapiro(data_column)\n        normality_result['Shapiro-Wilk'] = \"Not Normal\" if res.pvalue &lt; 0.05 else \"Normal\"\n        \n        # Lilliefors test \n        res = lilliefors(data_column)\n        normality_result['Lilliefors'] = \"Not Normal\" if res[1] &lt; 0.05 else \"Normal\"\n        \n        normality_results[name] = normality_result\n    return pd.DataFrame(normality_results)\n\n\n\ntest_normality_small_sample(dfi, interesting_col=target, hue_col=treatment)\n\n\n\n\n\n\n\n\n\n\n\n1\n4\n16\n64\n\n\n\n\nShapiro-Wilk\nNot Normal\nNot Normal\nNot Normal\nNot Normal\n\n\nLilliefors\nNormal\nNot Normal\nNot Normal\nNot Normal\n\n\n\n\n\n\n\n\nhomogeneity_of_variance(dfi, interesting_col=target, hue_col=treatment)\n\nThe variances are not homogeneous!\n\n\n\n\n\n\n{\n    'ratio_largest_to_smallest': 2.158185623471692,\n    'bartlett_result': BartlettResult(statistic=3.6668498840499297, pvalue=0.29975821213270615)\n}\n\n\n\n对于正态性，k=1的时候根据Lilliefors检验，是正态分布，其他情况下拒绝了是正态分布的假设。 对于方差齐性，根据拇指法则，方差不齐，但是根据假设检验，方法齐性满足。\n那么我们可以勉强使用。\n\nauto_anova_for_df(dfi, interesting_col=target, hue_col=treatment)\n\n\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares (SS)\nDegrees of Freedom (df)\nMean Square (MS)\nF\np\np_excel\n\n\n\n\n0\nBetween\n6.865326\n3\n2.288442\n8.42717\n0.000103\n0.000103\n\n\n1\nWithin\n15.207092\n56\n0.271555\nNaN\nNaN\nNaN\n\n\n2\nTotal\n22.072418\n59\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n尽管ANOVA的使用条件不满足，但是我们勉强使用ANOVA，可以看到ANOVA方法的p值很小，很显著地不同k之间存在显著差异！\n接下来我们使用 Kruskal-Wallis 检验，这个检验不需要方差齐性和正态性满足，就可以对多列样本进行比较。\n\nres = auto_kruskal_for_df(dfi, interesting_col=target, hue_col=treatment)\nif res.pvalue &lt; 0.05:\n    print(f\"There is a significant difference between the different {treatment}.\")\nres\n\nWed 2024-11-27 23:14:42.491233\n\n\n\nINFO     There is a significant difference between the different params_k.                            nucleus.py:53\n\n\n\n\n\n\n\nKruskalResult(statistic=21.605648342166887, pvalue=7.879126651465415e-05)\n\n\n\nKruskal-Wallis H-test tests的零假设是 不同组的中位数之间没有显著差异。看来我们可以拒绝原假设，认为不同k的矩阵分解的RMSE的中位数有显著差异。\n刚才我们检验出来存在显著差异，但是不知道具体是谁比谁大有显著性，所以我们还需要使用post-hoc类型的假设检验来进行进一步的分析。\n首先刚才检验的是中位数有显著差异，我们来求一下分组的中位数。\n\n# 分组中位数\nmedians = df.groupby(treatment)[target].median().sort_values(ascending=True)\norder = medians.index[:] # 中位数的排序\nmedians\n\n\n\n\n\nparams_k\n4     1.111837\n1     1.726936\n16    2.309724\n64    2.931462\nName: value, dtype: float64\n\n\n\nDunn’s test就是针对 Kruskal-Wallis one-way analysis 对应的 post-hoc 检验方法（之一，还有其他的）。\n\n\nExported source\nimport scikit_posthocs as sp\nfrom scikit_posthocs import posthoc_dunn\n\n\n\nres = posthoc_dunn(dfi, val_col=target, group_col=treatment, \n             sort=True, p_adjust='holm')\n\n# 按照中位数大小排序\nres = res.reindex(order)\nres = res[order]\nres\n\n\n\n\n\n\n\n\n\n\n\n4\n1\n16\n64\n\n\nparams_k\n\n\n\n\n\n\n\n\n4\n1.000000\n0.835664\n0.033024\n0.000609\n\n\n1\n0.835664\n1.000000\n0.035515\n0.000703\n\n\n16\n0.033024\n0.035515\n1.000000\n0.035515\n\n\n64\n0.000609\n0.000703\n0.035515\n1.000000\n\n\n\n\n\n\n\n\n# 对 post hoc检验的结果进行热力图可视化\nheatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\nsp.sign_plot(res, **heatmap_args)\n\n\n\n\n\n(&lt;Axes: ylabel='params_k'&gt;, &lt;matplotlib.colorbar.Colorbar object at 0x7ef55c5e1b40&gt;)\n\n\n\n\n\n\n\n\n\n\n\n\n\n从结果表可以看出，k=4和k=1的矩阵分解方法都非常显著地优于k=16和k=64的方法，是最好的两个参数。而k=16又显著地由于k=64的情况。而k=4和k=1之间，由于实验数据不足，无法得出明确的结论。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#基于用户的协同过滤方法与矩阵分解算法的结果与优缺点对比",
    "href": "coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html#基于用户的协同过滤方法与矩阵分解算法的结果与优缺点对比",
    "title": "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用",
    "section": "6 4. 基于用户的协同过滤方法与矩阵分解算法的结果与优缺点对比",
    "text": "6 4. 基于用户的协同过滤方法与矩阵分解算法的结果与优缺点对比\n\n6.1 理论上的优缺点对比\n《深度学习推荐系统》一书中对这两个方法都有所介绍，其中提到一些观点，这里我阅读总结如下，其中括号部分是我针对本次项目情况的思考和疑惑\n基于用户的协同过滤方法(UserCF)的优缺点\n\n优点：符合人们直觉上的“兴趣相似的朋友喜欢的物品，我也喜欢”的思想。因为是基于用户的相似度来进行推荐。书上认为这个方法非常直观、可解释性很强。（本次Netflix数据集就是假设其他和我对电影评分相似的朋友评价过的电影如果我去看也会有相似的评分）\n缺点：用户相似度矩阵的存储开销非常大。在实际的互联网应用中，用户数远远大于物品数（？一定是这样吗，根据分析报告, 淘宝用户数量是10亿，而2000万商家的商品数量是数十亿，不好说谁比谁多），为了快速找到最相似的n个用户，需要存储用户相似度矩阵（？真的是这样吗，KD树、FAISS等数据结构可以很高效地找到k近邻），因为用户数数以亿计，所以这个相似度矩阵很大，随着用户的增长以\\(n^2\\)的速度快速增长，系统难以承受。（本次数据集中，物品是电影，数量和用户一样多，相似度矩阵确实很大）\n缺点：新用户推荐问题。用户的历史数据向量是稀疏的，而对于一个只有几次购买记录的新用户来说，很难找到和他相似的用户。不只是新用户，如果正反馈获取是很困难的应用场景，比如酒店预订和大件商品预订，所有用户都很稀疏，互相之间的相似度都很低。\n优点：推荐具有社交属性，可以让用户快速得知兴趣相似的人喜欢什么，比较适合新闻推荐场景。因为不同人的新闻兴趣点比较分散，所以新闻的及时性和热点性比用户对新闻的兴趣偏好更重要（？所以这不就说明UserCF没有用吗，为什么王喆这里说userCF能发现和追踪热点呢）。\n缺点：对于兴趣变化稳定的应用不太适合。比如电商场景中，某段时间内用户会倾向于某一类热点商品，这个时候商品向量的相似度比用户向量的相似度是更加有价值的。（本次数据集NetFlix属于这个场景，因为看电影的评分是相对固定的偏好）\n缺点：泛化能力较差，因为无法把两个用户或者物品相似信息推广到其他用户和其他物品的相似上，导致新用户或者冷门物品太过稀疏，很少被推荐。\n缺点：只能利用共现矩阵也就是用户和物品的评分交互信息，无法有效引入用户年龄、性别，商品类别、描述等额外的信息，相比逻辑回归等机器学习模型而言使用的信息太少，所以泛化能力有限。（本次项目当中，Netflix数据集就包括了电影的标题信息，如果进行自然语言处理提取特征，可以提升推荐效果）\n\n矩阵分解技术的优缺点\n\n优点：泛化能力相对协同过滤更好。使用稠密的隐向量来表示用户和物品，所以可以挖掘到用户的隐含兴趣和物品的潜在特征，可以弥补协同过滤处理稀疏矩阵能力不足的问题。\n缺点：和协同过滤的缺点7一样，也只是利用了共现矩阵的信息，没有利用到其他信息。\n缺点：王喆指出，k越大，隐向量的表达能力越强，但是容易过拟合，所以泛化能力会相应降低。所以工程中需要多次实验才能找到最优的k值。\n优点：相比协同过滤，空间复杂度低，因为不需要存储mxm的相似度矩阵，只需要存储用户和物品的隐向量。（本次项目中 MatrixFactorization model 的参数量确实是比协同过滤的小）\n优点：更好的扩展性和灵活性。矩阵分解的最终产出是用户和物品的隐向量矩阵，与深度学习中的Embedding思想不谋而合（真的一样吗），因此矩阵分解的结果也非常便于与其它特征进行组合和拼接，并便于与深度学习网络进行无缝结合。\n\n\n\n6.2 实验结果比较\n我们可以来看看实验结果是否支持上面的理论分析。\n协同过滤方法我们得到的训练集RMSE是1.0127, 测试集RMSE是1.0184。\n对于给定 k=50, λ=0.01 的情况下，使用lr=5e-3, required_delta_loss=1e-6，Pytorch和 jax 在训练集上的RMSE是分别是6.760268e-01和8.220364e-01, 测试集上的RMSE分别是 9.441460e-01和9.783037e-01，\n在没有进行调参的情况下，矩阵分解的性能轻松超越了协同过滤方法，在训练集和测试集上都更小，可见矩阵分解的表达能力和泛化能力都优于协同过滤，确实符合理论分析中所说，使用稠密的隐向量表示用户和物品是可以挖掘到用户的隐含兴趣和物品的潜在特征的，弥补了协同过滤能力不足的问题。\n在实现协同过滤的时候，我们确实进行了多次优化，才成功计算出最后的推荐值，而且整个系统中最慢的步骤和存储量最大的步骤就是求解相似度矩阵，即使使用了sklearn的方法进行了稀疏矩阵相似度的优化，还是耗费了十多分钟的时间，相比矩阵分解实验所需要的时间长，存储量也大，符合理论分析中协同过滤的第二点和矩阵分解的第四点。\n\nmetrics_df.iloc[-1], jmetrics_df.iloc[-1]\n\n\n\n\n\n(\n    loss          2.285061e-01\ntrain_rmse    6.760268e-01\ntest_rmse     9.441460e-01\ndelta_loss    9.992896e-07\nName: 8898, dtype: float64,\n    loss          6.757439e-01\ntrain_rmse    8.220364e-01\ntest_rmse     9.783037e-01\ndelta_loss    8.344650e-07\nName: 5503, dtype: float64\n)\n\n\n\n而在lr=5e-3, required_delta_loss=1e-4条件下，搜索k和λ我们发现，λ对于RMSE的影响不大，而k的影响却很大。我们通过严格的假设检验分析，发现了k=1和k=4的矩阵分解方法显著优于k=16和k=64的矩阵分解方法，而k=16的矩阵分解方法又显著地优于k=64的矩阵分解方法。从平均值来看，k=4的RMSE比k=1的RMSE要小，但是缺乏统计学证据，差异并不显著。\n由此可以验证矩阵分解理论分析第三点，即 k越大，隐向量的表达能力越强，但是容易过拟合，所以泛化能力会相应降低。所以k=4在我们这次实验中是折中的最优最优选择。可见，在实际工程应用中，需要调解k这个元参数是矩阵分解算法的一个缺点。我们使用optuna调参也消耗了大量的时间，即使使用了最先进的Tree Prazen优化方法和Hyperband剪枝方法。\n刚才我们做的调参分析是期望改进分析，是说参数随机选取的情况下，哪个k期望的性能最好。如果参数不是随机选取，而是通过调参优化到最优呢？这也是一个公平比较各个方法的另外一个分析手段。我们列出下表：\n\n# 其他无关变量调到最优时，目标自变量对指标的影响。\nbest_rows = dfi.loc[dfi.groupby(treatment)[target].idxmin()]\nbest_rows[['params_k', 'user_attrs_test_rmse', 'user_attrs_train_rmse', 'user_attrs_delta_loss']]\n\n\n\n\n\n\n\n\n\n\n\nparams_k\nuser_attrs_test_rmse\nuser_attrs_train_rmse\nuser_attrs_delta_loss\n\n\n\n\n7\n1\n0.958201\n0.956666\n0.0001\n\n\n0\n4\n0.961816\n0.957153\n0.0001\n\n\n15\n16\n0.915919\n0.893912\n0.0001\n\n\n6\n64\n0.937775\n0.851572\n0.0001\n\n\n\n\n\n\n\n如上表所示，随着k的增大，train_rmse 会变小，所以说k越大，模型的表达能力越强。而对于test_rmse，在最优参数的情况下，k=16是最小的，而不是k=64最小。因而k=16在调参到最优的情况下，即具有k=1和k=4不具备的表达能力，也可以避免像k=64那样过拟合。\n综上所述，我们的实验结果基本支持书上给出的分析，我们通过本次实验深入了解了两种方法的实现细节和性能差异，受益匪浅。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "coding_projects",
      "big_data_analytics",
      "P2_Matrix-Decomposition",
      "深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用"
    ]
  },
  {
    "objectID": "theory_assignments/A2/p_assignment2_yecanming.html#sec-1",
    "href": "theory_assignments/A2/p_assignment2_yecanming.html#sec-1",
    "title": "大数据机器学习课程第二次作业",
    "section": "1 第一题",
    "text": "1 第一题\n题目如下\n\nMinsky与Papert指出：感知机因为是线性模型，所以不能表示复杂的函数，如异或(XOR)。验证感知机为什么不能表示异或。\n\n\n\n\n\n\n\n注记\n\n\n\nTL; DR 前面审题内容较长，学习了一些这道题的一些背景知识方便理解。 对于题目的证明，可以直接跳到解题部分@sec-proof。\n\n\n\n\n\n\n\ngraph LR\n    A[马文-明斯基]\n    B[美国科学家]\n    C[人工智能之父]\n    D[专长于认知科学]\n    E[与麦卡锡共同发起达特茅斯会议]\n    F[提出人工智能概念]\n    G[框架理论创立者]\n    H[出生-1927年8月9日]\n    I[逝世-2016年1月24日]\n    J[西蒙-派珀特]\n    K[美国麻省理工学院终身教授]\n    L[教育信息化奠基人]\n    M[数学家-计算机科学家-心理学家-教育家]\n    N[近代人工智能领域先驱者之一]\n    O[逝世-2016年7月31日]\n\n    A---B\n    A---C\n    A---D\n    A---E\n    A---F\n    A---G\n    A---H\n    A---I\n    J---K\n    J---L\n    J---M\n    J---N\n    J---O\n\n\n\n\n\n\n\n\n\n他们在什么时候，什么地方指出了上述观点？\n\n在1969年，Minsky和Papert发表了《Perceptrons》一书，探讨了单层感知器的局限性，特别是无法解决线性不可分问题，例如异或问题。 (Marvin 和 Seymour 1969)。这本书从理论上否定了神经网络的研究价值，并对神经网络的发展产生了深远的影响。\n\n\n\n\n\n\n\n\n注记\n\n\n\nMinsky和Papert的观点导致了神经网络研究进入低迷期。而实际上Minsky本人并没有看衰神经网络，只是他的书被人误解以为神经网络一无是处。实际上他写书的时候，MLP的训练算法已经出现了，但是他在书中没有提及(人民邮电出版社 2020)。\n\n\n\n1.1 解题\n\n1.1.1 感知机是什么？感知机是线性模型吗？\n根据李航课本内容(李航 2019)，感知机是一种简单的线性二分类模型，由Rosenblatt在1957年提出。它的数学形式可以表示为：\n\\[ f(x) = sign(w \\cdot x + b)\n\\tag{1}\\]\n在 式 1 中，\\(w\\) 和 \\(b\\) 是模型参数，\\(x\\) 是输入向量，\\(sign\\) 是符号函数，\\(f(x)\\) 是模型输出, f就是感知机。\n\\(f(x)\\) 本身当然不是一个线性函数，因为他输出的是一个决策。 我们换一个角度思考，我们有线性方程式 2 \\[  w \\cdot x + b =0\n\\tag{2}\\] 式 2表示了输入空间中的一个超平面， \\(w\\) 和 \\(b\\) 是该超平面的法向量和截距。 这个超平面能把输入空间划分为两部分，分为正类和负类，称为分离超平面。 线性方程表示了超平面，所以我们说感知机是线性模型。\n\n\n代码\nfrom sklearn.datasets import make_blobs\nfrom sklearn.linear_model import Perceptron\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# 生成线性可分的数据集\nX, y = make_blobs(n_samples=100, centers=2, n_features=3, random_state=42)\n\n# 使用感知机模型进行学习\nclf = Perceptron(random_state=42, max_iter=1000)\nclf.fit(X, y)\n\n# 获取感知机的权重和偏置\nw = clf.coef_[0]\nb = clf.intercept_[0]\n\n# 创建一个3D图形来展示数据和感知机超平面\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# 绘制数据点\nax.scatter(X[y == 0][:, 0], X[y == 0][:, 1], X[y == 0][:, 2], color='red', label='Class 0')\nax.scatter(X[y == 1][:, 0], X[y == 1][:, 1], X[y == 1][:, 2], color='blue', label='Class 1')\n\n# 计算超平面上的两个点用于绘制超平面\nxx, yy = np.meshgrid(range(-10, 11), range(-10, 11))\nzz = (-b - w[0] * xx - w[1] * yy) / w[2]\n\n# 绘制感知机超平面\nax.plot_surface(xx, yy, zz, alpha=0.2)\n\n# 设置图形属性\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.set_zlabel('X3')\nax.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.1.2 异或函数是什么呢？\n异或（XOR）是一个布尔函数，它返回两个输入值不同则为真（1），相同则为假（0）。 数理逻辑中分为模型论和证明论，我们从模型论的角度来说异或函数可以直接真值表表示如下：\n\n\n\n\n\n\n\n\nA\nB\nXOR(A, B)\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n0\n1\n\n\n1\n1\n0\n\n\n\n\n\n1.1.3 异或函数和分类问题的关系？\n这里我们在关注感知机能不能表示异或函数。所以我们要先把异或问题广义化为二分类问题，输入的A、B两个特征，原本AB的类型是bool，现在我们扩展一下认为异或的输入AB可以是任何实数。而原本输出的0和1正好对应正例和负例，感知机的\\(sign\\)也是输出0或者1，所以我们可以把异或问题转化为感知机的二分类问题。 其他实数上异或的结果仍然是0或者1，但是无论模型输出什么都认为是正确的就好。 我们可以可视化一下现在的异或问题\n\n\n代码\n# 绘制异或（XOR）函数的图像\n\n# XOR函数的数据点\nx = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([0, 1, 1, 0])\n\n# 创建图形和轴\nfig, ax = plt.subplots()\n\n# 绘制数据点\nax.scatter(x[y == 0][:, 0], x[y == 0][:, 1], color='red', label='0')\nax.scatter(x[y == 1][:, 0], x[y == 1][:, 1], color='blue', label='1')\n\n# 设置图形属性\nax.set_xlim(-0.5, 1.5)\nax.set_ylim(-0.5, 1.5)\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.legend()\nax.set_title('XOR Function')\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.1.4 验证感知机为什么不能表示异或\n要验证感知机不能表示异或，我们需要证明： &gt; 不\\(\\exists\\)一个\\(w\\)和\\(b\\), 使得\\(f(x) = \\text{sign}(w^Tx + b)\\)可以完美分离异或二分类问题的正负实例。\n我们可以使用反证法来证明这个结论。 假设存在权重 $ w_1, w_2 $ 和偏置 $ b $ 可以表示异或函数，那么对于异或函数的每个输入组合，感知机的输出应该满足以下条件：\n\n$ w_1 + w_2 + b $ （对应于点（0,0），输出应为0，sign里面的值应该小于0）\n$ w_1 + w_2 + b &gt; 0 $ （对应于点（0,1），输出应为+1）\n$ w_1 + w_2 + b &gt; 0 $ （对应于点（1,0），输出应为+1）\n$ w_1 + w_2 + b $ （对应于点（1,1），输出应为0）\n\n我们来化简一下这些不等式，我们使用sympy库来进行符号运算：\n\n\n代码\nimport sympy as sp\nfrom IPython.display import display, Latex\n\n# 定义变量\nw1, w2, b, x1, x2 = sp.symbols('w_1 w_2 b x_1 x_2')\n\n# XOR函数的四个点\npoints = [(0, 0, -1), (0, 1, 1), (1, 0, 1), (1, 1, -1)]\n\n# 建立不等式\ninequalities = []\nfor x1_val, x2_val, y_val in points:\n    # 感知机模型: sign(w1*x1 + w2*x2 + b)\n    # 对于每个点，根据y_val的正负建立不等式\n    if y_val &gt; 0:\n        inequalities.append(w1*x1_val + w2*x2_val + b &gt; 0)\n    else:\n        inequalities.append(w1*x1_val + w2*x2_val + b &lt;= 0)\n\n# 化简不等式\nsimplified_inequalities = [sp.simplify(ineq) for ineq in inequalities]\n# for ineq in simplified_inequalities:\n#     # display(Latex(sp.latex(ineq)))\n#     print(sp.latex(ineq))\nsimplified_inequalities\n\n\n[b &lt;= 0, b &gt; -w_2, b &gt; -w_1, b &lt;= -w_1 - w_2]\n\n\n我们进一步化简，观察b这个变量\n\n\n代码\nsolutions = sp.solve(simplified_inequalities, b)\nsolutions\n\n\n\\(\\displaystyle b \\leq 0 \\wedge b \\leq - w_{1} - w_{2} \\wedge b &gt; - w_{1} \\wedge b &gt; - w_{2} \\wedge -\\infty &lt; b\\)\n\n\n而由于\n\n\n代码\nfrom sympy.logic.boolalg import simplify_logic\ntherom = (simplified_inequalities[0] & simplified_inequalities[1] & simplified_inequalities[2])&gt;&gt;(~simplified_inequalities[3])\ntherom\n\n\n\\(\\displaystyle \\left(b \\leq 0 \\wedge b &gt; - w_{1} \\wedge b &gt; - w_{2}\\right) \\Rightarrow b &gt; - w_{1} - w_{2}\\)\n\n\n与 \\(b \\leq -w_1-w_2\\) 矛盾，所以假设不成立，原命题成立，即感知机不能表示异或。\n注意上面的逻辑表达式需要一定的推导，直接看是不一定能发现前3式和第4式的矛盾。 1. 首先发现\\(w_1, w_2 \\geq 0\\) 2. 然后发现\\(w_1+b \\gt 0\\) 3. 所以 \\(w_1+w_2+b \\gt 0\\) 4. 所以矛盾。\n因为人工观察不等式其实是启发式地去找矛盾，如果我们一开始不知道异或问题表达不了，我们可能一时看不出来这个问题。 我们可以使用人工智能的一个分支——逻辑智能体（Logical Agent）来进行自动定理发现，能够在形式系统中发现矛盾。\n具体来说，我们要把问题转化为约束可满足问题，然后使用forward/backward chaining、DPLL等算法求解。\n我们先试一下sympy的satisfiable函数，看看能不能求解出这个逻辑表达式。\n\n\n代码\nfrom sympy import symbols, And, Not, Implies\nfrom sympy.logic.boolalg import to_cnf\nfrom sympy.logic.inference import satisfiable\n# 将表达式转换为 CNF\ncnf_expr = to_cnf(And(*[Not(x) for x in simplified_inequalities]))\n\n# 检查逻辑表达式的可满足性\nresult = satisfiable(cnf_expr)\nprint(result)  # 如果表达式不可满足，输出 False\n\n\n{Q.gt(b, -w_1 - w_2): True, Q.le(b, -w_1): True, Q.le(b, -w_2): True, Q.gt(b, 0): True}\n\n\n看来不行，我们换一个库Z3 Theorem Prover，它由Microsoft开发，可以处理多种逻辑，包括线性不等式。\n首先要安装一下这个库，非常简单\n$ pip install z3-solver\n\n\n代码\nfrom z3 import *\nset_param(proof=True)\nctx = Context()\ns = Solver(ctx=ctx, logFile=\"log_theorem_prover.txt\")\nb, w_1, w_2 = Real('b', ctx=ctx), Real('w_1', ctx=ctx), Real('w_2', ctx=ctx)\ns.add(b &lt;= 0)  \ns.add(b &gt; -w_2)  \ns.add(b &gt; -w_1)  \ns.add(b &lt;= -w_1-w_2)\nresult = s.check()\nif result == sat: # 三种可能，sat, unsat, unknown\n    model = s.model()\n    print(model[x])  # 打印出 x 的解\nelse:\n    print(result)\n    print(\"No solution\")\n\n\nunsat\nNo solution\n\n\n\n\n代码\ns.proof()\n\n\nth-lemma(mp(mp(asserted(b &gt; -w_2),\n               trans(monotonicity(rewrite(-w_2 = -1·w_2),\n                                  (b &gt; -w_2) = (b &gt; -1·w_2)),\n                     rewrite((b &gt; -1·w_2) = ¬(b ≤ -1·w_2)),\n                     (b &gt; -w_2) = ¬(b ≤ -1·w_2)),\n               ¬(b ≤ -1·w_2)),\n            rewrite(¬(b ≤ -1·w_2) = ¬(b + w_2 ≤ 0)),\n            ¬(b + w_2 ≤ 0)),\n         mp(mp(asserted(b ≤ -w_1 - w_2),\n               rewrite((b ≤ -w_1 - w_2) =\n                       (b ≤ -1·w_1 + -1·w_2)),\n               b ≤ -1·w_1 + -1·w_2),\n            rewrite((b ≤ -1·w_1 + -1·w_2) =\n                    (b + w_1 + w_2 ≤ 0)),\n            b + w_1 + w_2 ≤ 0),\n         asserted(b ≤ 0),\n         mp(mp(asserted(b &gt; -w_1),\n               trans(monotonicity(rewrite(-w_1 = -1·w_1),\n                                  (b &gt; -w_1) = (b &gt; -1·w_1)),\n                     rewrite((b &gt; -1·w_1) = ¬(b ≤ -1·w_1)),\n                     (b &gt; -w_1) = ¬(b ≤ -1·w_1)),\n               ¬(b ≤ -1·w_1)),\n            rewrite(¬(b ≤ -1·w_1) = ¬(b + w_1 ≤ 0)),\n            ¬(b + w_1 ≤ 0)),\n         False)\n\n\n\n\n代码\n# s.proof()\ns.unsat_core()\n\n\n[]\n\n\n我们可以看到中间的过程\n\n\n代码\nwith open('log_theorem_prover.txt', 'r') as f:\n    content = f.read()\n    print(content)\n\n\n(declare-fun b () Real)\n(assert (&lt;= b 0.0))\n(declare-fun w_2 () Real)\n(assert (&gt; b (- w_2)))\n(declare-fun w_1 () Real)\n(assert (&gt; b (- w_1)))\n(assert (&lt;= b (- (- w_1) w_2)))\n(check-sat)\n\n\n\n\n\n\n1.2 题目扩展问题\n\n1.2.1 异或的“高级版”：奇偶校验问题 Parity Check\n刚才我们只说明了2维情况下感知机有局限性，现在假如我们是当年的Minsky和Papert，我们想要说明更高维度上线性不可分函数有多重要， 而感知机无法解决，我们就能崭露头角，告诉大家神经网络不行。 那么，我们就来看看异或的“高级版”：奇偶校验 Parity Check，这个问题非常重要，比如在早期的神经架构搜索研究中会经常使用(Yao 和 Liu 1997)。 奇偶校验问题的定义是根据被传输的一组二进制代码中“1”的个数是奇数或偶数来进行校验的一种方法。奇偶校验问题本质上是一个非线性问题，因为它涉及到对二进制数据中“1”的个数进行奇偶判断，这超出了感知机模型的线性决策边界能力。\n刚才我们一个个地去看不等式推导矛盾，很低效，现在我们引入线性代数的视角去看待这个问题。 我们要说明的问题其实是， 对于 \\[\nAx \\leq b\n\\] 其中 \\(A\\) 是一个 \\(m \\times n\\) 的矩阵，\\(x\\) 是一个 \\(n \\times 1\\) 的向量，\\(b\\) 是一个 \\(m \\times 1\\) 的向量。这个不等式组表示的是 \\(x\\) 需要满足的所有线性不等式条件。 在\\(A\\)和\\(b\\)满足什么条件的时候不等式不可能成立，而Parity check是否满足这个条件呢？\n实际上，这是简单版的线性规划问题，可以使用单纯形法来求解。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A2",
      "大数据机器学习课程第二次作业"
    ]
  },
  {
    "objectID": "theory_assignments/A2/p_assignment2_yecanming.html#sec-2",
    "href": "theory_assignments/A2/p_assignment2_yecanming.html#sec-2",
    "title": "大数据机器学习课程第二次作业",
    "section": "2 第二题",
    "text": "2 第二题\n题目如下\n\n利用课本例题3.2构造的kd树求点\\(x=(3,4.5)^{T}\\) 的最近邻点。\n\n\n2.1 审题\n例题3.2的内容如下 &gt; 给定二维空间的数据集T，构造一个平衡kd树，并给出其构造过程。\n\n\n代码\nimport numpy as np\nT = np.array([\n    [2, 3],\n    [5, 4],\n    [9, 6],\n    [4, 7],\n    [8, 1],\n    [7, 2],\n])\nT\n\n\narray([[2, 3],\n       [5, 4],\n       [9, 6],\n       [4, 7],\n       [8, 1],\n       [7, 2]])\n\n\n我们使用代码来表示一下构造的过程，并且可视化出来分界线。 首先我们要定义节点类，并且写一个验证函数，维持KD树的性质。\n\n\n代码\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('default')\n\n# 定义KD树的节点类和构建函数\nclass Node:\n    # 一个简单的二叉树\n    def __init__(self, point:np.ndarray, # 点的坐标，是k维向量\n                 left:'Node'=None, # 左子树\n                 right:'Node'=None, # 右子树\n                 axis:int=None # 划分的轴\n                 ):\n        # 维持的性质：在axis这个轴上，左子树的点坐标都小于等于point，右子树的点坐标都大于等于point\n        self.point = point\n        self.left = left\n        self.right = right\n        self.axis = axis\n    def validate(self):\n        # 检验性质：左子树的点坐标都小于等于point，右子树的点坐标都大于等于point\n        if self.left is not None:\n            if not self.left.point[self.axis] &lt;= self.point[self.axis]:\n                return False\n        if self.right is not None:\n            if not self.right.point[self.axis] &gt;= self.point[self.axis]:\n                return False\n        return True\nNode\n\n\n__main__.Node\n\n\n我们直接使用递归的方式来构建KD树\n\n\n代码\ndef build_kdtree(points, depth=0):\n    if not points:\n        return None\n\n    k = len(points[0])  # 假设所有点都有相同的维度\n    axis = depth % k # 轮着划分轴\n\n    points.sort(key=lambda x: x[axis])\n    median = len(points) // 2\n    print(\"\\t\"*depth+f\"我在构建第{depth}层的KD树， 我需要处理的数据量是{len(points)}。我对第{axis}维进行划分，在{points[median][axis]}处分割。\")\n\n    node = Node(\n        point=points[median],\n        left=build_kdtree(points[:median], depth + 1),\n        right=build_kdtree(points[median + 1:], depth + 1),\n        axis=axis\n    )\n    return node\n\n# 定义可视化函数\ndef draw_kdtree(ax, node, depth, min_x, max_x, min_y, max_y, more=0.1):\n    if node is None:\n        return\n\n    # 绘制分割线\n    if node.axis == 0:  # x轴分割\n        ax.plot([node.point[node.axis], node.point[node.axis]], [min_y, max_y], color='black', alpha=0.5 - 0.1 * depth)\n        draw_kdtree(ax, node.left, depth + 1, min_x, node.point[node.axis], min_y, max_y)\n        draw_kdtree(ax, node.right, depth + 1, node.point[node.axis], max_x, min_y, max_y)\n    else:  # y轴分割\n        ax.plot([min_x, max_x], [node.point[node.axis], node.point[node.axis]], color='black', alpha=0.5 - 0.1 * depth)\n        draw_kdtree(ax, node.left, depth + 1, min_x, max_x, min_y, node.point[node.axis])\n        draw_kdtree(ax, node.right, depth + 1, min_x, max_x, node.point[node.axis], max_y)\n    # 设置绘图限制\n    if depth == 0:\n        ax.set_xlim(min_x - more, max_x + more)\n        ax.set_ylim(min_y - more, max_y + more)\n        \n# 数据准备\npoints = T\n\n# 构建KD树\nroot = build_kdtree(points.tolist())\n\n# 可视化KD树\nfig, ax = plt.subplots()\nax.scatter(points[:, 0], points[:, 1], color='blue', zorder=10, s=50)\n\n# 绘制KD树的分割线\ndraw_kdtree(ax, root, 0, np.min(points[:, 0]), np.max(points[:, 0]), np.min(points[:, 1]), np.max(points[:, 1]), more = 1)\n\n\n我在构建第0层的KD树， 我需要处理的数据量是6。我对第0维进行划分，在7处分割。\n    我在构建第1层的KD树， 我需要处理的数据量是3。我对第1维进行划分，在4处分割。\n        我在构建第2层的KD树， 我需要处理的数据量是1。我对第0维进行划分，在2处分割。\n        我在构建第2层的KD树， 我需要处理的数据量是1。我对第0维进行划分，在4处分割。\n    我在构建第1层的KD树， 我需要处理的数据量是2。我对第1维进行划分，在6处分割。\n        我在构建第2层的KD树， 我需要处理的数据量是1。我对第0维进行划分，在8处分割。\n\n\n\n\n\n\n\n\n\n\n2.1.1 解题\n例题已经告诉我们KD树的建立过程，现在本题我们来学习一下KD树的搜索是怎么做的。\n\n\n代码\nx = np.array([3, 4.5])\nx\n\n\narray([3. , 4.5])\n\n\n\n\n代码\n# 可视化KD树\nfig, ax = plt.subplots()\nax.scatter(points[:, 0], points[:, 1], color='blue', zorder=10, s=50)\n\n# 绘制KD树的分割线\ndraw_kdtree(ax, root, 0, np.min(points[:, 0]), np.max(points[:, 0]), np.min(points[:, 1]), np.max(points[:, 1]), more = 1)\nax.scatter(x[0], x[1], color='red', zorder=10, s=50)\nax.text(x[0], x[1], f'({x[0]}, {x[1]})', verticalalignment='bottom', horizontalalignment='right')\n\n\nText(3.0, 4.5, '(3.0, 4.5)')\n\n\n\n\n\n\n\n\n\n李航书上的KD树的搜索算法我理解如下：\n\n首先我们肯定能快速找到目标点所在的最小超矩形区域。这一步就是二叉搜索树，我们按照axis去分割。\n刚才那个区域的那个点认为是目前最近的点。\n我们再考虑那个点的父节点，这个父节点有两个子树，一个是刚才的刚才的目前最近点。\n\n这个父节点和当前最近点可以比较，如果更近可以替代掉。\n检查另一个子树的时候很复杂，需要看球是否相交。\n\n\n实际上我们有更好理解的思路，书上讲了球的相交非常复杂，实际上没那么难。\n\n我们本来的目标是遍历整个树，找到所有点里面和目标点最小的。\n现在我们本来可以从root开始递归所有节点，通过先序遍历之类的方法来找到所有点。\n然后我们就发现，左子树和右子树，有一个子树整体来说是更加有希望的，那就是被划分点划分到左边还是右边。\n所以我们优先考虑被搜索点被划分的那个子树，然后再考虑另一个子树。\n父树的最短距离就是左子树的最短距离和右子树的最短距离的最小值。如果我们发现第一次查看的子树的最短距离已经比当前坐标轴上的最短距离要小，我们偶尔就可以跳过这个子树，从而提高效率。\n\n这个思路和书上的是等价的。 我们据此写Python代码\n\n\n代码\n# 定义最近邻点搜索函数\ndef find_nearest_neighbor(node, point, depth=0, best=None):\n    if node is None:\n        return best\n\n    # 初始化最佳点\n    if best is None:\n        best = node.point, float('inf')\n    # 计算当前点到查询点的距离\n    dist = np.linalg.norm(np.array(point) - np.array(node.point))\n    if dist &lt; best[1]:\n        best = (node.point, dist)\n\n    # 确定分割轴\n    axis = depth % 2\n    \n    log = \"\\t\"*depth+f\"我在第{depth}层，我现在在{node.point}，对比我现在的位置之后，我目前发现最好的点是{best[0]}，距离是{best[1]:.2f}。\"\n    # 沿着正确的子树进行搜索\n    next_branch = None\n    opposite_branch = None\n    if point[axis] &lt; node.point[axis]:\n        next_branch = node.left\n        opposite_branch = node.right\n        log += f\"我觉得左子树更有希望, 因为在{axis}维度上，我们被划分到左边了。\"\n    else:\n        next_branch = node.right\n        opposite_branch = node.left\n        log += f\"我觉得右子树更有希望, 因为在{axis}维度上，我们被划分到右边了。\"\n        \n    print(log)\n          \n    # 递归搜索\n    best = find_nearest_neighbor(next_branch, point, depth + 1, best)\n    print(\"\\t\"*depth+f\"我在第{depth}层，我现在在{node.point}，对比第一个子树之后，我目前发现最好的点是{best[0]}，距离是{best[1]:.2f}\")\n\n    # 如果分割线与查询点的距离小于最佳距离，则搜索另一边的子树\n    if abs(point[axis] - node.point[axis]) &lt; best[1]:\n        best = find_nearest_neighbor(opposite_branch, point, depth + 1, best)\n        print(\"\\t\"*depth+f\"我在第{depth}层，我现在在{node.point}，对比第二个子树之后，我目前发现最好的点是{best[0]}，距离是{best[1]:.2f}\")\n    else:\n        print(f\"另一边的子树在现在这个维度{axis}上的距离{abs(point[axis] - node.point[axis])}大于最佳距离{best[1]:.2f}，我不用继续搜索。\")\n\n    return best\n\n\n\n# 找到点 (3, 4.5) 的最近邻点\ninput_point = [3, 4.5]\nnearest_point, distance = find_nearest_neighbor(root, input_point)\nnearest_point\n\n\n我在第0层，我现在在[7, 2]，对比我现在的位置之后，我目前发现最好的点是[7, 2]，距离是4.72。我觉得左子树更有希望, 因为在0维度上，我们被划分到左边了。\n    我在第1层，我现在在[5, 4]，对比我现在的位置之后，我目前发现最好的点是[5, 4]，距离是2.06。我觉得右子树更有希望, 因为在1维度上，我们被划分到右边了。\n        我在第2层，我现在在[4, 7]，对比我现在的位置之后，我目前发现最好的点是[5, 4]，距离是2.06。我觉得左子树更有希望, 因为在0维度上，我们被划分到左边了。\n        我在第2层，我现在在[4, 7]，对比第一个子树之后，我目前发现最好的点是[5, 4]，距离是2.06\n        我在第2层，我现在在[4, 7]，对比第二个子树之后，我目前发现最好的点是[5, 4]，距离是2.06\n    我在第1层，我现在在[5, 4]，对比第一个子树之后，我目前发现最好的点是[5, 4]，距离是2.06\n        我在第2层，我现在在[2, 3]，对比我现在的位置之后，我目前发现最好的点是[2, 3]，距离是1.80。我觉得右子树更有希望, 因为在0维度上，我们被划分到右边了。\n        我在第2层，我现在在[2, 3]，对比第一个子树之后，我目前发现最好的点是[2, 3]，距离是1.80\n        我在第2层，我现在在[2, 3]，对比第二个子树之后，我目前发现最好的点是[2, 3]，距离是1.80\n    我在第1层，我现在在[5, 4]，对比第二个子树之后，我目前发现最好的点是[2, 3]，距离是1.80\n我在第0层，我现在在[7, 2]，对比第一个子树之后，我目前发现最好的点是[2, 3]，距离是1.80\n另一边的子树在现在这个维度0上的距离4大于最佳距离1.80，我不用继续搜索。\n\n\n[2, 3]\n\n\n上述算法的流程图如下：\n\n\n\n\n\ngraph TD\n    A[开始] --&gt; B[检查node是否为None]\n    B --&gt;|是| C[返回best]\n    B --&gt;|否| D[初始化best]\n    D --&gt; E[计算dist]\n    E --&gt; F[更新best]\n    F --&gt; G[确定分割轴axis]\n    G --&gt; H[判断搜索方向]\n    H --&gt;|左子树| I[递归搜索左子树]\n    H --&gt;|右子树| J[递归搜索右子树]\n    I --&gt; K[检查是否需要搜索另一边子树]\n    J --&gt; K\n    K --&gt;|需要| L[递归搜索另一边子树]\n    K --&gt;|不需要| M[结束递归]\n    L --&gt; M\n    M --&gt; N[返回best]\n    N --&gt; C\n\n    style A fill:#bbf,stroke:#f66,stroke-width:2px\n    style C fill:#bbf,stroke:#f66,stroke-width:2px\n    style N fill:#bbf,stroke:#f66,stroke-width:2px\n\n\n\n\n\n\n\n\n\n\n2.2 题目扩展问题\n\n2.2.1 在K=1时，KD树和红黑树、AVL树等平衡搜索树的关系是什么?\n关系在于KD树没有考虑新增加节点的算法复杂度，每次新增加节点都要重新构造。 KD树建树的时候直接算中位数，强行平衡。\n\n\n2.2.2 怎么证明刚才的过程就找到了最近邻点？\n\n\n2.2.3 刚才我们只找到了最近邻点，如果需要返回q个最近邻点，应该如何修改代码？\n\n\n2.2.4 KD树构建过程、搜索过程的平均算法复杂度、最坏情况算法复杂度分别都是多少？\n平均复杂度 搜索是O(logN)， N是点的数量(李航 2019)。\n\n\n2.2.5 目前前沿的向量数据库中实际上做KNN是用什么数据结构？支持GPU加速吗？\n目前前沿的向量数据库中，实际上做KNN（K-Nearest Neighbor，最近邻搜索）通常使用的数据结构除了KD-Tree，还有HNSW（Hierarchical Navigable Small World） 以及 Ball Tree、 FLANN、局部敏感哈希（LSH）。\nNVIDIA cuVS库用于GPU加速的向量搜索和聚类，使用CAGRA（CUDA-Accelerated Graph Index for Vector Retrieval）技术。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A2",
      "大数据机器学习课程第二次作业"
    ]
  },
  {
    "objectID": "theory_assignments/A3/p_assignment3_yecanming.html#sec-1",
    "href": "theory_assignments/A3/p_assignment3_yecanming.html#sec-1",
    "title": "朴素贝叶斯与决策树的深入理解",
    "section": "1 第一题——朴素贝叶斯法概率估计公式推导",
    "text": "1 第一题——朴素贝叶斯法概率估计公式推导\n题目如下\n\n用贝叶斯估计法推出朴素贝叶斯法中的概率估计公式(4.10)和(4.11) \\(\\begin{aligned}P_{\\lambda}(X^{(j)}=a_{jl}|Y=C_{k})=& \\frac{\\sum_{i=1}^{N}I(x_{i}^{(j)}=a_{jl},y_{i}=c_{k})+\\lambda}{\\sum_{i=1}^{N}I(y_{i}=c_{k})+S_{j}\\lambda}\\end{aligned}\\)\n\n\n\n\n\n\n\n注记\n\n\n\nTL; DR 前面审题内容较长，学习了一些这道题的一些背景知识方便理解。 对于题目的证明，可以直接跳到解题部分@sec-proof。\n\n\n\n1.1 审题\n\n1.1.1 4.10和4.11式是什么？题目所给的式子是另一个公式吗？\n根据李航机器学习方法课本内容(李航 2019) 54 页，\n4.10 式就是题目汇中给的式子，即： \\[\n\\boldsymbol{P_{\\lambda}(X^{(j)}=a_{jl}|Y=c_{k})=\\frac{(\\sum_{i=1}^{N}I(x_{i}^{(j)}=a_{jl},y_{i}=c_{k}))+\\lambda}{(\\sum_{i=1}^{N}I(y_{i}=c_{k}))+S_{j}\\lambda}}\n\\tag{1}\\]\n书中说，用极大似然估计可能会出现所要估计的概率值为0的情况。这时会影响后验概率的计算 结果，使分类产生偏差。而上式就是为了解决这个问题而提出的，上式是对条件概率的贝叶斯估计，引入了一个新的参数\\(\\lambda \\ge 0\\)，等价于在每一个随机变量的取值频数都增加\\(\\lambda\\)次。当 \\(\\lambda=0\\) 时，等价于使用极大似然估计， 当 \\(\\lambda = 1\\) 时，称为拉普拉斯平滑。\n朴素贝叶斯需要知道怎么估计先验概率和条件概率（似然），刚才4.10估计了条件概率，接下来4.11式是估计先验概率怎么用上拉普拉斯平滑，即： \\[\nP_{\\lambda}\\left(Y=c_{k}\\right)=\\frac{(\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right))+\\lambda}{N+K \\lambda}\n\\tag{2}\\]\n\n\n\n\n\n\n警告\n\n\n\n李航书上的原式对括号的位置不清晰，让人分不清楚\\(+\\lambda\\) 是在求和操作\\(\\sum\\)的里面还是外面。为了避免歧义，我们上面已经修改，加上了括号，即\\(+\\lambda\\)的操作是在求和操作\\(\\sum\\)结束之后。\n\n\n\n\n1.1.2 本题要从什么推导到什么？\n4.10和4.11都是推导的结果，即贝叶斯估计的结果，但是李航书上没有说具体为什么加上\\(\\lambda\\) 就是贝叶斯估计了，具体是怎么贝叶斯估计的，所以本题需要我们推导。\n\n\n1.1.3 以上公式中的符号是什么含义？\n我们需要了解 式 1 和 式 2 中的符号含义。\n\n首先最基础的\n\n$ X R^n $：表示输入空间是n维向量集合。\n$ Y = { c_1, c_2,…, c_K } $：输出空间为类别标签集合，共有K个不同的类。\n输入特征向量 $ x X \\(，输出类别标签（class label）\\) y Y $。X是在输入空间上的随机变量，Y是在输出空间上的随机变量。\nP(X,Y) 是X和Y的联合概率分布。\n训练数据集T由N对独立的同分布产生的样本组成，每对包括一个来自X的特征向量和一个来自Y的类别标签。\n\n实际上为了方便推导，这里\\(X^{(j)}\\) 的取值是离散的，并不是\\(R^n\\)上的连续随机变量。\n\n这里假设设第j个特征\\(x^{(i)}\\)可能取值的集合为\\(\\{a_{j_1},a_{j_2},…,a_{j_{S_j}}\\}\\), 其中\\(S_j\\)为第j个特征的取值个数。\\(a_{jl}\\)用下标\\(l\\)来表示是第几个取值。\n\\(I\\)为指示函数。\n\n\n\n\n\n\n\n\n注记\n\n\n\n李航书上推导的是Categorical Naive Bayes，输入的是离散型随机变量。如果是连续型随机变量，则需要使用Gaussian Naive Bayes。\n\n\n\n\n1.1.4 一个问题，式子式 1 和 式子式 2中的\\(\\lambda\\)是同一个参数吗？\n\n如果按照李航书上说的“在随机变量各个取值的频数上赋予一个正数\\(\\lambda\\)”，那么比较难理解，到底是在\\(X^{(j)}\\)的每个取值上面加一共\\(S_j\\)次经验，还是在Y的每个类别上一共加上\\(K\\)次经验？\n这两个都取1不会矛盾吗？\n根据例题4.2，实际上就是都是取1。\n\n\n\n\n1.2 解题\n\n1.2.1 总体推导原则\n朴素贝叶斯法需要学习 \\(P(Y=c_k)\\) 和 \\(P(X^{(j)}|Y=c_k)\\) 这两系列的参数，所谓学习就是通过统计学方法对参数进行估计。 给定一个具体的数据集，极大似然估计的意思是计算出上面这两个参数每一个具体取值下，数据集如此出现的概率（似然），通过最大化这个似然，我们可以得到最有可能的模型参数。\n而贝叶斯估计法，根据我们PPT课件中学习的知识，则是认为\\(P(Y=c_k)\\) 和 \\(P(X^{(j)}|Y=c_k)\\)参数本身作为随机变量，具有先验分布，在我们观察到数据集\\(T = \\{(x_1,y_1), ..., (x_N,y_N)\\}\\)之后，我们后验地更新我们对这两个参数分布的认知，最后可能以参数分布的期望或者使得后验最大的值作为我们对参数的估计。\n根据课件上的内容，最后决策的时候，也可以不使用参数的估计，而是把整个参数的后验分布拿过来，去积分来对预测值求一个分布，称为后验预测分布。 #### 符号简化\n我们记\\(P(Y=c_k)\\)这k个参数为随机向量\\(\\theta_k\\)\n记\\(P(X^{(j)}=a_{jl}|Y=c_k)\\)这j个参数为随机向量\\(\\theta_{kl}\\)\n\n\n1.2.2 取什么共轭先验分布？\n\\(\\theta_k=P(Y=c_k)\\) 中有K个参数，需要满足加起来等于1，而且每个值非负的约束条件。\n\\(\\theta_{kl}=P(X^{(j)}|Y=c_k)\\) 我们不妨只管第j个特征，其他的特征是独立的，推导起来是一样的，那么j是已知了，这里需要估计\\(S_j \\times K\\) 个参数。同样也需要满足约束条件，对于每个具体的\\(c_k\\), \\(\\boldsymbol{P(X^{(j)}=a_{jl}|Y=c_{k})}\\) 所有\\(X^{(j)}\\)取值加起来等于1，以及取值非负。\n对于这种要求加起来等于1的约束条件，可以选择狄利克雷分布（Dirichlet Distribution）作为先验分布。狄利克雷分布又称多元Beta分布(multivariate Beta distribution)。\n设随机变量\\(\\theta_k\\)组成的随机向量\\(\\theta_{1:k}\\) 服从 \\(Dir(\\alpha_{1:k})\\)，其中\\(\\alpha_{1:k}\\) 是先验分布的超参数，是一个K维向量，且每个元素\\(\\alpha_k&gt;0\\)。 \\[\nP(\\theta_{1:k} | \\alpha_{1:k}) = \\frac{1}{B(\\alpha_{1:k})} \\prod_{k=1}^K \\theta_k^{\\alpha_k-1}\n\\]\n为了进一步简化问题，我们不妨认为这个分布是对称狄利克雷分布，即\\(\\forall k, \\alpha_k=\\lambda\\)。\\(\\lambda\\)被称为浓度参数。\n\n\n1.2.3 推导4.11式（朴素贝叶斯的”类别先验分布”参数的贝叶斯估计后验分布）\n根据贝叶斯公式，我们有： \\[\n\\begin{aligned}\nP(\\theta_{1:k} | \\alpha_{1:k}, T_{1:N}) &= \\frac{P(T_{1:N} | \\theta_{1:k}, \\alpha_{1:k}) P(\\theta_{1:k}|\\alpha_{1:k})}{P(T_{1:N}| \\alpha_{1:k})} \\\\\n&\\propto P(T_{1:N} | \\theta_{1:k}, \\alpha_{1:k}) P(\\theta_{1:k}|\\alpha_{1:k}) \\\\\n&= P(T_{1:N} | \\theta_{1:k}) P(\\theta_{1:k}|\\alpha_{1:k}) \\\\\n&= likelihood \\times prior \\\\\n\\end{aligned}\n\\]\n\n其中数据集的似然函数，我们有： \\[\n\\begin{aligned}\nP(T_{1:N} | \\theta_{1:k}) &= \\prod_{n=1}^N P(t_n|\\theta_{1:k}) \\\\\n\\end{aligned}\n\\] 其中 \\(P(t_n|\\theta_{1:k})\\) 的值是，如果\\(t_n = (x_n, y_n)\\)的\\(y_n = c_k\\), 则值为 \\(\\theta_k\\), 也就是 \\(P(t_n|\\theta_{1:k}) = \\prod_{k=1}^K I(y_n = c_k) \\times \\theta_{k}\\)。\n\n据此我们可以换一下整个式子求积的方式，原本是对每一个样本求积，现在我们只需要对每个类别求积即可：\n\\[\n\\begin{aligned}\nP(T_{1:N} | \\theta_{1:k}) &= \\prod_{k=1}^K \\theta_{k}^{N_k} \\\\\n\\end{aligned}\n\\]\n\n而对于先验分布，代入@sec-prior的狄利克雷分布公式： \\[\n\\begin{aligned}\nP_{\\lambda}(\\theta_{1:k}|\\alpha_{1:k}) &= \\frac{1}{B(\\lambda)} \\prod_{k=1}^K \\theta_k^{\\lambda-1}\n\\end{aligned}\n\\]\n根据1.和2.，我们有后验分布：\n\n\\[\n\\begin{aligned}\nP(\\theta_{1:k} | \\alpha_{1:k}, T_{1:N}) &\\propto likelihood \\times prior \\\\\n&\\propto \\prod_{k=1}^K \\theta_k^{N_k + \\lambda-1}\n\\end{aligned}\n\\]\n\\(\\theta_{1:k}\\) 在已知\\(\\alpha_{1:k}, T_{1:N}\\)的情况下，服从对称Dirichlet分布 \\(Dir(\\alpha_{N_k + \\lambda})\\)。\n而Dirichlet分布每一个\\(\\theta_k\\)的期望为其对应的参数\\(\\alpha_k\\)的占比。\n因此，我们就可以用后验分布的期望来估计\\(\\theta_{1:k}\\)。\n$$\n\\[\\begin{aligned}\nP_{\\lambda}\\left(Y=c_{k}\\right) &= \\hat{\\theta_k} \\\\\n    &= E(\\theta_k| \\lambda, T_{1:N}) \\\\\n    & = \\frac{N_k + \\lambda}{\\sum_{k=1}^K (N_k + \\lambda)} \\\\\n    &=\\frac{(\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right))+\\lambda}{N+K \\lambda}\n\\end{aligned}\\]\n$$ 即 式 2 式。\n\n\n1.2.4 推导4.10式（朴素贝叶斯的”条件概率”参数的贝叶斯估计后验分布）\n类似于@sec-prior，我们首先要定义条件概率\\(\\theta_{kl}\\) 的先验分布\n设随机变量\\(\\theta_{kl}\\)组成的随机向量\\({\\theta_k}_{1:l}\\) 服从 \\(Dir({\\alpha_k}_{1:l})\\)，其中\\({\\alpha_k}_{1:l}\\) 是先验分布的超参数，是一个\\(S_j\\)维向量，且每个元素\\(\\alpha_{kl}&gt;0\\)。 \\[\nP(\\theta_{k1:l} | \\alpha_{k1:l}) = \\frac{1}{B(\\alpha_{k1:l})} \\prod_{l=1}^{S_j} \\theta_{kl}^{\\alpha_{kl}-1}\n\\]\n同理，为了进一步简化问题，我们不妨认为这个分布是对称狄利克雷分布，即\\(\\forall l, \\alpha_{kl}=\\lambda\\)。\\(\\lambda\\)被称为浓度参数。 &gt; 这里回答了上面我提出的问题，实际上两个式子的\\(\\lambda\\)可以不一样，这取决于使用朴素贝叶斯的人的偏好和经验，由于正好我们都要做拉普拉斯平滑，也就是\\(\\lambda=1\\)，所以正好两个\\(\\lambda\\)相等，但是也可以是不同的。\n与@sec-proof类似，我们可以做一样的推导，只是把符号替换 - K替换为\\(S_j\\) - \\(\\theta_{k}\\)替换为\\({\\theta_kl}\\) - \\(\\alpha_{k}\\)替换为\\({\\alpha_kl}\\)\n\\[\n\\begin{aligned}\nP_{\\lambda} (X^{(j)}=a_{jl}|Y=c_{k})\n  &= \\hat{\\theta_{kl}} \\\\\n   &= E(\\theta_{kl}|\\lambda, T_{1:N}) \\\\\n    &=\\frac{(\\sum_{i=1}^{N}I(x_{i}^{(j)}=a_{jl},y_{i}=c_{k}))+\\lambda}{(\\sum_{i=1}^{N}I(y_{i}=c_{k}))+S_{j}\\lambda}\n\\end{aligned}\n\\]\n\n\n\n1.3 题目扩展问题\n\n1.3.1 贝叶斯估计的先验是否可以被任意地操控，让我们的后验分布变成任意的分布？如果是这样，那么我们如何保证先验分布的合理性？\n\n\n1.3.2 贝叶斯估计参数的后验分布的期望能否代替后验分布本身来预测新的数据的分布？",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A3",
      "朴素贝叶斯与决策树的深入理解"
    ]
  },
  {
    "objectID": "theory_assignments/A3/p_assignment3_yecanming.html#sec-2",
    "href": "theory_assignments/A3/p_assignment3_yecanming.html#sec-2",
    "title": "朴素贝叶斯与决策树的深入理解",
    "section": "2 第二题",
    "text": "2 第二题\n题目如下\n\n已知如表5.2所示的训练数据，试用平方误差损失准则生成一个二叉回归树。\n\n5.2 训练数据是\n\n\n代码\nimport numpy as np\nx = np.arange(1, 11)\ny = np.array([4.5, 4.75, 4.91, 5.34, 5.80, 7.05, 7.90, 8.23, 8.70, 9.00])\nx, y\n\n\n(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n array([4.5 , 4.75, 4.91, 5.34, 5.8 , 7.05, 7.9 , 8.23, 8.7 , 9.  ]))\n\n\n\n2.1 审题\n数据可视化如下\n\n\n代码\nimport matplotlib.pyplot as plt\nplt.plot(x, y, 'o-')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('y vs x')\nplt.show()\n\n\n\n\n\n\n\n\n\n平方误差损失准则是什么？二叉回归树是什么？\nCART（Classification and Regression Tree）方法就是”分类与回归树”方法，CART对于输入X构建的决策树是二叉树，这里的分类与回归指的是输出变量Y是离散的还是连续的。CART认为回归树是要用平方误差作为损失函数，而分类树是要用基尼系数作为损失函数，所谓“准则”是指构建树的时候用损失函数来决定用哪个输入的属性来划分节点。\n具体来说，就是划分前后损失函数的变化。\n\n2.1.1 解题\n我们直接通过写代码（注意这里有参考一些网上的代码，但是我们每一行都认真审查过了）来加深自己的理解，实现书上算法5.5。 首先我们要定义二叉树的节点类，包括左右子树指针。\n对于决策树而言，二叉树的节点还需要记录 - 特征 feature：记录当前节点划分的特征（用属性的编号j来表示） - 切分值 split：是如何划分左右子树的 - 估计值 value：被划分到当前节点的输入可以用什么输出值（通过平均值）来估计\n\n\n代码\nimport numpy as np\n\nclass Node:\n    def __init__(self, feature=None, # 切分的特征\n                 split=None,  # 切分的值\n                 left:'Node'=None, # 左子树\n                 right:'Node'=None, # 右子树\n                 value=None # 叶子节点的预测值\n                 ):\n        self.feature = feature \n        self.split = split\n        self.left:'Node' = left\n        self.right:'Node' = right\n        self.value = value\n\n    def is_leaf_node(self):\n        return self.value is not None\n\n\n下面我们来写回归树类。我们一个一个方法的写（得益于fastcore库的patch函数，我们可以渐进式地给Python类添加方法），首先是构造函数，指定算法的超参数。\n原始的书上算法5.5 没有max_depth, 而 min_samples_split=2\n\n\n代码\nfrom fastcore.utils import patch\nclass RegressionTree:\n    def __init__(self, min_samples_split=2, # 最少需要多少个样本才能分裂\n                 max_depth=float('inf') # 最大深度，太深的话容易过拟合\n                 ):\n        self.min_samples_split = min_samples_split \n        self.max_depth = max_depth \n        self.root:'Node' = None # root 也就是不划分，用所有值的y的均值作为预测值\n\n\n接下来我们可以看看怎么写回归树的训练算法。这里的关键是对输入空间如何进行划分。 CART是启发式（贪心）算法，每一次就按照最优特征和最优切分点来划分子空间。具体来说，CART算法的训练过程如下：\n\n\n代码\n@patch\ndef fit(self:RegressionTree, X, y):\n    # 这里是对外的接口， 里面的_grow_tree是递归的过程\n    self.root = self._grow_tree(X, y)\n\n@patch\ndef _grow_tree(self:RegressionTree, \n                X, # 是划分后的子集\n                y, # 是对应的标签\n                depth=0 # 当前深度\n    ):\n    n_samples, n_features = X.shape\n    n_labels = len(np.unique(y)) \n\n    # stopping criteria\n    if (depth &gt;= self.max_depth\n            or n_labels == 1 # 只有一个值，就算有很多样本也不划分了。\n            or n_samples &lt; self.min_samples_split):\n        leaf_value = np.mean(y)\n        self._print_leaf(depth, leaf_value)\n        return Node(value=leaf_value)\n\n    # find the best split 这里是最难的地方，效率也比较低，需要对整个X的每一个特征都遍历一次。\n    best_feature, best_split, best_score = self._best_split(X, y)\n    self._print_split(depth, best_feature, best_split, best_score)\n    \n    # grow the children that result from the split\n    left_indices, right_indices = self._split(X[:, best_feature], best_split)\n    left_child = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n    right_child = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n    return Node(best_feature, best_split, left_child, right_child)\n\n@patch\ndef _print_split(self:RegressionTree, depth, feature, split, score):\n    print(f\"{' ' * depth}Depth {depth}: Split on feature {feature} at value {split} with score {score}\")\n\n@patch\ndef _print_leaf(self:RegressionTree, depth, value):\n    print(f\"{' ' * depth}Depth {depth}: Leaf with value {value}\")\n\n@patch\ndef _best_split(self:RegressionTree, X, y):\n    # 需要遍历所有的特征和所有可能的切分点，找到最佳切分点\n    best_score = float('inf') # 这里我们假设越小越好。注意我们不需要算增益，其实只需要算划分之后的loss就行\n    best_feature, best_split = None, None\n    for feature_index in range(X.shape[1]):\n        feature_values = X[:, feature_index]\n        possible_splits = np.unique(feature_values) # 如果输入没有那么多就可以少算一点\n        for split in possible_splits:\n            left_indices, right_indices = self._split(feature_values, split)\n            if len(left_indices) == 0 or len(right_indices) == 0: # 划分之后有一边没了，那就不考虑这个划分点。因为增益肯定是0。\n                continue\n            left_score = self._calculate_mse(y[left_indices])\n            right_score = self._calculate_mse(y[right_indices])\n            score = left_score + right_score\n            if score &lt; best_score: # 改进了\n                best_score, best_feature, best_split = score, feature_index, split\n    return best_feature, best_split, best_score\n@patch\ndef _split(self:RegressionTree, feature_values, split):\n    left_indices = np.where(feature_values &lt;= split)\n    right_indices = np.where(feature_values &gt; split)\n    return left_indices, right_indices\n\n@patch\ndef _calculate_mse(self:RegressionTree, y):\n    # 这里是y的子集，这个子集使用np.mean作为预测值，所以会有误差。  \n    return np.mean((y - np.mean(y)) ** 2)\n\nX = x.reshape(-1, 1)\nreg_tree = RegressionTree(min_samples_split=2, max_depth=float('inf'))\nreg_tree.fit(X, y)\n\n\nDepth 0: Split on feature 0 at value 5 with score 0.6717439999999998\n Depth 1: Split on feature 0 at value 3 with score 0.08136666666666667\n  Depth 2: Split on feature 0 at value 1 with score 0.006400000000000012\n   Depth 3: Leaf with value 4.5\n   Depth 3: Split on feature 0 at value 2 with score 0.0\n    Depth 4: Leaf with value 4.75\n    Depth 4: Leaf with value 4.91\n  Depth 2: Split on feature 0 at value 4 with score 0.0\n   Depth 3: Leaf with value 5.34\n   Depth 3: Leaf with value 5.8\n Depth 1: Split on feature 0 at value 6 with score 0.17891874999999977\n  Depth 2: Leaf with value 7.05\n  Depth 2: Split on feature 0 at value 8 with score 0.049725000000000116\n   Depth 3: Split on feature 0 at value 7 with score 0.0\n    Depth 4: Leaf with value 7.9\n    Depth 4: Leaf with value 8.23\n   Depth 3: Split on feature 0 at value 9 with score 0.0\n    Depth 4: Leaf with value 8.7\n    Depth 4: Leaf with value 9.0\n\n\n/home/ai_pitch_perfector/program_files/managers/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/home/ai_pitch_perfector/program_files/managers/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n\n\n\n\n代码\n!pip install graphviz\n\n\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nRequirement already satisfied: graphviz in /home/ai_pitch_perfector/program_files/managers/conda/lib/python3.10/site-packages (0.20.3)\n\n\n\n\n代码\nfrom graphviz import Digraph\n\ndef visualize_node(node:Node, graph_label=\"Regression Tree\"):\n    # Create Digraph object\n    dot = Digraph(comment=graph_label)\n\n    # Helper function to recursively add nodes and edges\n    def add_nodes_edges(node, parent_node_id=None):\n        # If node is a leaf, add it to the graph\n        if node.is_leaf_node():\n            node_id = str(id(node))\n            dot.node(node_id, f\"Leaf\\nValue: {node.value:.2f}\")\n        else:\n            # Add current node to the graph\n            node_id = str(id(node))\n            dot.node(node_id, f\"X_{node.feature} &lt;= {node.split:.2f}\")\n\n            # Recursively add left and right children\n            left_child_id = add_nodes_edges(node.left, node_id)\n            right_child_id = add_nodes_edges(node.right, node_id)\n\n            # Add edges from current node to its children\n            dot.edge(node_id, left_child_id, label=\"True\")\n            dot.edge(node_id, right_child_id, label=\"False\")\n\n        return node_id\n\n    # Start from the root node\n    add_nodes_edges(node)\n\n    return dot\n\n@patch\ndef visualize(self:RegressionTree):\n    return visualize_node(self.root)\n\n# Visualize the tree\ndot = reg_tree.visualize()\ndot.render('regression_tree', format='png', cleanup=True)  # Save the tree as an image\n'(regression_tree.png)'\ndot\n\n\n\n\n\n\n\n\n\n接下来是第二步，有了这个决策树，怎么预测新的数据呢？\n\n\n代码\n@patch\ndef predict(self:RegressionTree, X):\n    # 对于新的输入，预测值怎么计算呢，对每一个值去做。\n    self.decision_paths = [] \n    return np.array([self._predict_sample(x) for x in X])\n\n@patch\ndef _predict_sample(self:RegressionTree, inputs):\n        node:Node = self.root\n        path = []  # Track the decision path\n        while not node.is_leaf_node():\n            path.append(node)\n            if inputs[node.feature] &lt;= node.split:\n                node = node.left\n            else:\n                node = node.right\n        path.append(node)  # Add the leaf node to the path\n        self.decision_paths.append(path)\n        return node.value\n\npredictions = reg_tree.predict(X)\npredictions\n\n\narray([4.5 , 4.75, 4.91, 5.34, 5.8 , 7.05, 7.9 , 8.23, 8.7 , 9.  ])\n\n\n因为我们没有限制深度，所以predictions应该与真实值相同。\n\n\n代码\npredictions - y\n\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n如果我们有最大深度设为2，那么可以画出下面的图\n\n\n代码\nimport matplotlib.pyplot as plt\n\nreg_tree = RegressionTree(max_depth=2)\nreg_tree.fit(X, y)\npredictions = reg_tree.predict(X)\n\n# Scatter plot for actual values and predictions\nplt.figure(figsize=(10, 6))\nplt.scatter(range(len(y)), y, color='blue', label='Actual Values')\nplt.scatter(range(len(predictions)), predictions, color='red', label='Predictions')\n\n# Highlight the difference\nfor i, (act, pred) in enumerate(zip(y, predictions)):\n    plt.plot([i, i], [act, pred], color='green' if act == pred else 'orange')\n\nplt.title('Actual Values vs. Predictions')\nplt.xlabel('Data Points')\nplt.ylabel('Values')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n/home/ai_pitch_perfector/program_files/managers/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/home/ai_pitch_perfector/program_files/managers/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n\n\nDepth 0: Split on feature 0 at value 5 with score 0.6717439999999998\n Depth 1: Split on feature 0 at value 3 with score 0.08136666666666667\n  Depth 2: Leaf with value 4.72\n  Depth 2: Leaf with value 5.57\n Depth 1: Split on feature 0 at value 6 with score 0.17891874999999977\n  Depth 2: Leaf with value 7.05\n  Depth 2: Leaf with value 8.4575\n\n\n\n\n\n\n\n\n\n\n\n\n2.2 题目扩展问题\n这里我们产生一个疑问，划分一定能改进训练损失吗？有没有可能信息增益是负的，划分之后反而loss更大？\n我们其实想问，\\[MSE(E(l_1), l_1) + MSE(E(l_2), l_2) \\le MSE(E(l_1+l_2), l_1+l_2)\\] 这个不等式是否恒成立？ 其中 \\(l_1\\) 和 \\(l_2\\) 是两个任意实数列表， \\(l_1+l_2\\) 是两个列表的拼接。",
    "crumbs": [
      "理论作业 Theory Assignments",
      "theory_assignments",
      "A3",
      "朴素贝叶斯与决策树的深入理解"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "THU-Coursework-Machine-Learning-for-Big-Data",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "理论作业 Theory Assignments",
      "THU-Coursework-Machine-Learning-for-Big-Data"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "THU-Coursework-Machine-Learning-for-Big-Data",
    "section": "Developer Guide",
    "text": "Developer Guide\n如果你想加入我们一起开源作业，请阅读以下指南。\nIf you are new to using nbdev here are some useful pointers to get you started.\n\n关于Quarto和nbdev一些需要配置的地方\nnbdev_install_quarto\nquarto install tinytex\nquarto install chromium\nsudo apt-get install librsvg2-bin\n\n\n关于nbdev、quarto+pandoc 这一套系统支持和不支持的markdown与latex语法\n\nlatex公式：\n\n不能用””\n对于align公式,似乎都失败了 align, aligned和aligned*, 参考\nMathJax引擎支持的应该支持。https://quarto.org/docs/output-formats/html-basics.html\nVSCode也用的是 MathJax https://stackoverflow.com/questions/62879232/how-do-i-use-latex-in-a-jupyter-notebook-inside-visual-studio-code\n\nmarkdown语法：\n\n\n\nInstall THU_Coursework_Machine_Learning_for_Big_Data in Development mode\n# make sure THU_Coursework_Machine_Learning_for_Big_Data package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to THU_Coursework_Machine_Learning_for_Big_Data\n$ nbdev_prepare",
    "crumbs": [
      "理论作业 Theory Assignments",
      "THU-Coursework-Machine-Learning-for-Big-Data"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "THU-Coursework-Machine-Learning-for-Big-Data",
    "section": "Usage",
    "text": "Usage\n我们在学习清华大学《大数据机器学习》以及《大数据分析》两门课程完成作业的同时，也形成了一个简单的机器学习与数据分析库，对李航《统计学习方法》上的部分代码做了实现和可视化，你可以通过安装我们的库来复用我们写的代码逻辑。\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git\n\nor from pypi\n$ pip install thu_big_data_ml\n\n\nDocumentation\nDocumentation can be found hosted on this https://thu-coursework-machine-learning-for-big-data-docs.vercel.app/ . Additionally you can find package manager specific guidelines on pypi respectively.",
    "crumbs": [
      "理论作业 Theory Assignments",
      "THU-Coursework-Machine-Learning-for-Big-Data"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "THU-Coursework-Machine-Learning-for-Big-Data",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "理论作业 Theory Assignments",
      "THU-Coursework-Machine-Learning-for-Big-Data"
    ]
  }
]