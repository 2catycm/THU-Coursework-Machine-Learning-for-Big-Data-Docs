<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="叶璨铭 (2024214500) ycm24@mails.tsinghua.edu.cn">

<title>最大熵模型以及对数几率分类模型的深入理解 – THU-Coursework-Machine-Learning-for-Big-Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../thu_logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="最大熵模型以及对数几率分类模型的深入理解 – THU-Coursework-Machine-Learning-for-Big-Data">
<meta property="og:description" content="大数据机器学习课程第四次作业">
<meta property="og:site_name" content="THU-Coursework-Machine-Learning-for-Big-Data">
<meta name="twitter:title" content="最大熵模型以及对数几率分类模型的深入理解 – THU-Coursework-Machine-Learning-for-Big-Data">
<meta name="twitter:description" content="大数据机器学习课程第四次作业">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">THU-Coursework-Machine-Learning-for-Big-Data</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="搜索"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="展开或折叠导航栏" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../theory_assignments/index.html" aria-current="page"> 
<span class="menu-text">理论作业 Theory Assignments</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../coding_projects/index.html"> 
<span class="menu-text">代码项目 Coding Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.xuetangx.com/course/THU08091001026/1515437"> 
<span class="menu-text">关于课程 Course Information</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/Open-Book-Studio"> 
<span class="menu-text">关于我们 About Us</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-discuss-with-us" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">和我们一起讨论 Discuss with Us</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-discuss-with-us">    
        <li>
    <a class="dropdown-item" href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues"><i class="bi bi-bug" role="img">
</i> 
 <span class="dropdown-text">你的作业有地方写错了 Report an Issue on Assignments</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="http://qm.qq.com/cgi-bin/qm/qr?wv=1027&amp;k=v0Vpqbr4pScRi4IkFK3dsDUCzvu-BtX&amp;authKey=vyojwISealVovwzm6TQR7bkawm4oj6Wgbe4YBheQjRU5XOllK9pQ57eQjaG30dlq&amp;noverify=0&amp;group_code=935310031"><i class="bi bi-chat-right-text" role="img">
</i> 
 <span class="dropdown-text">X9高校人工智能技术讨论 X9 AI Tech Discussion</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/2catycm"><i class="bi bi-question-circle" role="img">
</i> 
 <span class="dropdown-text">联系我们 Contact Us</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Open-Book-Studio"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/THU-CVML"> <i class="bi bi-github" role="img" aria-label="THU-CVML 课题组">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../theory_assignments/index.html">theory_assignments</a></li><li class="breadcrumb-item"><a href="../../theory_assignments/A4/p_assignment4_yecanming.html">A4</a></li><li class="breadcrumb-item"><a href="../../theory_assignments/A4/p_assignment4_yecanming.html">最大熵模型以及对数几率分类模型的深入理解</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">THU-Coursework-Machine-Learning-for-Big-Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../help (library information).html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Library Information</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../coding_projects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">coding_projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">P1_ANOVA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P1_ANOVA/anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">深入探索方差分析 (Analysis of Variance, ANOVA)</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">P1_KNN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P1_KNN/kd_tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">深入探索KD树数据结构实现的KNN算法及其在手写数字识别中的应用</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">P2_SVM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/00svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——00绪论</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/use_lib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——01调库实现SVM手写数字识别</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/handy_crafted_linear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——02手动实现SGD优化的软间隔线性SVM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/kernel_hpo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——03不同Kernel的SVM超参数优化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/P2_SVM/handy_crafted_kernel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">更高效的支持向量机算法实现及其在手写数字识别中的应用——04手动实现使用SMO的Kernel SVM</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">big_data_analytics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">P2_Matrix-Decomposition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../coding_projects/big_data_analytics/P2_Matrix-Decomposition/decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">深入探索基于矩阵分解和协同过滤的个性化推荐系统及其在Netflix电影推荐中的应用</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../theory_assignments/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">theory_assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">A1</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A1/p_assignment1_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">从数据集中进行分布参数估计: 以伯努利分布为例</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">A2</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A2/p_assignment2_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">大数据机器学习课程第二次作业</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">A3</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A3/p_assignment3_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">朴素贝叶斯与决策树的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">A4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A4/p_assignment4_yecanming.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">最大熵模型以及对数几率分类模型的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">A5</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A5/p_assignment5_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">支持向量机的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">A6</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../theory_assignments/A6/p_assignment6_yecanming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AdaBoost算法的深入理解</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">该页面内容</h2>
   
  <ul>
  <li><a href="#sec-1" id="toc-sec-1" class="nav-link active" data-scroll-target="#sec-1"><span class="header-section-number">1</span> 第二题——最大熵模型的深入理解</a>
  <ul>
  <li><a href="#审题" id="toc-审题" class="nav-link" data-scroll-target="#审题"><span class="header-section-number">1.1</span> 审题</a>
  <ul class="collapse">
  <li><a href="#什么是熵" id="toc-什么是熵" class="nav-link" data-scroll-target="#什么是熵"><span class="header-section-number">1.1.1</span> 什么是熵？</a></li>
  <li><a href="#什么是最大熵" id="toc-什么是最大熵" class="nav-link" data-scroll-target="#什么是最大熵"><span class="header-section-number">1.1.2</span> 什么是最大熵？</a></li>
  <li><a href="#什么是最大熵原理" id="toc-什么是最大熵原理" class="nav-link" data-scroll-target="#什么是最大熵原理"><span class="header-section-number">1.1.3</span> 什么是最大熵原理？</a></li>
  <li><a href="#什么是最大熵模型" id="toc-什么是最大熵模型" class="nav-link" data-scroll-target="#什么是最大熵模型"><span class="header-section-number">1.1.4</span> 什么是最大熵模型？</a></li>
  </ul></li>
  <li><a href="#解题" id="toc-解题" class="nav-link" data-scroll-target="#解题"><span class="header-section-number">1.2</span> 解题</a>
  <ul class="collapse">
  <li><a href="#牛顿法和拟牛顿法" id="toc-牛顿法和拟牛顿法" class="nav-link" data-scroll-target="#牛顿法和拟牛顿法"><span class="header-section-number">1.2.1</span> 牛顿法和拟牛顿法</a></li>
  <li><a href="#dfp算法" id="toc-dfp算法" class="nav-link" data-scroll-target="#dfp算法"><span class="header-section-number">1.2.2</span> DFP算法</a></li>
  <li><a href="#最大熵模型拉格朗日乘子法化简" id="toc-最大熵模型拉格朗日乘子法化简" class="nav-link" data-scroll-target="#最大熵模型拉格朗日乘子法化简"><span class="header-section-number">1.2.3</span> 最大熵模型拉格朗日乘子法化简</a></li>
  <li><a href="#dfp算法求解" id="toc-dfp算法求解" class="nav-link" data-scroll-target="#dfp算法求解"><span class="header-section-number">1.2.4</span> DFP算法求解</a></li>
  <li><a href="#pytorch代码实现" id="toc-pytorch代码实现" class="nav-link" data-scroll-target="#pytorch代码实现"><span class="header-section-number">1.2.5</span> Pytorch代码实现</a></li>
  </ul></li>
  <li><a href="#题目扩展问题" id="toc-题目扩展问题" class="nav-link" data-scroll-target="#题目扩展问题"><span class="header-section-number">1.3</span> 题目扩展问题</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues/new" class="toc-action"><i class="bi bi-github"></i>反馈问题</a></li></ul></div><div class="quarto-alternate-formats"><h2>其他格式</h2><ul><li><a href="p_assignment4_yecanming.html.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../theory_assignments/index.html">theory_assignments</a></li><li class="breadcrumb-item"><a href="../../theory_assignments/A4/p_assignment4_yecanming.html">A4</a></li><li class="breadcrumb-item"><a href="../../theory_assignments/A4/p_assignment4_yecanming.html">最大熵模型以及对数几率分类模型的深入理解</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">最大熵模型以及对数几率分类模型的深入理解</h1>
<p class="subtitle lead">大数据机器学习课程第四次作业</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">作者</div>
    <div class="quarto-title-meta-contents">
             <p>叶璨铭 (2024214500) ycm24@mails.tsinghua.edu.cn </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">发布于</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2024年10月20日星期日</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p><img src="../../thu_sigs_logo.png" alt="清华深研院-横" style="zoom:50%;"></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
重要
</div>
</div>
<div class="callout-body-container callout-body">
<p>本文档具有一定的交互性，建议使用浏览器打开html文件，这样比pdf文件阅读体验更佳。</p>
</div>
</div>
<section id="sec-1" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-1"><span class="header-section-number">1</span> 第二题——最大熵模型的深入理解</h2>
<p>题目如下</p>
<blockquote class="blockquote">
<p>写出最大熵模型学习的DFP算法</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注记
</div>
</div>
<div class="callout-body-container callout-body">
<p>TL; DR 前面审题内容较长，学习了一些这道题的一些背景知识方便理解。 对于题目的证明，可以直接跳到解题部分@sec-proof。</p>
</div>
</div>
<section id="审题" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="审题"><span class="header-section-number">1.1</span> 审题</h3>
<section id="什么是熵" class="level4" data-number="1.1.1">
<h4 data-number="1.1.1" class="anchored" data-anchor-id="什么是熵"><span class="header-section-number">1.1.1</span> 什么是熵？</h4>
<section id="首先复习一下课件以及李航课本" class="level5" data-number="1.1.1.1">
<h5 data-number="1.1.1.1" class="anchored" data-anchor-id="首先复习一下课件以及李航课本"><span class="header-section-number">1.1.1.1</span> 首先复习一下课件以及李航课本</h5>
<p>《决策树》那节课上，我们学习了ID3算法，首次提到了熵的概念，我们来看第一页课件讲了什么：第一页我们就遇到了不少问题，我们稍后解答。我们首先明白了事件有信息量。 多个事件的平均信息量似乎是他们信息量的加和，那课件上说“平均”似乎不妥。 <img src="P_Assignment4_yecanming_files/figure-html/cell-6-1-image-2.png" class="img-fluid" alt="image-2.png"> 经过我的查询，其实是第一个定义错了，课件上的I(a)就已经是平均信息量了，事件的“信息量”其实是指香农信息量，就是 <span class="math inline">\(-log_2P(a)\)</span>，没有多乘一个<span class="math inline">\(P(a)\)</span>。 值得注意的是，从课件这一页的公式来看，<span class="math inline">\(I(a_1, a_2) \neq I(a_1 \cup a_2)\)</span>，也就是说如果两个事件合并为一个事件的平均信息量和两个事件的平均信息量之和是不一样的。有点让人困惑</p>
<p>在我们学习概率论与数理统计的时候，重要的就是从讨论事件变为讨论随机变量，所以随机变量的信息量也要定义。纠正了刚才第一页课件的错误之后，我们按照第一页的概念来说，随机变量的信息量就是随机变量所有取值事件各自平均信息量的加和，或者是说各个取值事件的信息量在随机变量分布下的期望。 <img src="P_Assignment4_yecanming_files/figure-html/cell-6-5-image.png" class="img-fluid" alt="image.png"> 第二页中让我们疑惑的是，熵和信息量这两个概念为什么可以混用？如果可以混用为什么上一页叫做信息量，这一页叫做熵？简单理解一下，目前我们认为信息量 (Information Content)是对一个随机变量取值去定义，熵 (Entropy) 是对随机变量去定义，熵就是信息量在这个随机变量下的期望。注意，一个随机变量取值可能实际上对应了很多个事件，我们刚才说<span class="math inline">\(I(a_1, a_2) \neq I(a_1 \cup a_2)\)</span>，随机变量这个变量被人定义后，就定义了一种对信息的理解方式，不同的理解方式下我们认为的信息量是不同的。</p>
<p>这一页是在讲熵(Entropy)和不确定性(Uncertainty)之间的关系。随机变量的不确定性通常是指其结果的不可预测性，即在进行观测之前，我们无法确定随机变量将取哪个具体的值。怎么量化这个不确定的程度呢？熵只是一种方式罢了，方差以及分布的图像也可以让我们看到随机变量的不确定性。这一页并没有解释这一点，而是开始举了个例子告诉我们什么情况下熵比较大，什么情况比较小，取值范围是什么样的。 <img src="P_Assignment4_yecanming_files/figure-html/cell-6-2-image-3.png" class="img-fluid" alt="image-3.png"> 注意这里说的是离散随机变量，有分布列，取值有n种，简单推导知道了熵在p=1/n的情况下最大。那么方差是不是一样呢？暂时没找到说法。不过我感觉熵似乎更靠谱的地方在于它不会被随机变量具体取值的大小所影响。</p>
<p>注意这里还有个要点，就是如果p=0， <span class="math inline">\(plog_2p\)</span> 等于0，这是因为我们学过洛必达法则，<span class="math inline">\(\lim_{p \to 0} \frac{\log p}{\frac{1}{p}} = \lim_{p \to 0} \frac{\frac{1}{p}}{-\frac{1}{p^2}} = \lim_{p \to 0} (-p) = 0\)</span></p>
<p>这里我们复习一下什么是条件期望。我们知道什么叫做条件概率分布，条件期望就是条件概率采样下y取值的期望。 <img src="P_Assignment4_yecanming_files/figure-html/cell-6-3-image-4.png" class="img-fluid" alt="image-4.png"> 上面课件中最下面的公式意思是说如果相求h(y)的期望，并不需要求出h(y)的分布或者h(y)|x的分布。这是因为函数期望的基本定理（注意不是说期望的函数等于函数的期望，而是说函数的期望可以用原本的采样去计算）。</p>
<p><img src="P_Assignment4_yecanming_files/figure-html/cell-6-4-image-5.png" class="img-fluid" alt="image-5.png"> 这里我们的问题是，这个定义看起来嵌套了一层，我们能不能直接通过条件期望去定义条件熵呢？ 答案是不能。这里的符号我们需要特别注意，<span class="math inline">\(H(Y|X) \neq H(Y|X=x)\)</span>，前者的X不知道，是个平均情况。</p>
<p>下一个概念是互信息。 李航书上提到，Y对X的互信息<span class="math inline">\(I(Y; X) = H(Y) - H(Y|X)\)</span>是指得知X的取值让Y的不确定性减少，需要得知Y取值所需要的信息量减少了多少。 之所以叫做互相信息，是因为 $I(Y;X) = I (X; Y) $</p>
</section>
<section id="prml书上有什么补充吗" class="level5" data-number="1.1.1.2">
<h5 data-number="1.1.1.2" class="anchored" data-anchor-id="prml书上有什么补充吗"><span class="header-section-number">1.1.1.2</span> PRML书上有什么补充吗？</h5>
</section>
<section id="进一步的资料查找" class="level5" data-number="1.1.1.3">
<h5 data-number="1.1.1.3" class="anchored" data-anchor-id="进一步的资料查找"><span class="header-section-number">1.1.1.3</span> 进一步的资料查找</h5>
</section>
</section>
<section id="什么是最大熵" class="level4" data-number="1.1.2">
<h4 data-number="1.1.2" class="anchored" data-anchor-id="什么是最大熵"><span class="header-section-number">1.1.2</span> 什么是最大熵？</h4>
<p>最大熵就是给定某些限制条件下，允许我们修改一个随机变量的分布，使得其熵最大。问我们怎么修改。</p>
<p>这个问题其实需要分类讨论。核心结论是 - 离散随机变量均匀分布熵最大。 - 连续随机变量给定方差一定时，高斯分布的熵最大。</p>
<p>这里有几个问题 - 连续随机变量为什么均匀分布熵没有高斯分布大？ - 如果我们限定连续随机变量的取值范围为[a, b], 截断高斯分布(Truncated Gaussian Distribution)和均匀分布去比，哪个熵更大？</p>
<section id="具体怎么推导的" class="level5" data-number="1.1.2.1">
<h5 data-number="1.1.2.1" class="anchored" data-anchor-id="具体怎么推导的"><span class="header-section-number">1.1.2.1</span> 具体怎么推导的？</h5>
<p>对于离散型随机变量X，取值有N个，每个取值的概率是<span class="math inline">\(p_i\)</span>，那么什么情况下X的熵最大呢？</p>
<p><span class="math inline">\(\max_{p_1,p_2,\cdots,p_N} H(X) = -\sum_{i=1}^N p_i \log_2 p_i \\ s.t. \sum_{i=1}^N p_i = 1\)</span></p>
<p>求导 <span class="math inline">\(\frac{dH_p(X)}{p_i} = - (1 \times \log_2 p_i + p_i \times \frac{1}{p_i}) = -( log_2 p_i + 1 ) = 0\)</span> 似乎得到p_i=0，然而这个不满足约束条件。我们不能直接求导解决，要考虑约束。</p>
<p>应当使用拉格朗日乘子法，引入拉格朗日函数$ L(p_1, p_2, …, p_N, ) = -(_{i=1}^{N} p_i <em>2 p_i) + (</em>{i=1}^{N} p_i - 1) $ 其中，$ $ 是拉格朗日乘子。</p>
<p>对每个变量 $ p_i $ 和 $ $ 求偏导数，并将它们设置为0以找到极值点。我们得到以下方程组： $ = -_2 p_i - 1 + = 0 $</p>
<p>$ = _{i=1}^{N} p_i - 1 = 0 $</p>
<p>这里的重点是注意到第一个方程组，告诉我们每一个 <span class="math inline">\(p_i\)</span> 都是 <span class="math inline">\(2^{-1+\lambda}\)</span>，都是同样的<span class="math inline">\(\lambda\)</span>，所以是同一个数。第二个方程其实就还是约束条件，那么就简单了，<span class="math inline">\(p_i = 1/N\)</span>。</p>
</section>
</section>
<section id="什么是最大熵原理" class="level4" data-number="1.1.3">
<h4 data-number="1.1.3" class="anchored" data-anchor-id="什么是最大熵原理"><span class="header-section-number">1.1.3</span> 什么是最大熵原理？</h4>
<p>最大熵原理是一个学习准则，认为学习概率模型应当选择熵最大的模型。 在什么东西里面选呢？还要先满足约束条件，也就是能在训练集上拟合，然后熵是在帮忙衡量模型的结构风险。</p>
<p><img src="P_Assignment4_yecanming_files/figure-html/cell-8-5-image.png" class="img-fluid" alt="image.png"> 李航书上没有讨论具体求解约束的顺序。</p>
<p>这里我们再理解下书上的这个图 <img src="P_Assignment4_yecanming_files/figure-html/cell-8-2-image-3.png" class="img-fluid" alt="image-3.png"> 一个三角形表示了能取三个值的离散分布列。在顶点上表示这个顶点的那个值概率为1，其他两个取值为0，在边上表示对面的顶点取值是0。具体坐标是怎么对应到概率的呢？这个暂时没有搜索到答案。 为什么约束条件是直线不是曲线呢？图中的约束条件两条直线有唯一的交点，为什么李航仍然说这个模型还有无穷多个呢？</p>
</section>
<section id="什么是最大熵模型" class="level4" data-number="1.1.4">
<h4 data-number="1.1.4" class="anchored" data-anchor-id="什么是最大熵模型"><span class="header-section-number">1.1.4</span> 什么是最大熵模型？</h4>
<p>书上讲的很抽象，这里我的理解是，模型是指机器学习模型，也就是<span class="math inline">\(P_w(Y|X)\)</span>, 机器学习训练集会给我们约束，限制<span class="math inline">\(P_w(Y|X)\)</span>，然后我们使用最大熵原理去选择。</p>
<p>具体怎么约束是关键。李航书上介绍的方法是利用 <span class="math inline">\(P(X, Y) = P(X) \times P(Y|X)\)</span>的性质，其中P(X, Y)和P(X)直接从数据集进行估计得到经验分布。 利用函数的期望的性质，进一步说要用期望相等来作为约束条件。 <img src="P_Assignment4_yecanming_files/figure-html/cell-8-1-image-2.png" class="img-fluid" alt="image-2.png"></p>
<p>但是李航的书上讲到这里戛然而止，并没有说对于分类模型f要怎么定义。袁老师的课件上说对于NLP和CV是不同的，我仍然无法理解到底要干什么。</p>
<p>李航书上另一个疑点是X的分布他认为是连续型，但是这样估计出来的P(X, Y)和P(X)对吗？</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="P_Assignment4_yecanming_files/figure-html/cell-8-3-image-4.png" class="img-fluid figure-img"></p>
<figcaption>image-4.png</figcaption>
</figure>
</div>
<p>我们可以看到最后李航推到出来的东西 <img src="P_Assignment4_yecanming_files/figure-html/cell-8-4-image-6.png" class="img-fluid" alt="image-6.png"> 推理的时候，模型对于已知的x，试一下每一个不同的y，看看n个f(x, y)特征在w的组合下得到的值是多少，然后最后exp一下这个值，对所有试过的y做归一化。 这里我们终于看懂最大熵模型在搞什么了，前面推导时”f(x, y)“只能是两个值让我们不找到在干什么。 现在懂了，最大熵模型，如果<span class="math inline">\(f(x, y)=x\)</span>，不去管y，就是softmax。</p>
</section>
</section>
<section id="解题" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="解题"><span class="header-section-number">1.2</span> 解题</h3>
<section id="牛顿法和拟牛顿法" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="牛顿法和拟牛顿法"><span class="header-section-number">1.2.1</span> 牛顿法和拟牛顿法</h4>
<p>首先需要商榷一下课件上术语的表述。 - Number 1, 牛顿法=牛顿迭代法=Newton-Raphson Method， 这三个东西肯定一样的。但是梯度下降法有所区别。 - Number 2, 牛顿法分为两个，一个是用来解方程的（求根使得式子=0），一个是用来优化（求最小值）。这个很容易混淆，因为我们机器学习的时候，往往loss最小值就是0，搞得求根好像就是在优化一样。 - Number 3, 牛顿法解方程，迭代公式是 <span class="math inline">\(x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}\)</span>，其中 <span class="math inline">\(f(x_k)\)</span> 是函数值，<span class="math inline">\(f'(x_k)\)</span> 是函数的导数，这个是用切线去搞，不是叫做梯度下降法，梯度在下面，梯度下降法是用来优化的不是求根的。而牛顿法做优化，迭代公式才是 <span class="math inline">\(x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)}\)</span>， 这个反而和梯度下降法有关系，是对梯度下降法用二阶导数做了修正。 - 李航书上直接介绍了牛顿优化法的多维情况，也就是黑塞矩阵啦。 <img src="P_Assignment4_yecanming_files/figure-html/cell-9-4-image.png" class="img-fluid" alt="image.png"> - 牛顿法解方程是利用一阶泰勒展开，局部用切线近似曲线，用切线的根代替曲线的根。牛顿法做优化则是利用二阶泰勒展开，局部用二次函数近似曲线，用二次函数的极值代替曲线的极值。</p>
<p>拟（quasi, /ˈkweɪzaɪ; ˈkweɪsaɪ; ˈkwɑːzi/, as it were）牛顿法想要替代掉 黑塞矩阵的逆矩阵 <span class="math inline">\(H^{-1}\)</span>。 首先一阶导数的变化量可以用二阶导数乘上x的变化量来近似（二阶泰勒展开就是相等） <img src="P_Assignment4_yecanming_files/figure-html/cell-9-1-image-2.png" class="img-fluid" alt="image-2.png"> 这个就是拟牛顿条件，就是说能充当<span class="math inline">\(H_k^{-1}\)</span>的<span class="math inline">\(G_k\)</span>, 需要 $G_k (g_{k+1}-g_k) = (x_{k+1}-x_k) $</p>
<p>拟牛顿法需要通过迭代来计算<span class="math inline">\(G_{k+1} = G_k + \Delta_k\)</span>，其中<span class="math inline">\(\Delta_k\)</span>是拟牛顿条件的增量。</p>
<blockquote class="blockquote">
<p>中间有一段感觉李航突然介绍了另一个东西，和拟牛顿法没关系，介绍了正定性说明牛顿法一定可以成功好奇怪。</p>
</blockquote>
</section>
<section id="dfp算法" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="dfp算法"><span class="header-section-number">1.2.2</span> DFP算法</h4>
<p>DFP(Davidon-Fletcher-Powell)算法(DFP algorithm) 在李航528页附录B有描述，是求解无约束最优化问题的一种拟牛顿法。</p>
<p>假设 <span class="math inline">\(\Delta_k = P_k + Q_k\)</span>，使用拟牛顿条件可以得到 <img src="P_Assignment4_yecanming_files/figure-html/cell-9-2-image-3.png" class="img-fluid" alt="image-3.png"></p>
<p>注意这里符号<span class="math inline">\(y_k\)</span>实际上是<span class="math inline">\(g_{k+1}-g_k\)</span>，不是原本那个y。</p>
<p>而初始的<span class="math inline">\(G_k\)</span> 要正定。</p>
<p>BGFS和DFP类似，只不过不是近似<span class="math inline">\(G_k \approx H_k^{-1}\)</span>，而是近似<span class="math inline">\(B_k \approx H_k\)</span>。</p>
</section>
<section id="最大熵模型拉格朗日乘子法化简" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="最大熵模型拉格朗日乘子法化简"><span class="header-section-number">1.2.3</span> 最大熵模型拉格朗日乘子法化简</h4>
<p>一开始我们最大熵的模型优化问题是</p>
<p><span class="math display">\[
\max_{P\in C} H(P) = -\sum_{x, y} \tilde{P}(x) P(y|x) \log P(y|x)\\
s.t. E_{P}(f_i) = E_{\tilde{P}}(f_i), i=1,2,...,n\\
\sum_{y} P(y|x) = 1, x\in X
\]</span></p>
<p>引入拉格朗日乘子w_{0:n}后，问题变成</p>
<p><span class="math display">\[
\min_{P\in C} \max_{w} L(P, w) \equiv -H(P) + w_0 (1-\sum_{y} P(y|x)) + \sum_{i=1}^n w_i (E_{P}(f_i) - E_{\tilde{P}}(f_i))
\]</span></p>
<p>注意这个式子的列法，我们产生疑问，求最大值和最小值有没有区别，是加上lambda还是减去lambda乘上约束条件？</p>
<p>首先注意拉格朗日乘子是大于等于0的，我们之所以可以按照上面的方法变换，在于外面想要最小化，而里面让约束条件不满足时有机会优化到正无穷（让违反约束的对应的拉格朗日乘子很大就行），所以里面是最小化。如果外面是要搞最大化，那里面就应该是最小化，或者变成减去拉格朗日乘子，让约束条件满足时有机会优化到负无穷。</p>
<p>对偶问题是反过来，在所有的拉格朗日乘子中搜索，其中任何一个x都有对应的最小的值，可能有时候偶尔违反下约束，得让那个东西小，最后搜索到x那么吝啬的小东西还要让它大。根据定理，这样对抗下来，其实拉格朗日乘子也不太敢把自己弄得很大，x会变得很小心翼翼，所以其实这个找到的最优值甚至比原始问题还要小。 <img src="P_Assignment4_yecanming_files/figure-html/cell-9-3-image-4.png" class="img-fluid" alt="image-4.png"></p>
<p>在满足KKT条件的时候，原始问题和对偶问题的最优解是等价的。最大熵模型就是满足了。</p>
<p>进一步求解偏导数=0之后，我们首先把P_w(y|x)的形式优化了出来。</p>
<p><span class="math display">\[
P_w(y|x) = softmax(\sum_{i=1}^n w_i f_i(x,y))
\]</span></p>
<p>所以我们最后的问题简化为拉格朗日乘子，这里实际上是模型参数，的最大化 <span class="math display">\[
\max_{w} L(P, w) \equiv -H(P) + w_0 (1-\sum_{y} P_w(y|x)) + \sum_{i=1}^n w_i (E_{P}(f_i) - E_{\tilde{P}}(f_i))
\]</span></p>
<p>也就是 <span class="math display">\[\min_{w\in R^n}\begin{aligned}
f(w)
&amp;=\sum_x \hat P(x)\log \sum_y \exp \left( \sum_{i=1}^{n} w_i f_i(x,y)\right)-\sum_{x,y} \hat P(x,y)\sum_{i=1}^{n} w_i f_i(x,y)
\end{aligned},\]</span> 梯度为 <span class="math display">\[g(w)=\left(\frac{\partial f(w)}{\partial w_1}, \frac{\partial f(w)}{\partial w_2},...,\frac{\partial f(w)}{\partial w_n}\right)^T\]</span> 其中, <span class="math display">\[\frac{\partial f(w)}{\partial w_i}=\sum_{x,y} \hat P(x)P_w(y|x)f_i(x,y)-E_{\hat P}(f_i),\quad i=1,2,...,n\]</span></p>
</section>
<section id="dfp算法求解" class="level4" data-number="1.2.4">
<h4 data-number="1.2.4" class="anchored" data-anchor-id="dfp算法求解"><span class="header-section-number">1.2.4</span> DFP算法求解</h4>
<p>输入为：特征函数 $ f_1,f_2,…,f_n$ ，经验分布 <span class="math inline">\(\hat{P}(x,y)\)</span> ，目标函数 $ f(w)$ ，梯度 <span class="math inline">\(g(w)=\nabla f(w)\)</span> ，精度要求 $$ 。</p>
<p>输出为：最优参数值 $ w^<em>$ ，最优模型 $ P_{w^</em>}(y|x)$ 。</p>
<p>算法步骤：</p>
<p>（1）选定初始点 $ w^{(0)}$ ，取 $ G_0$ 为正定对称矩阵，置 $ k=0$ ；</p>
<p>（2）计算 $ g_k=g{(w^{(k)})}$ ，若 $|g_k|&lt;$ ，则认为精度到了，停止计算，得 $ w^*=w^{(k)}$，退出算法；</p>
<p>（3）由 $ p_k=-G_kg_k$ 求出 $ p_k$， 这个 $ p_k$ 就是要更新的东西，近似的是 <span class="math inline">\(-H_kg_k\)</span></p>
<p>（4）一维搜索：求 $ _k$ 使得 $ f(w^{(k)}+_kp_k)=f(w^{(k)}+p_k)$ ；这一步是为了更好的利用 $ p_k$</p>
<p>（5）置 $ w<sup>{(k+1)}=w</sup>{(k)}+_kp_k$ ；进行权重的实际更新</p>
<p>（6）计算 $ g_{k+1}=g(w^{(k+1)})$ ，若 $|g_{k+1}|&lt;$ ，则停止计算，得 $ w^*=w^{(k+1)}<span class="math inline">\(；否则，按下式求出 新的\)</span> G_{k+1};$ <span class="math inline">\(\begin{aligned}
&amp;G_{k+1}=G_k+\frac{\delta_k\delta_k^T}{\delta_k^Ty_k}-\frac{G_ky_ky_k^TG_k}{y_k^TG_ky_k}
\end{aligned}\)</span> 其中， <span class="math inline">\(\begin{aligned}&amp;y_k=g_{k+1}-g_k,&amp;\delta_k=w^{(k+1)}-w^{(k)}\end{aligned}\)</span></p>
<p>（7）置 $ k=k+1$ ，转步骤（3）。</p>
</section>
<section id="pytorch代码实现" class="level4" data-number="1.2.5">
<h4 data-number="1.2.5" class="anchored" data-anchor-id="pytorch代码实现"><span class="header-section-number">1.2.5</span> Pytorch代码实现</h4>
<p>最大熵实际上是怎么做多分类任务的呢？ 我们尝试把上面的那些公式再用Pytorch实现一下。</p>
<p>由于我们还没有理解多分类任务的特征函数到底要怎么定义，所以我们这一部分的代码暂时先不写，等到理解了再补充。</p>
<div id="cell-13" class="cell">
<details class="code-fold">
<summary>代码</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XYFeatureExtractor(nn.Module):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, output_dim):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(XYFeatureExtractor, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 这个是生成式模型，所以模型会自己脑补y，把所有情况的y都考虑一下</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 定义最大熵模型（softmax分类器）</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MaxEntropyModel(nn.Module):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, output_dim):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MaxEntropyModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(input_dim<span class="op">*</span>output_dim, output_dim)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, features):</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 这里的x就是 batch个  f_{1:n}(x, y) 向量</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.softmax(<span class="va">self</span>.fc(features), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MaxEntropyLoss(nn.Module):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model:MaxEntropyModel, extractor : XYFeatureExtractor):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MaxEntropyLoss, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 最大熵模型的损失函数和weight也有关系, 所以得传进来</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>, target):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(input.shape)</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        log_sum_exp <span class="op">=</span> torch.logsumexp(<span class="va">self</span>.model.fc(<span class="bu">input</span>), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(log_sum_exp.shape)</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        sum_x_log_sum_exp <span class="op">=</span> torch.<span class="bu">sum</span>(log_sum_exp) <span class="co"># empirical x</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        sum_logits <span class="op">=</span> torch.<span class="bu">sum</span>(<span class="va">self</span>.model.fc(<span class="bu">input</span>), dim<span class="op">=</span><span class="dv">1</span>) </span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>sum_x_log_sum_exp</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-14" class="cell">
<details class="code-fold">
<summary>代码</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model = MaxEntropyModel(100, 10) </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion = MaxEntropyLoss(model)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion(torch.randn(10, 100), torch.randint(0, 10, (10,)))</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10, 100])
torch.Size([10])</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>tensor(-23.8446, grad_fn=&lt;NegBackward0&gt;)</code></pre>
</div>
</div>
<p>我们很快观察到代码似乎都没用到target变量，到底怎么学习呢？</p>
<p>有待于进一步探究，我们会在后面的理论作业中尽可能搞懂这个问题，现在确实太抽象了，公式我是懂的，但是f(x, y)书上是真的没有写。需要调查一下资料，要不然我不知道Pytorch怎么实现最大熵模型。</p>
<p>我们倒是可以实现以下DFP算法先，这个看起来很好理解。</p>
<div id="cell-17" class="cell">
<details class="code-fold">
<summary>代码</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># class DFP_optimizer(torch.optim.Optimizer):</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DFP_optimizer():</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> <span class="bu">list</span>(params)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.G <span class="op">=</span> [torch.eye(p.size()[<span class="dv">0</span>]) <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.params]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, param <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.params):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>            g <span class="op">=</span> param.grad</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            G <span class="op">=</span> <span class="va">self</span>.G[i]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            pk <span class="op">=</span> <span class="op">-</span>torch.mv(G, g)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 一维搜索（这里简化为固定步长）</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            lambda_k <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            param.data.add_(lambda_k, pk)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            gk_new <span class="op">=</span> param.grad</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            yk <span class="op">=</span> gk_new <span class="op">-</span> g</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>            dk <span class="op">=</span> lambda_k <span class="op">*</span> pk</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>            rho_k <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> torch.dot(yk, dk)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 更新G</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            G <span class="op">=</span> G <span class="op">-</span> rho_k <span class="op">*</span> torch.ger(torch.mv(G, yk), torch.mv(G, yk)) <span class="op">+</span> rho_k <span class="op">*</span> torch.ger(dk, dk)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.G[i] <span class="op">=</span> G</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-18" class="cell">
<details class="code-fold">
<summary>代码</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing the DFP optimizer on a simple quadratic function</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> quadratic_function(x):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x <span class="op">-</span> <span class="dv">3</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient of the quadratic function</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> quadratic_gradient(x):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">3</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize parameter</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> DFP_optimizer([x])</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimization loop</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizer.zero_grad()</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    x.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> quadratic_function(x)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Current x: </span><span class="sc">{</span>x<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Optimized x: </span><span class="sc">{</span>x<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Current x: 0.05999999865889549, Loss: 9.0
Current x: nan, Loss: 8.643600463867188
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Current x: nan, Loss: nan
Optimized x: nan</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_2183857/2759460865.py:15: UserWarning: This overload of add_ is deprecated:
    add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
    add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1578.)
  param.data.add_(lambda_k, pk)</code></pre>
</div>
</div>
<p>看来我们的实现还有问题，要进一步优化一下，不过不是这次理论作业的重点，暂时先这样吧，去做科研了。</p>
</section>
</section>
<section id="题目扩展问题" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="题目扩展问题"><span class="header-section-number">1.3</span> 题目扩展问题</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "已复制");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/Open-Book-Studio\.github\.io\/THU-Coursework-Machine-Learning-for-Big-Data");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/issues/new" class="toc-action"><i class="bi bi-github"></i>反馈问题</a></li></ul></div></div></div></footer></body></html>